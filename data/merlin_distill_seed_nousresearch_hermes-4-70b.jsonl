{"id": "20260120-195007-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 46, "completion_tokens": 22, "latency_ms": 49037.017822265625, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T19:50:56Z"}}
{"id": "20260120-195007-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to the appropriate team members or departments based on predefined rules and criteria, ensuring timely completion and optimal resource utilization.", "prompt_tokens": 38, "completion_tokens": 30, "latency_ms": 20385.87784767151, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to the appropriate team members or departments based on predefined rules and criteria, ensuring timely completion and optimal resource utilization.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T19:51:17Z"}}
{"id": "20260120-195007-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Urgent", "prompt_tokens": 47, "completion_tokens": 4, "latency_ms": 8190.897464752197, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Urgent", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T19:51:26Z"}}
{"id": "20260120-195007-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here's a Python snippet that loads JSON data from the file \"guild/config/model_routing.json\":\n\n```python\nimport json\n\n# Load JSON data from file\nwith open(\"guild/config/model_routing.json\", \"r\") as file:\n    model_routing = json.load(file)\n\nprint(model_routing)\n```\n\nThis code does the following:\n\n1. We import the `json` module to work with JSON data.\n\n2. We use a `with` statement to open the file \"guild/config/model_routing.json\" in read mode (\"r\"). This ensures that the file is properly closed after we're done reading from it.\n\n3. Inside the `with` block, we use `json.load()` to parse the contents of the file and load the JSON data into a Python object called `model_routing`. The resulting object will be a dictionary if the top-level element in the JSON file is an object, or a list if the top-level element is an array.\n\n4. Finally, we print the loaded `model_routing` object to see its contents.\n\nMake sure that the file path \"guild/config/model_routing.json\" correctly points to the location of your JSON file relative to the script's execution directory.\n\nNote: This code assumes that the JSON file exists and is valid. If", "prompt_tokens": 39, "completion_tokens": 256, "latency_ms": 151563.1046295166, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here's a Python snippet that loads JSON data from the file \"guild/config/model_routing.json\":\n\n```python\nimport json\n\n# Load JSON data from file\nwith open(\"guild/config/model_routing.json\", \"r\") as file:\n    model_routing = json.load(file)\n\nprint(model_routing)\n```\n\nThis code does the following:\n\n1. We import the `json` module to work with JSON data.\n\n2. We use a `with` statement to open the file \"guild/config/model_routing.json\" in read mode (\"r\"). This ensures that the file is properly closed after we're done reading from it.\n\n3. Inside the `with` block, we use `json.load()` to parse the contents of the file and load the JSON data into a Python object called `model_routing`. The resulting object will be a dictionary if the top-level element in the JSON file is an object, or a list if the top-level element is an array.\n\n4. Finally, we print the loaded `model_routing` object to see its contents.\n\nMake sure that the file path \"guild/config/model_routing.json\" correctly points to the location of your JSON file relative to the script's execution directory.\n\nNote: This code assumes that the JSON file exists and is valid. If", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T19:53:57Z"}}
{"id": "20260120-195007-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"task_id\": \"T-100\", \"status\": \"queued\"}", "prompt_tokens": 40, "completion_tokens": 16, "latency_ms": 13191.364049911499, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"task_id\": \"T-100\", \"status\": \"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T19:54:11Z"}}
{"id": "20260120-195007-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here's the bash command to run `scripts/eval_lmstudio_models.py` against all models on `http://127.0.0.1:1234`:\n\n```bash\npython scripts/eval_lmstudio_models.py --model_server http://127.0.0.1:1234 --all_models\n```\n\nThis command assumes that:\n- The `scripts/eval_lmstudio_models.py` script is located in the current directory or a directory specified by the `PYTHONPATH` environment variable.\n- The script accepts the `--model_server` argument to specify the URL of the model server, and the `--all_models` argument to evaluate all available models on that server.\n\nMake sure you have the necessary dependencies installed and the appropriate permissions to run the script.", "prompt_tokens": 54, "completion_tokens": 158, "latency_ms": 91761.4598274231, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here's the bash command to run `scripts/eval_lmstudio_models.py` against all models on `http://127.0.0.1:1234`:\n\n```bash\npython scripts/eval_lmstudio_models.py --model_server http://127.0.0.1:1234 --all_models\n```\n\nThis command assumes that:\n- The `scripts/eval_lmstudio_models.py` script is located in the current directory or a directory specified by the `PYTHONPATH` environment variable.\n- The script accepts the `--model_server` argument to specify the URL of the model server, and the `--all_models` argument to evaluate all available models on that server.\n\nMake sure you have the necessary dependencies installed and the appropriate permissions to run the script.", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T19:55:43Z"}}
{"id": "20260120-195007-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "lfm2.5-1.2b", "prompt_tokens": 60, "completion_tokens": 11, "latency_ms": 8341.140508651733, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T19:55:51Z"}}
{"id": "20260120-195007-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here are two key principles for selecting models in resource-constrained scenarios:\n\n- Prioritize models that offer the best performance per unit of compute/memory. Evaluate metrics like accuracy, latency, and throughput relative to the model size, number of parameters, and inference cost. Choose leaner architectures that deliver sufficient capabilities within budget.\n\n- Opt for models with strong open-source support and pre-trained weights. Leveraging community-vetted implementations reduces development overhead. Transfer learning from established checkpoints accelerates adaptation while minimizing training compute requirements.", "prompt_tokens": 40, "completion_tokens": 103, "latency_ms": 60115.77081680298, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here are two key principles for selecting models in resource-constrained scenarios:\n\n- Prioritize models that offer the best performance per unit of compute/memory. Evaluate metrics like accuracy, latency, and throughput relative to the model size, number of parameters, and inference cost. Choose leaner architectures that deliver sufficient capabilities within budget.\n\n- Opt for models with strong open-source support and pre-trained weights. Leveraging community-vetted implementations reduces development overhead. Transfer learning from established checkpoints accelerates adaptation while minimizing training compute requirements.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T19:56:52Z"}}
{"id": "20260120-195007-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 46, "completion_tokens": 22, "latency_ms": 17299.03531074524, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T19:57:09Z"}}
{"id": "20260120-195007-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to the appropriate team members or departments based on predefined rules and criteria, ensuring timely completion and optimal resource utilization.", "prompt_tokens": 38, "completion_tokens": 30, "latency_ms": 20688.751220703125, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to the appropriate team members or departments based on predefined rules and criteria, ensuring timely completion and optimal resource utilization.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T19:57:30Z"}}
{"id": "20260120-195007-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Urgent", "prompt_tokens": 47, "completion_tokens": 4, "latency_ms": 7786.377906799316, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Urgent", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T19:57:38Z"}}
{"id": "20260120-195007-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here's a Python snippet that loads JSON data from the file \"guild/config/model_routing.json\":\n\n```python\nimport json\n\n# Load JSON data from file\nwith open(\"guild/config/model_routing.json\", \"r\") as file:\n    model_routing = json.load(file)\n\nprint(model_routing)\n```\n\nThis code does the following:\n\n1. We import the `json` module to work with JSON data.\n\n2. We use a `with` statement to open the file \"guild/config/model_routing.json\" in read mode (\"r\"). This ensures that the file is properly closed after we're done reading from it.\n\n3. Inside the `with` block, we use `json.load()` to parse the contents of the file and load the JSON data into a Python object called `model_routing`. The resulting object will be a dictionary if the top-level element in the JSON file is an object, or a list if the top-level element is an array.\n\n4. Finally, we print the loaded `model_routing` object to see its contents.\n\nMake sure that the file path \"guild/config/model_routing.json\" correctly points to the location of your JSON file relative to the Python script's execution directory.\n\nNote: This code assumes that the JSON file exists and is valid.", "prompt_tokens": 39, "completion_tokens": 256, "latency_ms": 148031.4769744873, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here's a Python snippet that loads JSON data from the file \"guild/config/model_routing.json\":\n\n```python\nimport json\n\n# Load JSON data from file\nwith open(\"guild/config/model_routing.json\", \"r\") as file:\n    model_routing = json.load(file)\n\nprint(model_routing)\n```\n\nThis code does the following:\n\n1. We import the `json` module to work with JSON data.\n\n2. We use a `with` statement to open the file \"guild/config/model_routing.json\" in read mode (\"r\"). This ensures that the file is properly closed after we're done reading from it.\n\n3. Inside the `with` block, we use `json.load()` to parse the contents of the file and load the JSON data into a Python object called `model_routing`. The resulting object will be a dictionary if the top-level element in the JSON file is an object, or a list if the top-level element is an array.\n\n4. Finally, we print the loaded `model_routing` object to see its contents.\n\nMake sure that the file path \"guild/config/model_routing.json\" correctly points to the location of your JSON file relative to the Python script's execution directory.\n\nNote: This code assumes that the JSON file exists and is valid.", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:00:07Z"}}
{"id": "20260120-195007-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"task_id\": \"T-100\", \"status\": \"queued\"}", "prompt_tokens": 40, "completion_tokens": 16, "latency_ms": 14105.990409851074, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"task_id\": \"T-100\", \"status\": \"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:00:21Z"}}
{"id": "20260120-195007-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here's the bash command to run `scripts/eval_lmstudio_models.py` against all models on `http://127.0.0.1:1234`:\n\n```bash\npython scripts/eval_lmstudio_models.py --model_server http://127.0.0.1:1234 --all_models\n```\n\nThis command assumes that:\n- The `scripts/eval_lmstudio_models.py` script is located in the current directory or a directory specified by the `PYTHONPATH` environment variable.\n- The model server is running and accessible at `http://127.0.0.1:1234`.\n- The `--all_models` flag is supported by the `scripts/eval_lmstudio_models.py` script to evaluate all available models on the server.\n\nMake sure you have the necessary dependencies installed and the required environment variables set before running this command.", "prompt_tokens": 54, "completion_tokens": 177, "latency_ms": 105731.40263557434, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here's the bash command to run `scripts/eval_lmstudio_models.py` against all models on `http://127.0.0.1:1234`:\n\n```bash\npython scripts/eval_lmstudio_models.py --model_server http://127.0.0.1:1234 --all_models\n```\n\nThis command assumes that:\n- The `scripts/eval_lmstudio_models.py` script is located in the current directory or a directory specified by the `PYTHONPATH` environment variable.\n- The model server is running and accessible at `http://127.0.0.1:1234`.\n- The `--all_models` flag is supported by the `scripts/eval_lmstudio_models.py` script to evaluate all available models on the server.\n\nMake sure you have the necessary dependencies installed and the required environment variables set before running this command.", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:02:07Z"}}
{"id": "20260120-195007-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "lfm2.5-1.2b", "prompt_tokens": 60, "completion_tokens": 11, "latency_ms": 9249.406337738037, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:02:16Z"}}
{"id": "20260120-195007-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here are two key principles for selecting models in resource-constrained scenarios:\n\n- Prioritize models that deliver the most value per unit of compute/memory. Look at metrics like accuracy per FLOP, latency, or cost to identify efficient options.\n\n- Opt for smaller, simpler architectures when possible. Models with fewer parameters and less complexity generally train faster and require less resources while still providing strong performance.", "prompt_tokens": 40, "completion_tokens": 79, "latency_ms": 50450.99067687988, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here are two key principles for selecting models in resource-constrained scenarios:\n\n- Prioritize models that deliver the most value per unit of compute/memory. Look at metrics like accuracy per FLOP, latency, or cost to identify efficient options.\n\n- Opt for smaller, simpler architectures when possible. Models with fewer parameters and less complexity generally train faster and require less resources while still providing strong performance.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:03:07Z"}}
{"id": "20260120-195007-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 46, "completion_tokens": 22, "latency_ms": 17559.001207351685, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:03:25Z"}}
{"id": "20260120-195007-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to the appropriate team members or departments based on predefined criteria, ensuring timely and effective completion of work.", "prompt_tokens": 38, "completion_tokens": 28, "latency_ms": 18660.701751708984, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to the appropriate team members or departments based on predefined criteria, ensuring timely and effective completion of work.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:03:44Z"}}
{"id": "20260120-195007-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Urgent", "prompt_tokens": 47, "completion_tokens": 4, "latency_ms": 8006.249189376831, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Urgent", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:03:52Z"}}
{"id": "20260120-195007-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here's a Python snippet that loads JSON data from the file \"guild/config/model_routing.json\":\n\n```python\nimport json\n\n# Load JSON data from file\nwith open(\"guild/config/model_routing.json\", \"r\") as file:\n    model_routing = json.load(file)\n\nprint(model_routing)\n```\n\nThis code does the following:\n\n1. We import the `json` module to work with JSON data.\n\n2. We use a `with` statement to open the file \"guild/config/model_routing.json\" in read mode (\"r\"). This ensures that the file is properly closed after we're done reading from it.\n\n3. Inside the `with` block, we use `json.load()` to parse the contents of the file and load the JSON data into a Python object called `model_routing`. The resulting object will be a dictionary if the top-level element in the JSON file is an object, or a list if the top-level element is an array.\n\n4. Finally, we print the loaded `model_routing` object to see its contents.\n\nMake sure that the file path \"guild/config/model_routing.json\" correctly points to the location of your JSON file relative to the Python script's execution directory.\n\nNote: This code assumes that the JSON file exists and is valid.", "prompt_tokens": 39, "completion_tokens": 256, "latency_ms": 150005.9461593628, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here's a Python snippet that loads JSON data from the file \"guild/config/model_routing.json\":\n\n```python\nimport json\n\n# Load JSON data from file\nwith open(\"guild/config/model_routing.json\", \"r\") as file:\n    model_routing = json.load(file)\n\nprint(model_routing)\n```\n\nThis code does the following:\n\n1. We import the `json` module to work with JSON data.\n\n2. We use a `with` statement to open the file \"guild/config/model_routing.json\" in read mode (\"r\"). This ensures that the file is properly closed after we're done reading from it.\n\n3. Inside the `with` block, we use `json.load()` to parse the contents of the file and load the JSON data into a Python object called `model_routing`. The resulting object will be a dictionary if the top-level element in the JSON file is an object, or a list if the top-level element is an array.\n\n4. Finally, we print the loaded `model_routing` object to see its contents.\n\nMake sure that the file path \"guild/config/model_routing.json\" correctly points to the location of your JSON file relative to the Python script's execution directory.\n\nNote: This code assumes that the JSON file exists and is valid.", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:06:22Z"}}
{"id": "20260120-195007-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"task_id\": \"T-100\", \"status\": \"queued\"}", "prompt_tokens": 40, "completion_tokens": 16, "latency_ms": 13997.64609336853, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"task_id\": \"T-100\", \"status\": \"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:06:37Z"}}
{"id": "20260120-195007-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here is the bash command to run `scripts/eval_lmstudio_models.py` against all models on `http://127.0.0.1:1234`:\n\n```bash\npython scripts/eval_lmstudio_models.py --model_server http://127.0.0.1:1234 --all_models\n```\n\nThis assumes the script takes a `--model_server` argument to specify the model server URL, and an `--all_models` flag to evaluate all available models on that server.\n\nLet me know if you need any other details!", "prompt_tokens": 54, "completion_tokens": 114, "latency_ms": 74765.43116569519, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here is the bash command to run `scripts/eval_lmstudio_models.py` against all models on `http://127.0.0.1:1234`:\n\n```bash\npython scripts/eval_lmstudio_models.py --model_server http://127.0.0.1:1234 --all_models\n```\n\nThis assumes the script takes a `--model_server` argument to specify the model server URL, and an `--all_models` flag to evaluate all available models on that server.\n\nLet me know if you need any other details!", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:07:52Z"}}
{"id": "20260120-195007-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "lfm2.5-1.2b", "prompt_tokens": 60, "completion_tokens": 11, "latency_ms": 9111.73129081726, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:08:01Z"}}
{"id": "20260120-195007-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here are two key principles for model selection under resource constraints:\n\n- Prioritize models that have demonstrated strong empirical performance on similar tasks and datasets to the target problem. Look at benchmarks, papers, and leaderboards.\n\n- Favor simpler architectures that require less compute and data to train effectively. All else equal, prefer linear models over deep neural nets, smaller transformers over larger ones, etc.", "prompt_tokens": 40, "completion_tokens": 77, "latency_ms": 56898.892879486084, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here are two key principles for model selection under resource constraints:\n\n- Prioritize models that have demonstrated strong empirical performance on similar tasks and datasets to the target problem. Look at benchmarks, papers, and leaderboards.\n\n- Favor simpler architectures that require less compute and data to train effectively. All else equal, prefer linear models over deep neural nets, smaller transformers over larger ones, etc.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:08:58Z"}}
{"id": "20260120-195007-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 46, "completion_tokens": 22, "latency_ms": 25924.51000213623, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:09:24Z"}}
{"id": "20260120-195007-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to appropriate team members based on factors like skills, availability and workload, optimizing workflow and productivity.", "prompt_tokens": 38, "completion_tokens": 27, "latency_ms": 25303.016901016235, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to appropriate team members based on factors like skills, availability and workload, optimizing workflow and productivity.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:09:50Z"}}
{"id": "20260120-195007-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Urgent", "prompt_tokens": 47, "completion_tokens": 4, "latency_ms": 10903.359174728394, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Urgent", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:10:01Z"}}
{"id": "20260120-195007-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here's a Python snippet that loads JSON data from the file \"guild/config/model_routing.json\":\n\n```python\nimport json\n\n# Load JSON data from file\nwith open(\"guild/config/model_routing.json\", \"r\") as file:\n    model_routing = json.load(file)\n\nprint(model_routing)\n```\n\nThis code does the following:\n\n1. We import the `json` module to work with JSON data.\n\n2. We use a `with` statement to open the file \"guild/config/model_routing.json\" in read mode (\"r\"). This ensures that the file is properly closed after we're done reading from it.\n\n3. Inside the `with` block, we use `json.load()` to parse the contents of the file and load the JSON data into a Python object called `model_routing`. The resulting `model_routing` variable will be a dictionary if the top-level element in the JSON is an object, or a list if the top-level element is an array.\n\n4. Finally, we print the loaded `model_routing` data to see its contents.\n\nMake sure that the file path \"guild/config/model_routing.json\" correctly points to the location of your JSON file relative to the script's execution directory.\n\nNote: This code assumes that the JSON file exists and is", "prompt_tokens": 39, "completion_tokens": 256, "latency_ms": 179379.9078464508, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here's a Python snippet that loads JSON data from the file \"guild/config/model_routing.json\":\n\n```python\nimport json\n\n# Load JSON data from file\nwith open(\"guild/config/model_routing.json\", \"r\") as file:\n    model_routing = json.load(file)\n\nprint(model_routing)\n```\n\nThis code does the following:\n\n1. We import the `json` module to work with JSON data.\n\n2. We use a `with` statement to open the file \"guild/config/model_routing.json\" in read mode (\"r\"). This ensures that the file is properly closed after we're done reading from it.\n\n3. Inside the `with` block, we use `json.load()` to parse the contents of the file and load the JSON data into a Python object called `model_routing`. The resulting `model_routing` variable will be a dictionary if the top-level element in the JSON is an object, or a list if the top-level element is an array.\n\n4. Finally, we print the loaded `model_routing` data to see its contents.\n\nMake sure that the file path \"guild/config/model_routing.json\" correctly points to the location of your JSON file relative to the script's execution directory.\n\nNote: This code assumes that the JSON file exists and is", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:13:01Z"}}
{"id": "20260120-195007-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"task_id\": \"T-100\", \"status\": \"queued\"}", "prompt_tokens": 40, "completion_tokens": 16, "latency_ms": 16765.98572731018, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"task_id\": \"T-100\", \"status\": \"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:13:18Z"}}
{"id": "20260120-195007-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here's the bash command to run `scripts/eval_lmstudio_models.py` against all models on `http://127.0.0.1:1234`:\n\n```bash\npython scripts/eval_lmstudio_models.py --model_server http://127.0.0.1:1234 --all_models\n```\n\nExplanation:\n- `python` is used to execute the Python script.\n- `scripts/eval_lmstudio_models.py` is the path to the evaluation script you want to run.\n- `--model_server http://127.0.0.1:1234` specifies the URL of the model server where the models are hosted.\n- `--all_models` is an argument that tells the script to evaluate all available models on the specified model server.\n\nMake sure you have the necessary dependencies installed and the appropriate permissions to run the script before executing this command.", "prompt_tokens": 54, "completion_tokens": 180, "latency_ms": 132052.94799804688, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here's the bash command to run `scripts/eval_lmstudio_models.py` against all models on `http://127.0.0.1:1234`:\n\n```bash\npython scripts/eval_lmstudio_models.py --model_server http://127.0.0.1:1234 --all_models\n```\n\nExplanation:\n- `python` is used to execute the Python script.\n- `scripts/eval_lmstudio_models.py` is the path to the evaluation script you want to run.\n- `--model_server http://127.0.0.1:1234` specifies the URL of the model server where the models are hosted.\n- `--all_models` is an argument that tells the script to evaluate all available models on the specified model server.\n\nMake sure you have the necessary dependencies installed and the appropriate permissions to run the script before executing this command.", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:15:30Z"}}
{"id": "20260120-195007-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "lfm2.5-1.2b", "prompt_tokens": 60, "completion_tokens": 11, "latency_ms": 18638.036489486694, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:15:49Z"}}
{"id": "20260120-195007-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here are two key principles for selecting models in resource-constrained scenarios:\n\n- Prioritize models that deliver the most value per unit of compute/memory. Favor architectures known to be parameter-efficient and sample-efficient, like Transformers over RNNs or diffusion over GANs if comparable performance.\n\n- Opt for smaller base variants (e.g. BERT-base vs BERT-large) with proven fine-tuning capabilities rather than attempting massive models that may not fully converge due to hardware limits.", "prompt_tokens": 40, "completion_tokens": 96, "latency_ms": 77607.62214660645, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here are two key principles for selecting models in resource-constrained scenarios:\n\n- Prioritize models that deliver the most value per unit of compute/memory. Favor architectures known to be parameter-efficient and sample-efficient, like Transformers over RNNs or diffusion over GANs if comparable performance.\n\n- Opt for smaller base variants (e.g. BERT-base vs BERT-large) with proven fine-tuning capabilities rather than attempting massive models that may not fully converge due to hardware limits.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:17:07Z"}}
{"id": "20260120-195007-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 46, "completion_tokens": 22, "latency_ms": 29352.74863243103, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:17:37Z"}}
{"id": "20260120-195007-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to appropriate individuals or teams based on predefined rules and criteria, optimizing workflow and resource allocation within an organization.", "prompt_tokens": 38, "completion_tokens": 29, "latency_ms": 28070.214986801147, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to appropriate individuals or teams based on predefined rules and criteria, optimizing workflow and resource allocation within an organization.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:18:05Z"}}
{"id": "20260120-195007-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Urgent", "prompt_tokens": 47, "completion_tokens": 4, "latency_ms": 11310.275793075562, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Urgent", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:18:17Z"}}
{"id": "20260120-195007-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here's a Python snippet that loads JSON data from the file 'guild/config/model_routing.json':\n\n```python\nimport json\n\n# Load JSON data from file\nwith open('guild/config/model_routing.json', 'r') as file:\n    model_routing = json.load(file)\n\nprint(model_routing)\n```\n\nExplanation:\n\n1. We import the `json` module to work with JSON data.\n\n2. We use a `with` statement to open the file 'guild/config/model_routing.json' in read mode ('r'). This ensures that the file is properly closed after we're done reading from it.\n\n3. Inside the `with` block, we use `json.load()` to parse the JSON data from the file and assign it to the variable `model_routing`. The `json.load()` function reads the JSON data from the file object and returns a Python dictionary or list, depending on the structure of the JSON data.\n\n4. Finally, we print the loaded JSON data using `print(model_routing)` to display its contents.\n\nMake sure that the file path 'guild/config/model_routing.json' is correct and accessible from your current working directory. If the file doesn't exist or if there are any issues with reading the file, you may need to handle exceptions accordingly.", "prompt_tokens": 39, "completion_tokens": 254, "latency_ms": 199897.39751815796, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here's a Python snippet that loads JSON data from the file 'guild/config/model_routing.json':\n\n```python\nimport json\n\n# Load JSON data from file\nwith open('guild/config/model_routing.json', 'r') as file:\n    model_routing = json.load(file)\n\nprint(model_routing)\n```\n\nExplanation:\n\n1. We import the `json` module to work with JSON data.\n\n2. We use a `with` statement to open the file 'guild/config/model_routing.json' in read mode ('r'). This ensures that the file is properly closed after we're done reading from it.\n\n3. Inside the `with` block, we use `json.load()` to parse the JSON data from the file and assign it to the variable `model_routing`. The `json.load()` function reads the JSON data from the file object and returns a Python dictionary or list, depending on the structure of the JSON data.\n\n4. Finally, we print the loaded JSON data using `print(model_routing)` to display its contents.\n\nMake sure that the file path 'guild/config/model_routing.json' is correct and accessible from your current working directory. If the file doesn't exist or if there are any issues with reading the file, you may need to handle exceptions accordingly.", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:21:37Z"}}
{"id": "20260120-195007-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"task_id\": \"T-100\", \"status\": \"queued\"}", "prompt_tokens": 40, "completion_tokens": 16, "latency_ms": 14755.472183227539, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"task_id\": \"T-100\", \"status\": \"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:21:52Z"}}
{"id": "20260120-195007-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here's the bash command to run `scripts/eval_lmstudio_models.py` against all models on `http://127.0.0.1:1234`:\n\n```bash\npython scripts/eval_lmstudio_models.py --model_server http://127.0.0.1:1234 --all_models\n```\n\nThis command assumes that:\n- The `scripts/eval_lmstudio_models.py` script is located in the current directory or a directory specified in your Python path.\n- The model server is running and accessible at `http://127.0.0.1:1234`.\n- The `--all_models` flag is supported by the `scripts/eval_lmstudio_models.py` script to evaluate all available models on the server.\n\nMake sure you have the necessary dependencies installed and the required environment variables set before running this command.", "prompt_tokens": 54, "completion_tokens": 173, "latency_ms": 135509.13047790527, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here's the bash command to run `scripts/eval_lmstudio_models.py` against all models on `http://127.0.0.1:1234`:\n\n```bash\npython scripts/eval_lmstudio_models.py --model_server http://127.0.0.1:1234 --all_models\n```\n\nThis command assumes that:\n- The `scripts/eval_lmstudio_models.py` script is located in the current directory or a directory specified in your Python path.\n- The model server is running and accessible at `http://127.0.0.1:1234`.\n- The `--all_models` flag is supported by the `scripts/eval_lmstudio_models.py` script to evaluate all available models on the server.\n\nMake sure you have the necessary dependencies installed and the required environment variables set before running this command.", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:24:07Z"}}
{"id": "20260120-195007-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "lfm2.5-1.2b", "prompt_tokens": 60, "completion_tokens": 11, "latency_ms": 10046.311378479004, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:24:18Z"}}
{"id": "20260120-195007-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here are two key principles for selecting models in resource-constrained scenarios:\n\n\u2022 Prioritize models that deliver the highest marginal ROI per unit of compute. Focus on architectures and training approaches that achieve strong performance with minimal computational requirements.\n\n\u2022 Opt for smaller, more efficient base models rather than attempting to train large models from scratch. Fine-tune compact architectures like MobileNet or DistilBERT that provide excellent tradeoffs between size, speed and capability.\n\nThe goal is to maximize the impact of limited resources by selecting lean, optimized models that can still achieve the target performance metrics through smart training strategies and transfer learning approaches.", "prompt_tokens": 40, "completion_tokens": 121, "latency_ms": 119615.58771133423, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here are two key principles for selecting models in resource-constrained scenarios:\n\n\u2022 Prioritize models that deliver the highest marginal ROI per unit of compute. Focus on architectures and training approaches that achieve strong performance with minimal computational requirements.\n\n\u2022 Opt for smaller, more efficient base models rather than attempting to train large models from scratch. Fine-tune compact architectures like MobileNet or DistilBERT that provide excellent tradeoffs between size, speed and capability.\n\nThe goal is to maximize the impact of limited resources by selecting lean, optimized models that can still achieve the target performance metrics through smart training strategies and transfer learning approaches.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-195007", "created_at": "2026-01-20T20:26:18Z"}}
{"id": "20260121-001417-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 46, "completion_tokens": 22, "latency_ms": 54367.29192733765, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001417", "created_at": "2026-01-21T00:15:11Z"}}
{"id": "20260121-011430-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 46, "completion_tokens": 22, "latency_ms": 56074.32770729065, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:15:26Z"}}
{"id": "20260121-011430-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to the appropriate individuals or teams based on predefined rules and criteria, ensuring optimal allocation of resources and timely completion of work.", "prompt_tokens": 38, "completion_tokens": 32, "latency_ms": 22977.69260406494, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to the appropriate individuals or teams based on predefined rules and criteria, ensuring optimal allocation of resources and timely completion of work.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:15:49Z"}}
{"id": "20260121-011430-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Urgent", "prompt_tokens": 47, "completion_tokens": 4, "latency_ms": 7435.804128646851, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Urgent", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:15:57Z"}}
{"id": "20260121-011430-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here's a Python snippet that loads JSON data from the file 'guild/config/model_routing.json':\n\n```python\nimport json\n\n# Load JSON data from file\nwith open('guild/config/model_routing.json', 'r') as file:\n    model_routing = json.load(file)\n\nprint(model_routing)\n```\n\nExplanation:\n\n1. We import the `json` module to work with JSON data.\n\n2. We use a `with` statement to open the file 'guild/config/model_routing.json' in read mode ('r'). This ensures that the file is properly closed after we're done reading from it.\n\n3. Inside the `with` block, we use `json.load()` to parse the JSON data from the file and assign it to the variable `model_routing`. The `json.load()` function automatically converts the JSON data into a Python dictionary or list, depending on the structure of the JSON.\n\n4. Finally, we print the loaded `model_routing` data to see its contents.\n\nMake sure that the 'guild/config/model_routing.json' file exists in the specified path relative to your Python script. If the file is located elsewhere, you need to provide the correct path to the file.\n\nThis code snippet assumes that the JSON data in the file is valid and can be successfully", "prompt_tokens": 39, "completion_tokens": 256, "latency_ms": 153171.1070537567, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here's a Python snippet that loads JSON data from the file 'guild/config/model_routing.json':\n\n```python\nimport json\n\n# Load JSON data from file\nwith open('guild/config/model_routing.json', 'r') as file:\n    model_routing = json.load(file)\n\nprint(model_routing)\n```\n\nExplanation:\n\n1. We import the `json` module to work with JSON data.\n\n2. We use a `with` statement to open the file 'guild/config/model_routing.json' in read mode ('r'). This ensures that the file is properly closed after we're done reading from it.\n\n3. Inside the `with` block, we use `json.load()` to parse the JSON data from the file and assign it to the variable `model_routing`. The `json.load()` function automatically converts the JSON data into a Python dictionary or list, depending on the structure of the JSON.\n\n4. Finally, we print the loaded `model_routing` data to see its contents.\n\nMake sure that the 'guild/config/model_routing.json' file exists in the specified path relative to your Python script. If the file is located elsewhere, you need to provide the correct path to the file.\n\nThis code snippet assumes that the JSON data in the file is valid and can be successfully", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:18:31Z"}}
{"id": "20260121-011430-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"task_id\": \"T-100\", \"status\": \"queued\"}", "prompt_tokens": 40, "completion_tokens": 16, "latency_ms": 12277.03332901001, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"task_id\": \"T-100\", \"status\": \"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:18:43Z"}}
{"id": "20260121-011430-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here's the bash command to run `scripts/eval_lmstudio_models.py` against all models on `http://127.0.0.1:1234`:\n\n```bash\npython scripts/eval_lmstudio_models.py --model_server http://127.0.0.1:1234 --all_models\n```\n\nThis command assumes that:\n- The `scripts/eval_lmstudio_models.py` script is located in the current directory or a directory specified in your Python path.\n- The model server is running and accessible at `http://127.0.0.1:1234`.\n- The `--all_models` flag is supported by the `scripts/eval_lmstudio_models.py` script to evaluate all available models on the server.\n\nMake sure you have the necessary dependencies installed and the required environment variables set up before running this command.", "prompt_tokens": 54, "completion_tokens": 174, "latency_ms": 103946.69485092163, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here's the bash command to run `scripts/eval_lmstudio_models.py` against all models on `http://127.0.0.1:1234`:\n\n```bash\npython scripts/eval_lmstudio_models.py --model_server http://127.0.0.1:1234 --all_models\n```\n\nThis command assumes that:\n- The `scripts/eval_lmstudio_models.py` script is located in the current directory or a directory specified in your Python path.\n- The model server is running and accessible at `http://127.0.0.1:1234`.\n- The `--all_models` flag is supported by the `scripts/eval_lmstudio_models.py` script to evaluate all available models on the server.\n\nMake sure you have the necessary dependencies installed and the required environment variables set up before running this command.", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:20:27Z"}}
{"id": "20260121-011430-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "lfm2.5-1.2b", "prompt_tokens": 60, "completion_tokens": 11, "latency_ms": 8529.2387008667, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:20:36Z"}}
{"id": "20260121-011430-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here are two key principles for selecting models in resource-constrained scenarios:\n\n\u2022 Prioritize models that deliver the most value per unit cost. Analyze which models have the strongest ROI based on their expected impact vs computational requirements, data needs, and serving costs. Favor high-impact, efficient architectures.\n\n\u2022 Optimize for flexibility and future-proofing within budget constraints. Choose models that enable iterative improvements - ones where you can start with a smaller/cheaper variant but scale up as resources allow. Factor in total-cost-of-ownership including training, tuning, deployment and maintenance.", "prompt_tokens": 40, "completion_tokens": 115, "latency_ms": 85371.61922454834, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here are two key principles for selecting models in resource-constrained scenarios:\n\n\u2022 Prioritize models that deliver the most value per unit cost. Analyze which models have the strongest ROI based on their expected impact vs computational requirements, data needs, and serving costs. Favor high-impact, efficient architectures.\n\n\u2022 Optimize for flexibility and future-proofing within budget constraints. Choose models that enable iterative improvements - ones where you can start with a smaller/cheaper variant but scale up as resources allow. Factor in total-cost-of-ownership including training, tuning, deployment and maintenance.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:22:02Z"}}
{"id": "20260121-011430-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 46, "completion_tokens": 22, "latency_ms": 23848.480224609375, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:22:26Z"}}
{"id": "20260121-011430-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to the appropriate team members or departments based on predefined rules and criteria, ensuring timely completion and optimal resource allocation.", "prompt_tokens": 38, "completion_tokens": 30, "latency_ms": 24955.317497253418, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to the appropriate team members or departments based on predefined rules and criteria, ensuring timely completion and optimal resource allocation.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:22:51Z"}}
{"id": "20260121-011430-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Urgent", "prompt_tokens": 47, "completion_tokens": 4, "latency_ms": 8756.41417503357, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Urgent", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:23:00Z"}}
{"id": "20260121-011430-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here's a Python snippet that loads JSON data from the file \"guild/config/model_routing.json\":\n\n```python\nimport json\n\n# Load JSON data from file\nwith open(\"guild/config/model_routing.json\", \"r\") as file:\n    model_routing = json.load(file)\n\nprint(model_routing)\n```\n\nThis code does the following:\n\n1. We import the `json` module to work with JSON data.\n\n2. We use a `with` statement to open the file \"guild/config/model_routing.json\" in read mode (\"r\"). This ensures that the file is properly closed after we're done reading from it.\n\n3. Inside the `with` block, we use `json.load()` to parse the contents of the file and load the JSON data into a Python object called `model_routing`. The resulting `model_routing` variable will be a dictionary if the top-level element in the JSON is an object, or a list if the top-level element is an array.\n\n4. Finally, we print the loaded `model_routing` data to see its contents.\n\nMake sure that the file path \"guild/config/model_routing.json\" correctly points to the location of your JSON file relative to the Python script's execution directory.\n\nNote: This code assumes that the JSON file exists and", "prompt_tokens": 39, "completion_tokens": 256, "latency_ms": 154255.48195838928, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here's a Python snippet that loads JSON data from the file \"guild/config/model_routing.json\":\n\n```python\nimport json\n\n# Load JSON data from file\nwith open(\"guild/config/model_routing.json\", \"r\") as file:\n    model_routing = json.load(file)\n\nprint(model_routing)\n```\n\nThis code does the following:\n\n1. We import the `json` module to work with JSON data.\n\n2. We use a `with` statement to open the file \"guild/config/model_routing.json\" in read mode (\"r\"). This ensures that the file is properly closed after we're done reading from it.\n\n3. Inside the `with` block, we use `json.load()` to parse the contents of the file and load the JSON data into a Python object called `model_routing`. The resulting `model_routing` variable will be a dictionary if the top-level element in the JSON is an object, or a list if the top-level element is an array.\n\n4. Finally, we print the loaded `model_routing` data to see its contents.\n\nMake sure that the file path \"guild/config/model_routing.json\" correctly points to the location of your JSON file relative to the Python script's execution directory.\n\nNote: This code assumes that the JSON file exists and", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:25:35Z"}}
{"id": "20260121-011430-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"task_id\": \"T-100\", \"status\": \"queued\"}", "prompt_tokens": 40, "completion_tokens": 16, "latency_ms": 12529.305458068848, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"task_id\": \"T-100\", \"status\": \"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:25:47Z"}}
{"id": "20260121-011430-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here's the bash command to run `scripts/eval_lmstudio_models.py` against all models on `http://127.0.0.1:1234`:\n\n```bash\npython scripts/eval_lmstudio_models.py --model_server http://127.0.0.1:1234 --all_models\n```\n\nExplanation:\n- `python` is used to execute the Python script.\n- `scripts/eval_lmstudio_models.py` is the path to the evaluation script you want to run.\n- `--model_server http://127.0.0.1:1234` specifies the URL of the model server where the models are hosted.\n- `--all_models` is an argument that tells the script to evaluate all available models on the specified model server.\n\nMake sure you have the necessary dependencies installed and the script `scripts/eval_lmstudio_models.py` is accessible from your current directory or provide the appropriate path to the script.", "prompt_tokens": 54, "completion_tokens": 194, "latency_ms": 120875.65779685974, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here's the bash command to run `scripts/eval_lmstudio_models.py` against all models on `http://127.0.0.1:1234`:\n\n```bash\npython scripts/eval_lmstudio_models.py --model_server http://127.0.0.1:1234 --all_models\n```\n\nExplanation:\n- `python` is used to execute the Python script.\n- `scripts/eval_lmstudio_models.py` is the path to the evaluation script you want to run.\n- `--model_server http://127.0.0.1:1234` specifies the URL of the model server where the models are hosted.\n- `--all_models` is an argument that tells the script to evaluate all available models on the specified model server.\n\nMake sure you have the necessary dependencies installed and the script `scripts/eval_lmstudio_models.py` is accessible from your current directory or provide the appropriate path to the script.", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:27:48Z"}}
{"id": "20260121-011430-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "lfm2.5-1.2b", "prompt_tokens": 60, "completion_tokens": 11, "latency_ms": 8504.16874885559, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:27:57Z"}}
{"id": "20260121-011430-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here are two key principles for model selection under resource constraints:\n\n- Prioritize models that achieve the best performance-to-cost ratio on your specific task and dataset. Evaluate options based on metrics like accuracy per training FLOP, inference speed, or memory footprint.\n\n- Favor smaller, more efficient architectures unless a larger model provides significant gains in your most important metric. Consider techniques like quantization, pruning, or distillation to reduce resource requirements of high-performing models.", "prompt_tokens": 40, "completion_tokens": 93, "latency_ms": 55918.16020011902, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here are two key principles for model selection under resource constraints:\n\n- Prioritize models that achieve the best performance-to-cost ratio on your specific task and dataset. Evaluate options based on metrics like accuracy per training FLOP, inference speed, or memory footprint.\n\n- Favor smaller, more efficient architectures unless a larger model provides significant gains in your most important metric. Consider techniques like quantization, pruning, or distillation to reduce resource requirements of high-performing models.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:28:53Z"}}
{"id": "20260121-011430-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 46, "completion_tokens": 22, "latency_ms": 17798.585653305054, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:29:11Z"}}
{"id": "20260121-011430-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to the appropriate individuals or teams based on predefined rules and criteria, ensuring optimal allocation of resources and timely completion of work.", "prompt_tokens": 38, "completion_tokens": 32, "latency_ms": 20278.935194015503, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to the appropriate individuals or teams based on predefined rules and criteria, ensuring optimal allocation of resources and timely completion of work.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:29:32Z"}}
{"id": "20260121-011430-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Urgent", "prompt_tokens": 47, "completion_tokens": 4, "latency_ms": 8966.47334098816, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Urgent", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:29:41Z"}}
{"id": "20260121-011430-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here's a Python snippet that loads JSON data from the file 'guild/config/model_routing.json':\n\n```python\nimport json\n\n# Load JSON data from file\nwith open('guild/config/model_routing.json', 'r') as file:\n    model_routing = json.load(file)\n\n# Print the loaded JSON data\nprint(model_routing)\n```\n\nExplanation:\n\n1. We import the `json` module to work with JSON data.\n\n2. We use a `with` statement to open the file 'guild/config/model_routing.json' in read mode ('r'). This ensures that the file is properly closed after we're done reading from it.\n\n3. Inside the `with` block, we use `json.load()` to parse the JSON data from the file and assign it to the variable `model_routing`. The `json.load()` function reads the JSON data from the file object and converts it into a Python dictionary or list, depending on the structure of the JSON.\n\n4. Finally, we print the loaded JSON data using `print(model_routing)` to display its contents.\n\nMake sure that the file 'guild/config/model_routing.json' exists in the specified path relative to your Python script. If the file is located elsewhere, you need to provide the correct path to the file.\n\nThis", "prompt_tokens": 39, "completion_tokens": 256, "latency_ms": 150816.89834594727, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here's a Python snippet that loads JSON data from the file 'guild/config/model_routing.json':\n\n```python\nimport json\n\n# Load JSON data from file\nwith open('guild/config/model_routing.json', 'r') as file:\n    model_routing = json.load(file)\n\n# Print the loaded JSON data\nprint(model_routing)\n```\n\nExplanation:\n\n1. We import the `json` module to work with JSON data.\n\n2. We use a `with` statement to open the file 'guild/config/model_routing.json' in read mode ('r'). This ensures that the file is properly closed after we're done reading from it.\n\n3. Inside the `with` block, we use `json.load()` to parse the JSON data from the file and assign it to the variable `model_routing`. The `json.load()` function reads the JSON data from the file object and converts it into a Python dictionary or list, depending on the structure of the JSON.\n\n4. Finally, we print the loaded JSON data using `print(model_routing)` to display its contents.\n\nMake sure that the file 'guild/config/model_routing.json' exists in the specified path relative to your Python script. If the file is located elsewhere, you need to provide the correct path to the file.\n\nThis", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:32:12Z"}}
{"id": "20260121-011430-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"task_id\": \"T-100\", \"status\": \"queued\"}", "prompt_tokens": 40, "completion_tokens": 16, "latency_ms": 13303.960800170898, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"task_id\": \"T-100\", \"status\": \"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:32:26Z"}}
{"id": "20260121-011430-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here's the bash command to run `scripts/eval_lmstudio_models.py` against all models on `http://127.0.0.1:1234`:\n\n```bash\npython scripts/eval_lmstudio_models.py --model_server http://127.0.0.1:1234 --all_models\n```\n\nExplanation:\n- `python` is used to execute the Python script.\n- `scripts/eval_lmstudio_models.py` is the path to the evaluation script you want to run.\n- `--model_server http://127.0.0.1:1234` specifies the URL of the model server where the models are hosted.\n- `--all_models` is an argument that tells the script to evaluate all available models on the specified model server.\n\nMake sure you have the necessary dependencies installed and the script `scripts/eval_lmstudio_models.py` is accessible from your current directory or provide the appropriate path to the script.", "prompt_tokens": 54, "completion_tokens": 194, "latency_ms": 112001.5242099762, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here's the bash command to run `scripts/eval_lmstudio_models.py` against all models on `http://127.0.0.1:1234`:\n\n```bash\npython scripts/eval_lmstudio_models.py --model_server http://127.0.0.1:1234 --all_models\n```\n\nExplanation:\n- `python` is used to execute the Python script.\n- `scripts/eval_lmstudio_models.py` is the path to the evaluation script you want to run.\n- `--model_server http://127.0.0.1:1234` specifies the URL of the model server where the models are hosted.\n- `--all_models` is an argument that tells the script to evaluate all available models on the specified model server.\n\nMake sure you have the necessary dependencies installed and the script `scripts/eval_lmstudio_models.py` is accessible from your current directory or provide the appropriate path to the script.", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:34:18Z"}}
{"id": "20260121-011430-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "lfm2.5-1.2b", "prompt_tokens": 60, "completion_tokens": 11, "latency_ms": 9343.720197677612, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:34:28Z"}}
{"id": "20260121-011430-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here are two key principles for selecting models in resource-constrained scenarios:\n\n\u2022 Prioritize models that deliver the most value relative to their cost and complexity. Focus on \"good enough\" solutions that address core needs rather than over-engineered approaches.\n\n\u2022 Favor simpler, more interpretable models when possible, as they tend to be cheaper to develop, deploy and maintain. Only use complex models if the incremental performance gains justify the additional resource requirements.", "prompt_tokens": 40, "completion_tokens": 88, "latency_ms": 52834.521532058716, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here are two key principles for selecting models in resource-constrained scenarios:\n\n\u2022 Prioritize models that deliver the most value relative to their cost and complexity. Focus on \"good enough\" solutions that address core needs rather than over-engineered approaches.\n\n\u2022 Favor simpler, more interpretable models when possible, as they tend to be cheaper to develop, deploy and maintain. Only use complex models if the incremental performance gains justify the additional resource requirements.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:35:21Z"}}
{"id": "20260121-011430-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 46, "completion_tokens": 22, "latency_ms": 17726.941347122192, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:35:39Z"}}
{"id": "20260121-011430-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to the appropriate team members or departments based on predefined rules and criteria, ensuring timely completion and optimal resource allocation.", "prompt_tokens": 38, "completion_tokens": 30, "latency_ms": 20713.664293289185, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to the appropriate team members or departments based on predefined rules and criteria, ensuring timely completion and optimal resource allocation.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:36:00Z"}}
{"id": "20260121-011430-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Urgent", "prompt_tokens": 47, "completion_tokens": 4, "latency_ms": 7449.512720108032, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Urgent", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:36:07Z"}}
{"id": "20260121-011430-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here's a Python snippet that loads JSON data from the file 'guild/config/model_routing.json':\n\n```python\nimport json\n\n# Load JSON data from file\nwith open('guild/config/model_routing.json', 'r') as file:\n    model_routing = json.load(file)\n\nprint(model_routing)\n```\n\nExplanation:\n\n1. We import the `json` module to work with JSON data.\n\n2. We use a `with` statement to open the file 'guild/config/model_routing.json' in read mode ('r'). This ensures that the file is properly closed after we're done reading from it.\n\n3. Inside the `with` block, we use `json.load()` to parse the JSON data from the file and assign it to the variable `model_routing`. The `json.load()` function reads the JSON data from the file object and returns a Python dictionary or list, depending on the structure of the JSON data.\n\n4. Finally, we print the loaded JSON data using `print(model_routing)` to display its contents.\n\nMake sure that the file 'guild/config/model_routing.json' exists in the specified path relative to your Python script. If the file is located elsewhere, you'll need to provide the correct path to the file.\n\nThis snippet assumes that the JSON data in", "prompt_tokens": 39, "completion_tokens": 256, "latency_ms": 153696.97380065918, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here's a Python snippet that loads JSON data from the file 'guild/config/model_routing.json':\n\n```python\nimport json\n\n# Load JSON data from file\nwith open('guild/config/model_routing.json', 'r') as file:\n    model_routing = json.load(file)\n\nprint(model_routing)\n```\n\nExplanation:\n\n1. We import the `json` module to work with JSON data.\n\n2. We use a `with` statement to open the file 'guild/config/model_routing.json' in read mode ('r'). This ensures that the file is properly closed after we're done reading from it.\n\n3. Inside the `with` block, we use `json.load()` to parse the JSON data from the file and assign it to the variable `model_routing`. The `json.load()` function reads the JSON data from the file object and returns a Python dictionary or list, depending on the structure of the JSON data.\n\n4. Finally, we print the loaded JSON data using `print(model_routing)` to display its contents.\n\nMake sure that the file 'guild/config/model_routing.json' exists in the specified path relative to your Python script. If the file is located elsewhere, you'll need to provide the correct path to the file.\n\nThis snippet assumes that the JSON data in", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:38:41Z"}}
{"id": "20260121-011430-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"task_id\": \"T-100\", \"status\": \"queued\"}", "prompt_tokens": 40, "completion_tokens": 16, "latency_ms": 14024.188041687012, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"task_id\": \"T-100\", \"status\": \"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:38:56Z"}}
{"id": "20260121-011430-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here's the bash command to run `scripts/eval_lmstudio_models.py` against all models on `http://127.0.0.1:1234`:\n\n```bash\npython scripts/eval_lmstudio_models.py --model_server http://127.0.0.1:1234 --all_models\n```\n\nThis command assumes that:\n- The `scripts/eval_lmstudio_models.py` script is located in the current directory.\n- The model server is running on `http://127.0.0.1:1234`.\n- The `--all_models` flag is used to evaluate all available models on the specified model server.\n\nMake sure you have the necessary dependencies installed and the appropriate permissions to run the script.", "prompt_tokens": 54, "completion_tokens": 151, "latency_ms": 92488.42692375183, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here's the bash command to run `scripts/eval_lmstudio_models.py` against all models on `http://127.0.0.1:1234`:\n\n```bash\npython scripts/eval_lmstudio_models.py --model_server http://127.0.0.1:1234 --all_models\n```\n\nThis command assumes that:\n- The `scripts/eval_lmstudio_models.py` script is located in the current directory.\n- The model server is running on `http://127.0.0.1:1234`.\n- The `--all_models` flag is used to evaluate all available models on the specified model server.\n\nMake sure you have the necessary dependencies installed and the appropriate permissions to run the script.", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:40:28Z"}}
{"id": "20260121-011430-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "lfm2.5-1.2b", "prompt_tokens": 60, "completion_tokens": 11, "latency_ms": 10192.812442779541, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:40:39Z"}}
{"id": "20260121-011430-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here are two key principles for model selection under resource constraints:\n\n- Prioritize models that deliver the highest marginal ROI per unit of compute. Focus on architectures and training approaches that achieve strong performance with efficient parameter usage, such as distillation, pruning, quantization, and sparse models.\n\n- Favor models that enable transfer learning to maximize code reuse across tasks. Selecting a versatile base model that can be efficiently adapted to multiple use cases reduces the need to train many specialized models from scratch.", "prompt_tokens": 40, "completion_tokens": 97, "latency_ms": 63296.80156707764, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here are two key principles for model selection under resource constraints:\n\n- Prioritize models that deliver the highest marginal ROI per unit of compute. Focus on architectures and training approaches that achieve strong performance with efficient parameter usage, such as distillation, pruning, quantization, and sparse models.\n\n- Favor models that enable transfer learning to maximize code reuse across tasks. Selecting a versatile base model that can be efficiently adapted to multiple use cases reduces the need to train many specialized models from scratch.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:41:42Z"}}
{"id": "20260121-011430-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 46, "completion_tokens": 22, "latency_ms": 18339.54644203186, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:42:01Z"}}
{"id": "20260121-011430-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to appropriate team members based on skills, availability and workload for optimal productivity and timely completion.", "prompt_tokens": 38, "completion_tokens": 26, "latency_ms": 20963.42134475708, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to appropriate team members based on skills, availability and workload for optimal productivity and timely completion.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:42:22Z"}}
{"id": "20260121-011430-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Urgent", "prompt_tokens": 47, "completion_tokens": 4, "latency_ms": 7604.6462059021, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Urgent", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:42:30Z"}}
{"id": "20260121-011430-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here's a Python snippet that loads JSON data from the file 'guild/config/model_routing.json':\n\n```python\nimport json\n\n# Load JSON data from file\nwith open('guild/config/model_routing.json', 'r') as file:\n    model_routing = json.load(file)\n\nprint(model_routing)\n```\n\nThis code uses the `json` module to load the contents of the specified JSON file. The `open()` function is used to open the file in read mode ('r'). The `json.load()` method reads the JSON data from the file and parses it into a Python dictionary or list, depending on the structure of the JSON.\n\nThe loaded JSON data is stored in the `model_routing` variable, which you can then access and manipulate as needed. Finally, the code prints the contents of `model_routing` to display the loaded JSON data.\n\nMake sure that the file path 'guild/config/model_routing.json' correctly points to the location of your JSON file relative to the script's execution directory.", "prompt_tokens": 39, "completion_tokens": 201, "latency_ms": 122100.41737556458, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here's a Python snippet that loads JSON data from the file 'guild/config/model_routing.json':\n\n```python\nimport json\n\n# Load JSON data from file\nwith open('guild/config/model_routing.json', 'r') as file:\n    model_routing = json.load(file)\n\nprint(model_routing)\n```\n\nThis code uses the `json` module to load the contents of the specified JSON file. The `open()` function is used to open the file in read mode ('r'). The `json.load()` method reads the JSON data from the file and parses it into a Python dictionary or list, depending on the structure of the JSON.\n\nThe loaded JSON data is stored in the `model_routing` variable, which you can then access and manipulate as needed. Finally, the code prints the contents of `model_routing` to display the loaded JSON data.\n\nMake sure that the file path 'guild/config/model_routing.json' correctly points to the location of your JSON file relative to the script's execution directory.", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:44:32Z"}}
{"id": "20260121-011430-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"task_id\": \"T-100\", \"status\": \"queued\"}", "prompt_tokens": 40, "completion_tokens": 16, "latency_ms": 14309.879541397095, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"task_id\": \"T-100\", \"status\": \"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:44:47Z"}}
{"id": "20260121-011430-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here is the bash command to run eval_lmstudio_models.py against all models on http://127.0.0.1:1234:\n\npython3 scripts/eval_lmstudio_models.py --model_server_url=http://127.0.0.1:1234 --all_models\n\nThis assumes:\n- The script is located in the \"scripts\" directory \n- You want to evaluate all available models on the server\n- Python 3 is used to run the script\n\nThe key flags are:\n--model_server_url to specify the model server URL \n--all_models to evaluate all models instead of a specific one\n\nLet me know if you have any other questions!", "prompt_tokens": 54, "completion_tokens": 136, "latency_ms": 92739.02153968811, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here is the bash command to run eval_lmstudio_models.py against all models on http://127.0.0.1:1234:\n\npython3 scripts/eval_lmstudio_models.py --model_server_url=http://127.0.0.1:1234 --all_models\n\nThis assumes:\n- The script is located in the \"scripts\" directory \n- You want to evaluate all available models on the server\n- Python 3 is used to run the script\n\nThe key flags are:\n--model_server_url to specify the model server URL \n--all_models to evaluate all models instead of a specific one\n\nLet me know if you have any other questions!", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:46:20Z"}}
{"id": "20260121-011430-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "lfm2.5-1.2b", "prompt_tokens": 60, "completion_tokens": 11, "latency_ms": 8889.863014221191, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:46:29Z"}}
{"id": "20260121-011430-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here are two key principles for selecting models when compute or data is limited:\n\n- Prioritize smaller, more efficient architectures like TinyRAM, Llama 2, or state-space models that achieve good performance with fewer parameters and less training time\n- Focus on models that have already demonstrated strong capabilities in the specific domains most critical to your product roadmap", "prompt_tokens": 40, "completion_tokens": 69, "latency_ms": 47355.093240737915, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here are two key principles for selecting models when compute or data is limited:\n\n- Prioritize smaller, more efficient architectures like TinyRAM, Llama 2, or state-space models that achieve good performance with fewer parameters and less training time\n- Focus on models that have already demonstrated strong capabilities in the specific domains most critical to your product roadmap", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:47:17Z"}}
{"id": "20260121-011430-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 46, "completion_tokens": 22, "latency_ms": 19231.682062149048, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:47:36Z"}}
{"id": "20260121-011430-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to the appropriate team members or departments based on predefined rules and criteria.", "prompt_tokens": 38, "completion_tokens": 22, "latency_ms": 18471.344470977783, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to the appropriate team members or departments based on predefined rules and criteria.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:47:55Z"}}
{"id": "20260121-011430-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Urgent", "prompt_tokens": 47, "completion_tokens": 4, "latency_ms": 7823.4992027282715, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Urgent", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:48:03Z"}}
{"id": "20260121-011430-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here's a Python snippet that loads JSON data from the file 'guild/config/model_routing.json':\n\n```python\nimport json\n\n# Load the JSON data from the file\nwith open('guild/config/model_routing.json', 'r') as file:\n    model_routing = json.load(file)\n\n# Print the loaded JSON data\nprint(model_routing)\n```\n\nExplanation:\n\n1. We import the `json` module to work with JSON data.\n\n2. We use a `with` statement to open the file 'guild/config/model_routing.json' in read mode ('r'). This ensures that the file is properly closed after we're done reading from it.\n\n3. Inside the `with` block, we use `json.load()` to load the contents of the file into a Python object called `model_routing`. The `json.load()` function automatically parses the JSON data and converts it into a corresponding Python data structure (e.g., dictionaries, lists).\n\n4. Finally, we print the loaded JSON data using `print(model_routing)`.\n\nMake sure that the file 'guild/config/model_routing.json' exists in the specified path relative to your Python script. If the file is located elsewhere, you'll need to provide the correct path to the file.\n\nThis snippet assumes that the contents of '", "prompt_tokens": 39, "completion_tokens": 256, "latency_ms": 163193.23778152466, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here's a Python snippet that loads JSON data from the file 'guild/config/model_routing.json':\n\n```python\nimport json\n\n# Load the JSON data from the file\nwith open('guild/config/model_routing.json', 'r') as file:\n    model_routing = json.load(file)\n\n# Print the loaded JSON data\nprint(model_routing)\n```\n\nExplanation:\n\n1. We import the `json` module to work with JSON data.\n\n2. We use a `with` statement to open the file 'guild/config/model_routing.json' in read mode ('r'). This ensures that the file is properly closed after we're done reading from it.\n\n3. Inside the `with` block, we use `json.load()` to load the contents of the file into a Python object called `model_routing`. The `json.load()` function automatically parses the JSON data and converts it into a corresponding Python data structure (e.g., dictionaries, lists).\n\n4. Finally, we print the loaded JSON data using `print(model_routing)`.\n\nMake sure that the file 'guild/config/model_routing.json' exists in the specified path relative to your Python script. If the file is located elsewhere, you'll need to provide the correct path to the file.\n\nThis snippet assumes that the contents of '", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:50:46Z"}}
{"id": "20260121-011430-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"task_id\": \"T-100\", \"status\": \"queued\"}", "prompt_tokens": 40, "completion_tokens": 16, "latency_ms": 14668.28989982605, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"task_id\": \"T-100\", \"status\": \"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:51:01Z"}}
{"id": "20260121-011430-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here's the bash command to run `scripts/eval_lmstudio_models.py` against all models on `http://127.0.0.1:1234`:\n\n```bash\npython scripts/eval_lmstudio_models.py --model_server http://127.0.0.1:1234 --all_models\n```\n\nExplanation:\n- `python` is used to execute the Python script.\n- `scripts/eval_lmstudio_models.py` specifies the path to the evaluation script.\n- `--model_server http://127.0.0.1:1234` sets the model server URL to `http://127.0.0.1:1234`.\n- `--all_models` is an argument that tells the script to evaluate all available models on the specified model server.\n\nMake sure you have the necessary dependencies installed and the evaluation script (`scripts/eval_lmstudio_models.py`) is accessible from your current directory or provide the appropriate path to the script.", "prompt_tokens": 54, "completion_tokens": 198, "latency_ms": 142873.21543693542, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here's the bash command to run `scripts/eval_lmstudio_models.py` against all models on `http://127.0.0.1:1234`:\n\n```bash\npython scripts/eval_lmstudio_models.py --model_server http://127.0.0.1:1234 --all_models\n```\n\nExplanation:\n- `python` is used to execute the Python script.\n- `scripts/eval_lmstudio_models.py` specifies the path to the evaluation script.\n- `--model_server http://127.0.0.1:1234` sets the model server URL to `http://127.0.0.1:1234`.\n- `--all_models` is an argument that tells the script to evaluate all available models on the specified model server.\n\nMake sure you have the necessary dependencies installed and the evaluation script (`scripts/eval_lmstudio_models.py`) is accessible from your current directory or provide the appropriate path to the script.", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:53:24Z"}}
{"id": "20260121-011430-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "lfm2.5-1.2b", "prompt_tokens": 60, "completion_tokens": 11, "latency_ms": 10860.50271987915, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:53:36Z"}}
{"id": "20260121-011430-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Here are two key principles for selecting models in resource-constrained scenarios:\n\n\u2022 Prioritize models that deliver the most value per unit of compute. Favor architectures known to be parameter-efficient and sample-efficient, such as transformers over RNNs or linear models. Quantify expected ROI by estimating (model_quality * business_value) / (training_cost + inference_cost).\n\n\u2022 Opt for smaller, well-established model families first. Start with base or small variants from reputable libraries before scaling up. Leverage proven architectures rather than experimental approaches that may require more tuning. Only pursue larger models if rigorous analysis shows diminishing returns from smaller options.", "prompt_tokens": 40, "completion_tokens": 124, "latency_ms": 75954.36143875122, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Here are two key principles for selecting models in resource-constrained scenarios:\n\n\u2022 Prioritize models that deliver the most value per unit of compute. Favor architectures known to be parameter-efficient and sample-efficient, such as transformers over RNNs or linear models. Quantify expected ROI by estimating (model_quality * business_value) / (training_cost + inference_cost).\n\n\u2022 Opt for smaller, well-established model families first. Start with base or small variants from reputable libraries before scaling up. Leverage proven architectures rather than experimental approaches that may require more tuning. Only pursue larger models if rigorous analysis shows diminishing returns from smaller options.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:54:52Z"}}
{"id": "20260121-011430-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 46, "completion_tokens": 22, "latency_ms": 18119.638442993164, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "{\"category\": \"code\", \"models\": [\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:55:10Z"}}
{"id": "20260121-011430-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to the appropriate team members or departments based on predefined rules and criteria, ensuring timely completion and optimal resource utilization.", "prompt_tokens": 38, "completion_tokens": 30, "latency_ms": 19543.238162994385, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "A task routing system efficiently directs tasks to the appropriate team members or departments based on predefined rules and criteria, ensuring timely completion and optimal resource utilization.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:55:30Z"}}
{"id": "20260121-011430-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "nousresearch/hermes-4-70b", "response": "Urgent", "prompt_tokens": 47, "completion_tokens": 4, "latency_ms": 8869.030475616455, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "nousresearch/hermes-4-70b", "response": "Urgent", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-011430", "created_at": "2026-01-21T01:55:39Z"}}
