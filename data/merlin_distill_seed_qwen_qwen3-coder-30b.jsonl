{"id": "20260120-202626-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 22435.66131591797, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:26:48Z"}}
{"id": "20260120-202626-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "A task routing system automatically directs work assignments to the most appropriate team members or departments based on criteria like skills, workload, priority, or expertise to optimize efficiency and ensure tasks are handled by the right people.", "prompt_tokens": 22, "completion_tokens": 42, "latency_ms": 1834.397554397583, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "A task routing system automatically directs work assignments to the most appropriate team members or departments based on criteria like skills, workload, priority, or expertise to optimize efficiency and ensure tasks are handled by the right people.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:26:50Z"}}
{"id": "20260120-202626-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "Critical", "prompt_tokens": 31, "completion_tokens": 2, "latency_ms": 322.7648735046387, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "Critical", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:26:51Z"}}
{"id": "20260120-202626-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "Here's a Python snippet that loads JSON from 'guild/config/model_routing.json':\n\n```python\nimport json\n\ntry:\n    with open('guild/config/model_routing.json', 'r') as file:\n        model_routing = json.load(file)\n    print(\"JSON loaded successfully:\")\n    print(model_routing)\nexcept FileNotFoundError:\n    print(\"Error: 'guild/config/model_routing.json' not found\")\nexcept json.JSONDecodeError as e:\n    print(f\"Error decoding JSON: {e}\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\n```\n\nThis snippet includes error handling for common issues like:\n- File not found\n- Invalid JSON format\n- Other unexpected errors\n\nIf you want a simpler version without error handling:\n\n```python\nimport json\n\nwith open('guild/config/model_routing.json', 'r') as file:\n    model_routing = json.load(file)\n```\n\nThe `model_routing` variable will contain the parsed JSON data as a Python dictionary or list, depending on the JSON structure.", "prompt_tokens": 23, "completion_tokens": 206, "latency_ms": 12020.708799362183, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "Here's a Python snippet that loads JSON from 'guild/config/model_routing.json':\n\n```python\nimport json\n\ntry:\n    with open('guild/config/model_routing.json', 'r') as file:\n        model_routing = json.load(file)\n    print(\"JSON loaded successfully:\")\n    print(model_routing)\nexcept FileNotFoundError:\n    print(\"Error: 'guild/config/model_routing.json' not found\")\nexcept json.JSONDecodeError as e:\n    print(f\"Error decoding JSON: {e}\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\n```\n\nThis snippet includes error handling for common issues like:\n- File not found\n- Invalid JSON format\n- Other unexpected errors\n\nIf you want a simpler version without error handling:\n\n```python\nimport json\n\nwith open('guild/config/model_routing.json', 'r') as file:\n    model_routing = json.load(file)\n```\n\nThe `model_routing` variable will contain the parsed JSON data as a Python dictionary or list, depending on the JSON structure.", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:27:03Z"}}
{"id": "20260120-202626-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 5129.4684410095215, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:27:09Z"}}
{"id": "20260120-202626-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "Here's a bash command to run the evaluation script against all models on the local LM Studio server:\n\n```bash\n#!/bin/bash\n\n# Get list of all models from LM Studio API and run evaluation script for each\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read model_id; do\n    echo \"Running evaluation for model: $model_id\"\n    python scripts/eval_lmstudio_models.py --model \"$model_id\"\ndone\n```\n\nOr as a one-liner:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | xargs -I {} python scripts/eval_lmstudio_models.py --model {}\n```\n\n**Note:** This assumes:\n1. Your `eval_lmstudio_models.py` script accepts a `--model` parameter\n2. The LM Studio API endpoint returns models in the expected JSON format with `id` field\n3. You have `jq` installed for JSON parsing\n\nIf your script uses a different parameter name (like `--model_id` or `-m`), adjust accordingly. If", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 14394.864320755005, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "Here's a bash command to run the evaluation script against all models on the local LM Studio server:\n\n```bash\n#!/bin/bash\n\n# Get list of all models from LM Studio API and run evaluation script for each\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read model_id; do\n    echo \"Running evaluation for model: $model_id\"\n    python scripts/eval_lmstudio_models.py --model \"$model_id\"\ndone\n```\n\nOr as a one-liner:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | xargs -I {} python scripts/eval_lmstudio_models.py --model {}\n```\n\n**Note:** This assumes:\n1. Your `eval_lmstudio_models.py` script accepts a `--model` parameter\n2. The LM Studio API endpoint returns models in the expected JSON format with `id` field\n3. You have `jq` installed for JSON parsing\n\nIf your script uses a different parameter name (like `--model_id` or `-m`), adjust accordingly. If", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:27:23Z"}}
{"id": "20260120-202626-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 1029.6263694763184, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:27:25Z"}}
{"id": "20260120-202626-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "\u2022 **Prioritize models with the highest potential return on investment** - Focus on projects or opportunities that offer the greatest expected value relative to the resources required, even if they're not the most obvious choices\n\n\u2022 **Choose models that can be scaled efficiently** - Select approaches that can grow or adapt with minimal additional resource costs, rather than opting for solutions that require disproportionate increases in funding or personnel as they expand", "prompt_tokens": 24, "completion_tokens": 82, "latency_ms": 3247.1978664398193, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "\u2022 **Prioritize models with the highest potential return on investment** - Focus on projects or opportunities that offer the greatest expected value relative to the resources required, even if they're not the most obvious choices\n\n\u2022 **Choose models that can be scaled efficiently** - Select approaches that can grow or adapt with minimal additional resource costs, rather than opting for solutions that require disproportionate increases in funding or personnel as they expand", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:27:28Z"}}
{"id": "20260120-202626-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 1120.1469898223877, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:27:29Z"}}
{"id": "20260120-202626-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "A task routing system automatically directs work items to the most appropriate team members or departments based on criteria like expertise, workload, or priority to optimize efficiency and ensure tasks are handled by the right people.", "prompt_tokens": 22, "completion_tokens": 40, "latency_ms": 1837.2302055358887, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "A task routing system automatically directs work items to the most appropriate team members or departments based on criteria like expertise, workload, or priority to optimize efficiency and ensure tasks are handled by the right people.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:27:32Z"}}
{"id": "20260120-202626-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "Critical", "prompt_tokens": 31, "completion_tokens": 2, "latency_ms": 382.9231262207031, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "Critical", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:27:32Z"}}
{"id": "20260120-202626-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "Here's a Python snippet that loads JSON from 'guild/config/model_routing.json':\n\n```python\nimport json\n\ntry:\n    with open('guild/config/model_routing.json', 'r') as file:\n        model_routing = json.load(file)\n    print(\"JSON loaded successfully:\")\n    print(model_routing)\nexcept FileNotFoundError:\n    print(\"Error: 'guild/config/model_routing.json' not found\")\nexcept json.JSONDecodeError as e:\n    print(f\"Error decoding JSON: {e}\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\n```\n\nThis snippet includes error handling for common issues like:\n- File not found\n- Invalid JSON format\n- Other unexpected errors\n\nIf you want a simpler version without error handling:\n\n```python\nimport json\n\nwith open('guild/config/model_routing.json', 'r') as file:\n    model_routing = json.load(file)\n```\n\nThe `model_routing` variable will contain the parsed JSON data as a Python dictionary or list, depending on the JSON structure.", "prompt_tokens": 23, "completion_tokens": 206, "latency_ms": 10853.808879852295, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "Here's a Python snippet that loads JSON from 'guild/config/model_routing.json':\n\n```python\nimport json\n\ntry:\n    with open('guild/config/model_routing.json', 'r') as file:\n        model_routing = json.load(file)\n    print(\"JSON loaded successfully:\")\n    print(model_routing)\nexcept FileNotFoundError:\n    print(\"Error: 'guild/config/model_routing.json' not found\")\nexcept json.JSONDecodeError as e:\n    print(f\"Error decoding JSON: {e}\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\n```\n\nThis snippet includes error handling for common issues like:\n- File not found\n- Invalid JSON format\n- Other unexpected errors\n\nIf you want a simpler version without error handling:\n\n```python\nimport json\n\nwith open('guild/config/model_routing.json', 'r') as file:\n    model_routing = json.load(file)\n```\n\nThe `model_routing` variable will contain the parsed JSON data as a Python dictionary or list, depending on the JSON structure.", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:27:43Z"}}
{"id": "20260120-202626-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 1122.8821277618408, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:27:45Z"}}
{"id": "20260120-202626-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "Here's a bash command to run the evaluation script against all models on the local LM Studio server:\n\n```bash\n#!/bin/bash\n\n# Get list of all models from LM Studio API and run evaluation script for each\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read model_id; do\n    echo \"Running evaluation for model: $model_id\"\n    python scripts/eval_lmstudio_models.py --model \"$model_id\"\ndone\n```\n\nOr as a one-liner:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | xargs -I {} python scripts/eval_lmstudio_models.py --model {}\n```\n\n**Note:** This assumes:\n1. Your `eval_lmstudio_models.py` script accepts a `--model` parameter\n2. The LM Studio API endpoint returns models in the expected JSON format with `id` field\n3. You have `jq` installed for JSON parsing\n\nIf your script uses a different parameter format, you might need to adjust it accordingly. For example, if it expects model", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 12990.174531936646, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "Here's a bash command to run the evaluation script against all models on the local LM Studio server:\n\n```bash\n#!/bin/bash\n\n# Get list of all models from LM Studio API and run evaluation script for each\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read model_id; do\n    echo \"Running evaluation for model: $model_id\"\n    python scripts/eval_lmstudio_models.py --model \"$model_id\"\ndone\n```\n\nOr as a one-liner:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | xargs -I {} python scripts/eval_lmstudio_models.py --model {}\n```\n\n**Note:** This assumes:\n1. Your `eval_lmstudio_models.py` script accepts a `--model` parameter\n2. The LM Studio API endpoint returns models in the expected JSON format with `id` field\n3. You have `jq` installed for JSON parsing\n\nIf your script uses a different parameter format, you might need to adjust it accordingly. For example, if it expects model", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:27:58Z"}}
{"id": "20260120-202626-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 1004.0462017059326, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:27:59Z"}}
{"id": "20260120-202626-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "\u2022 **Prioritize models with the highest potential return on investment** - Focus on projects or opportunities that can generate the most value, revenue, or impact relative to the resources required, even if they're not the most obvious choices.\n\n\u2022 **Choose proven, low-risk models over experimental ones** - Select established approaches or well-tested strategies that have demonstrated success in similar situations, rather than pursuing unproven methods that could waste limited resources without guaranteed outcomes.", "prompt_tokens": 24, "completion_tokens": 91, "latency_ms": 3554.656505584717, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "\u2022 **Prioritize models with the highest potential return on investment** - Focus on projects or opportunities that can generate the most value, revenue, or impact relative to the resources required, even if they're not the most obvious choices.\n\n\u2022 **Choose proven, low-risk models over experimental ones** - Select established approaches or well-tested strategies that have demonstrated success in similar situations, rather than pursuing unproven methods that could waste limited resources without guaranteed outcomes.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:28:03Z"}}
{"id": "20260120-202626-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 1066.3371086120605, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:28:04Z"}}
{"id": "20260120-202626-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "A task routing system automatically directs work assignments to the most appropriate team members or departments based on criteria like expertise, workload, or priority to optimize efficiency and ensure tasks are handled by the right people.", "prompt_tokens": 22, "completion_tokens": 40, "latency_ms": 1839.9758338928223, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "A task routing system automatically directs work assignments to the most appropriate team members or departments based on criteria like expertise, workload, or priority to optimize efficiency and ensure tasks are handled by the right people.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:28:06Z"}}
{"id": "20260120-202626-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "Critical", "prompt_tokens": 31, "completion_tokens": 2, "latency_ms": 413.62619400024414, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "Critical", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:28:07Z"}}
{"id": "20260120-202626-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "Here's a Python snippet that loads JSON from 'guild/config/model_routing.json':\n\n```python\nimport json\n\ntry:\n    with open('guild/config/model_routing.json', 'r') as file:\n        model_routing = json.load(file)\n    print(\"JSON loaded successfully:\")\n    print(model_routing)\nexcept FileNotFoundError:\n    print(\"Error: 'guild/config/model_routing.json' not found\")\nexcept json.JSONDecodeError as e:\n    print(f\"Error decoding JSON: {e}\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\n```\n\nThis snippet includes error handling for common issues like:\n- File not found\n- Invalid JSON format\n- Other unexpected errors\n\nIf you want a simpler version without error handling:\n\n```python\nimport json\n\nwith open('guild/config/model_routing.json', 'r') as file:\n    model_routing = json.load(file)\n```\n\nThe `model_routing` variable will contain the parsed JSON data as a Python dictionary or list, depending on the JSON structure.", "prompt_tokens": 23, "completion_tokens": 206, "latency_ms": 12504.715204238892, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "Here's a Python snippet that loads JSON from 'guild/config/model_routing.json':\n\n```python\nimport json\n\ntry:\n    with open('guild/config/model_routing.json', 'r') as file:\n        model_routing = json.load(file)\n    print(\"JSON loaded successfully:\")\n    print(model_routing)\nexcept FileNotFoundError:\n    print(\"Error: 'guild/config/model_routing.json' not found\")\nexcept json.JSONDecodeError as e:\n    print(f\"Error decoding JSON: {e}\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\n```\n\nThis snippet includes error handling for common issues like:\n- File not found\n- Invalid JSON format\n- Other unexpected errors\n\nIf you want a simpler version without error handling:\n\n```python\nimport json\n\nwith open('guild/config/model_routing.json', 'r') as file:\n    model_routing = json.load(file)\n```\n\nThe `model_routing` variable will contain the parsed JSON data as a Python dictionary or list, depending on the JSON structure.", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:28:20Z"}}
{"id": "20260120-202626-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 1020.9171772003174, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:28:21Z"}}
{"id": "20260120-202626-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "Here's a bash command to run the evaluation script against all models on the local LM Studio server:\n\n```bash\n#!/bin/bash\n\n# Get list of all models from LM Studio API\nmodels=$(curl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id')\n\n# Loop through each model and run evaluation\nfor model in $models; do\n    echo \"Evaluating model: $model\"\n    python scripts/eval_lmstudio_models.py --model \"$model\"\ndone\n```\n\nOr as a one-liner:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | xargs -I {} python scripts/eval_lmstudio_models.py --model {}\n```\n\n**Note:** This assumes:\n1. Your `eval_lmstudio_models.py` script accepts a `--model` argument\n2. You have `jq` installed for JSON parsing\n3. The LM Studio API endpoint returns models in the expected format\n\nIf your script uses a different argument format, you may need to adjust the command accordingly. For example, if it expects model names as", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 20469.199419021606, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "Here's a bash command to run the evaluation script against all models on the local LM Studio server:\n\n```bash\n#!/bin/bash\n\n# Get list of all models from LM Studio API\nmodels=$(curl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id')\n\n# Loop through each model and run evaluation\nfor model in $models; do\n    echo \"Evaluating model: $model\"\n    python scripts/eval_lmstudio_models.py --model \"$model\"\ndone\n```\n\nOr as a one-liner:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | xargs -I {} python scripts/eval_lmstudio_models.py --model {}\n```\n\n**Note:** This assumes:\n1. Your `eval_lmstudio_models.py` script accepts a `--model` argument\n2. You have `jq` installed for JSON parsing\n3. The LM Studio API endpoint returns models in the expected format\n\nIf your script uses a different argument format, you may need to adjust the command accordingly. For example, if it expects model names as", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:28:42Z"}}
{"id": "20260120-202626-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 1195.552110671997, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:28:43Z"}}
{"id": "20260120-202626-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "\u2022 **Prioritize models with the highest potential return on investment** - Focus on projects or opportunities that offer the greatest expected value relative to the resources required, even if they're not the most obvious choices\n\n\u2022 **Choose proven, low-risk models over experimental ones** - Select approaches or solutions that have demonstrated success in similar situations rather than pursuing untested methods that could waste valuable resources if they fail", "prompt_tokens": 24, "completion_tokens": 80, "latency_ms": 4175.434827804565, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "\u2022 **Prioritize models with the highest potential return on investment** - Focus on projects or opportunities that offer the greatest expected value relative to the resources required, even if they're not the most obvious choices\n\n\u2022 **Choose proven, low-risk models over experimental ones** - Select approaches or solutions that have demonstrated success in similar situations rather than pursuing untested methods that could waste valuable resources if they fail", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:28:48Z"}}
{"id": "20260120-202626-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 1401.731014251709, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:28:49Z"}}
{"id": "20260120-202626-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "A task routing system automatically directs work assignments to the most appropriate team members or departments based on criteria like skills, workload, priority, or expertise to optimize efficiency and ensure tasks are handled by the right people.", "prompt_tokens": 22, "completion_tokens": 42, "latency_ms": 2900.2299308776855, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "A task routing system automatically directs work assignments to the most appropriate team members or departments based on criteria like skills, workload, priority, or expertise to optimize efficiency and ensure tasks are handled by the right people.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:28:53Z"}}
{"id": "20260120-202626-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "Critical", "prompt_tokens": 31, "completion_tokens": 2, "latency_ms": 527.1780490875244, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "Critical", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:28:53Z"}}
{"id": "20260120-202626-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "Here's a Python snippet that loads JSON from 'guild/config/model_routing.json':\n\n```python\nimport json\n\ntry:\n    with open('guild/config/model_routing.json', 'r') as file:\n        model_routing = json.load(file)\n    print(\"JSON loaded successfully:\")\n    print(model_routing)\nexcept FileNotFoundError:\n    print(\"Error: 'guild/config/model_routing.json' not found\")\nexcept json.JSONDecodeError as e:\n    print(f\"Error decoding JSON: {e}\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\n```\n\nThis snippet includes error handling for common issues like:\n- File not found\n- Invalid JSON format\n- Other unexpected errors\n\nIf you want a simpler version without error handling:\n\n```python\nimport json\n\nwith open('guild/config/model_routing.json', 'r') as file:\n    model_routing = json.load(file)\n```\n\nThe `model_routing` variable will contain the parsed JSON data as a Python dictionary or list, depending on the JSON structure.", "prompt_tokens": 23, "completion_tokens": 206, "latency_ms": 14672.212362289429, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "Here's a Python snippet that loads JSON from 'guild/config/model_routing.json':\n\n```python\nimport json\n\ntry:\n    with open('guild/config/model_routing.json', 'r') as file:\n        model_routing = json.load(file)\n    print(\"JSON loaded successfully:\")\n    print(model_routing)\nexcept FileNotFoundError:\n    print(\"Error: 'guild/config/model_routing.json' not found\")\nexcept json.JSONDecodeError as e:\n    print(f\"Error decoding JSON: {e}\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\n```\n\nThis snippet includes error handling for common issues like:\n- File not found\n- Invalid JSON format\n- Other unexpected errors\n\nIf you want a simpler version without error handling:\n\n```python\nimport json\n\nwith open('guild/config/model_routing.json', 'r') as file:\n    model_routing = json.load(file)\n```\n\nThe `model_routing` variable will contain the parsed JSON data as a Python dictionary or list, depending on the JSON structure.", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:29:08Z"}}
{"id": "20260120-202626-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 1553.3466339111328, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:29:10Z"}}
{"id": "20260120-202626-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "Here's a bash command to run the evaluation script against all models on the local LM Studio server:\n\n```bash\n#!/bin/bash\n\n# Get list of all models from LM Studio API\nmodels=$(curl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id')\n\n# Loop through each model and run evaluation\nfor model in $models; do\n    echo \"Evaluating model: $model\"\n    python scripts/eval_lmstudio_models.py --model \"$model\"\ndone\n```\n\nOr as a one-liner:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | xargs -I {} python scripts/eval_lmstudio_models.py --model {}\n```\n\n**Note:** This assumes:\n1. Your `eval_lmstudio_models.py` script accepts a `--model` argument\n2. You have `jq` installed for JSON parsing\n3. The LM Studio API endpoint returns models in the expected format\n\nIf your script uses a different argument format, you may need to adjust the command accordingly. For example, if it expects model names as", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 15850.357055664062, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "Here's a bash command to run the evaluation script against all models on the local LM Studio server:\n\n```bash\n#!/bin/bash\n\n# Get list of all models from LM Studio API\nmodels=$(curl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id')\n\n# Loop through each model and run evaluation\nfor model in $models; do\n    echo \"Evaluating model: $model\"\n    python scripts/eval_lmstudio_models.py --model \"$model\"\ndone\n```\n\nOr as a one-liner:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | xargs -I {} python scripts/eval_lmstudio_models.py --model {}\n```\n\n**Note:** This assumes:\n1. Your `eval_lmstudio_models.py` script accepts a `--model` argument\n2. You have `jq` installed for JSON parsing\n3. The LM Studio API endpoint returns models in the expected format\n\nIf your script uses a different argument format, you may need to adjust the command accordingly. For example, if it expects model names as", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:29:26Z"}}
{"id": "20260120-202626-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 1932.02805519104, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:29:28Z"}}
{"id": "20260120-202626-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "\u2022 **Prioritize models with the highest potential return on investment** - Focus on projects or opportunities that offer the greatest expected value relative to the resources required, even if they're not the most obvious choices\n\n\u2022 **Choose models that can be scaled efficiently** - Select approaches that can grow or adapt with minimal additional resource costs, rather than opting for solutions that require disproportionate increases in funding or personnel as they expand", "prompt_tokens": 24, "completion_tokens": 82, "latency_ms": 5510.857582092285, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "\u2022 **Prioritize models with the highest potential return on investment** - Focus on projects or opportunities that offer the greatest expected value relative to the resources required, even if they're not the most obvious choices\n\n\u2022 **Choose models that can be scaled efficiently** - Select approaches that can grow or adapt with minimal additional resource costs, rather than opting for solutions that require disproportionate increases in funding or personnel as they expand", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:29:34Z"}}
{"id": "20260120-202626-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 2372.2403049468994, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:29:37Z"}}
{"id": "20260120-202626-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "A task routing system automatically directs work items to the most appropriate team members or departments based on criteria like expertise, workload, or priority to ensure efficient and effective task completion.", "prompt_tokens": 22, "completion_tokens": 35, "latency_ms": 4240.729570388794, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "A task routing system automatically directs work items to the most appropriate team members or departments based on criteria like expertise, workload, or priority to ensure efficient and effective task completion.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:29:41Z"}}
{"id": "20260120-202626-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "Critical", "prompt_tokens": 31, "completion_tokens": 2, "latency_ms": 1454.9031257629395, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "Critical", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:29:43Z"}}
{"id": "20260120-202626-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "Here's a Python snippet that loads JSON from 'guild/config/model_routing.json':\n\n```python\nimport json\n\ntry:\n    with open('guild/config/model_routing.json', 'r') as file:\n        model_routing = json.load(file)\n    print(\"JSON loaded successfully:\")\n    print(model_routing)\nexcept FileNotFoundError:\n    print(\"Error: 'guild/config/model_routing.json' not found\")\nexcept json.JSONDecodeError as e:\n    print(f\"Error decoding JSON: {e}\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\n```\n\nThis snippet includes error handling for common issues like:\n- File not found\n- Invalid JSON format\n- Other unexpected errors\n\nIf you want a simpler version without error handling:\n\n```python\nimport json\n\nwith open('guild/config/model_routing.json', 'r') as file:\n    model_routing = json.load(file)\n```\n\nThe `model_routing` variable will contain the parsed JSON data as a Python dictionary or list, depending on the JSON structure.", "prompt_tokens": 23, "completion_tokens": 206, "latency_ms": 16173.384666442871, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "Here's a Python snippet that loads JSON from 'guild/config/model_routing.json':\n\n```python\nimport json\n\ntry:\n    with open('guild/config/model_routing.json', 'r') as file:\n        model_routing = json.load(file)\n    print(\"JSON loaded successfully:\")\n    print(model_routing)\nexcept FileNotFoundError:\n    print(\"Error: 'guild/config/model_routing.json' not found\")\nexcept json.JSONDecodeError as e:\n    print(f\"Error decoding JSON: {e}\")\nexcept Exception as e:\n    print(f\"Unexpected error: {e}\")\n```\n\nThis snippet includes error handling for common issues like:\n- File not found\n- Invalid JSON format\n- Other unexpected errors\n\nIf you want a simpler version without error handling:\n\n```python\nimport json\n\nwith open('guild/config/model_routing.json', 'r') as file:\n    model_routing = json.load(file)\n```\n\nThe `model_routing` variable will contain the parsed JSON data as a Python dictionary or list, depending on the JSON structure.", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:30:00Z"}}
{"id": "20260120-202626-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 901.0202884674072, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:30:01Z"}}
{"id": "20260120-202626-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "Here's a bash command to run the evaluation script against all models on the local LM Studio server:\n\n```bash\n#!/bin/bash\n\n# Get list of all models from LM Studio API\nmodels=$(curl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id')\n\n# Loop through each model and run evaluation\nfor model in $models; do\n    echo \"Evaluating model: $model\"\n    python scripts/eval_lmstudio_models.py --model \"$model\"\ndone\n```\n\nOr as a one-liner:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | xargs -I {} python scripts/eval_lmstudio_models.py --model {}\n```\n\n**Note:** This assumes:\n1. Your `eval_lmstudio_models.py` script accepts a `--model` argument\n2. You have `jq` installed for JSON parsing\n3. The LM Studio API endpoint returns models in the expected format\n\nIf your script uses a different argument format, you may need to adjust the command accordingly. For example, if it expects model names as", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 12731.728076934814, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "Here's a bash command to run the evaluation script against all models on the local LM Studio server:\n\n```bash\n#!/bin/bash\n\n# Get list of all models from LM Studio API\nmodels=$(curl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id')\n\n# Loop through each model and run evaluation\nfor model in $models; do\n    echo \"Evaluating model: $model\"\n    python scripts/eval_lmstudio_models.py --model \"$model\"\ndone\n```\n\nOr as a one-liner:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | xargs -I {} python scripts/eval_lmstudio_models.py --model {}\n```\n\n**Note:** This assumes:\n1. Your `eval_lmstudio_models.py` script accepts a `--model` argument\n2. You have `jq` installed for JSON parsing\n3. The LM Studio API endpoint returns models in the expected format\n\nIf your script uses a different argument format, you may need to adjust the command accordingly. For example, if it expects model names as", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:30:14Z"}}
{"id": "20260120-202626-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 1077.9571533203125, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:30:15Z"}}
{"id": "20260120-202626-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "\u2022 **Prioritize models with the highest return on investment** - Focus on models that can generate the most value or revenue per unit of resource invested, ensuring each dollar spent delivers maximum impact\n\n\u2022 **Choose proven, low-maintenance models over experimental ones** - Select established models with demonstrated performance and minimal ongoing resource requirements rather than risky new approaches that may need extensive support", "prompt_tokens": 24, "completion_tokens": 74, "latency_ms": 3324.232578277588, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "\u2022 **Prioritize models with the highest return on investment** - Focus on models that can generate the most value or revenue per unit of resource invested, ensuring each dollar spent delivers maximum impact\n\n\u2022 **Choose proven, low-maintenance models over experimental ones** - Select established models with demonstrated performance and minimal ongoing resource requirements rather than risky new approaches that may need extensive support", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-202626", "created_at": "2026-01-20T20:30:19Z"}}
{"id": "20260121-001518-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-coder-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 16036.63444519043, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-coder-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001518", "created_at": "2026-01-21T00:15:34Z"}}
