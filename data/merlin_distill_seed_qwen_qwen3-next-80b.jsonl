{"id": "20260120-192728-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 49443.35746765137, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:28:18Z"}}
{"id": "20260120-192728-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of work.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 5042.153596878052, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of work.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:28:23Z"}}
{"id": "20260120-192728-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1223.9375114440918, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:28:25Z"}}
{"id": "20260120-192728-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for compatibility with most modern systems.\n- **Return Value**: Returns the parsed data if successful, `", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 31530.12228012085, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for compatibility with most modern systems.\n- **Return Value**: Returns the parsed data if successful, `", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:28:56Z"}}
{"id": "20260120-192728-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2255.2785873413086, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:28:59Z"}}
{"id": "20260120-192728-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you need to:\n\n1. First, **fetch the list of running models** from the LM Studio local API endpoint (`http://127.0.0.1:1234/v1/models` \u2014 this is the standard OpenAI-compatible endpoint used by LM Studio).\n2. Extract the model IDs (names) from the JSON response.\n3. Loop over each model and run your evaluation script with that model name.\n\nAssuming:\n- Your script `scripts/eval_lmstudio_models.py` accepts a `--model` argument to specify which model to evaluate.\n- The API endpoint returns models in the format:  \n  ```json\n  {\n    \"object\": \"list\",\n    \"data\": [\n      {\n        \"id\": \"model-name-here\",\n        \"object\": \"model\",\n        ...\n      },\n      ...\n    ]\n  }\n  ```\n\nHere\u2019s a complete, robust bash command to do this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 32837.34631538391, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you need to:\n\n1. First, **fetch the list of running models** from the LM Studio local API endpoint (`http://127.0.0.1:1234/v1/models` \u2014 this is the standard OpenAI-compatible endpoint used by LM Studio).\n2. Extract the model IDs (names) from the JSON response.\n3. Loop over each model and run your evaluation script with that model name.\n\nAssuming:\n- Your script `scripts/eval_lmstudio_models.py` accepts a `--model` argument to specify which model to evaluate.\n- The API endpoint returns models in the format:  \n  ```json\n  {\n    \"object\": \"list\",\n    \"data\": [\n      {\n        \"id\": \"model-name-here\",\n        \"object\": \"model\",\n        ...\n      },\n      ...\n    ]\n  }\n  ```\n\nHere\u2019s a complete, robust bash command to do this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:29:32Z"}}
{"id": "20260120-192728-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 2389.873504638672, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:29:35Z"}}
{"id": "20260120-192728-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational cost, training time, or engineering effort\u2014favoring smaller, efficient architectures (like DistilBERT, TinyML, or quantized variants) over larger ones unless absolutely necessary.\n\n- **Leverage existing, well-supported models before building from scratch**: Reuse pre-trained, open-source, or community-vetted models that align closely with your task to avoid reinventing the wheel\u2014this saves time, reduces risk, and conserves scarce resources like data, compute, and talent.", "prompt_tokens": 24, "completion_tokens": 157, "latency_ms": 19426.169395446777, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational cost, training time, or engineering effort\u2014favoring smaller, efficient architectures (like DistilBERT, TinyML, or quantized variants) over larger ones unless absolutely necessary.\n\n- **Leverage existing, well-supported models before building from scratch**: Reuse pre-trained, open-source, or community-vetted models that align closely with your task to avoid reinventing the wheel\u2014this saves time, reduces risk, and conserves scarce resources like data, compute, and talent.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:29:54Z"}}
{"id": "20260120-192728-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 2928.1022548675537, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:29:58Z"}}
{"id": "20260120-192728-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workflows.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 4522.862911224365, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workflows.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:30:02Z"}}
{"id": "20260120-192728-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1145.735740661621, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:30:04Z"}}
{"id": "20260120-192728-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Notes:\n- Uses `with open()` for safe file handling.\n- Includes proper error handling for common issues: missing file, invalid JSON, or other I/O errors.\n- Specifies `encoding='utf-8'` for compatibility across platforms.\n", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 31326.2140750885, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Notes:\n- Uses `with open()` for safe file handling.\n- Includes proper error handling for common issues: missing file, invalid JSON, or other I/O errors.\n- Specifies `encoding='utf-8'` for compatibility across platforms.\n", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:30:35Z"}}
{"id": "20260120-192728-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2309.0522289276123, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:30:38Z"}}
{"id": "20260120-192728-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you need to:\n\n1. **List all models** served by the LM Studio local API (typically via `/v1/models`).\n2. **Iterate over each model ID** and invoke your evaluation script with that model.\n\nLM Studio\u2019s local server (on `http://127.0.0.1:1234`) follows the OpenAI-compatible API format, so you can query `http://127.0.0.1:1234/v1/models` to get a JSON list of available models.\n\nHere\u2019s a complete **bash one-liner** that does this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model_id; do echo \"Evaluating model: $model_id\"; python scripts/eval_lmstudio_models.py --model \"$model_id\"; done\n```\n\n---\n\n### \u2705 Requirements:\n- `curl` \u2014 for HTTP requests (usually pre-inst", "prompt_tokens": 42, "completion_tokens": 255, "latency_ms": 31408.08057785034, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you need to:\n\n1. **List all models** served by the LM Studio local API (typically via `/v1/models`).\n2. **Iterate over each model ID** and invoke your evaluation script with that model.\n\nLM Studio\u2019s local server (on `http://127.0.0.1:1234`) follows the OpenAI-compatible API format, so you can query `http://127.0.0.1:1234/v1/models` to get a JSON list of available models.\n\nHere\u2019s a complete **bash one-liner** that does this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model_id; do echo \"Evaluating model: $model_id\"; python scripts/eval_lmstudio_models.py --model \"$model_id\"; done\n```\n\n---\n\n### \u2705 Requirements:\n- `curl` \u2014 for HTTP requests (usually pre-inst", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:31:10Z"}}
{"id": "20260120-192728-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 2433.345317840576, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:31:12Z"}}
{"id": "20260120-192728-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of resource consumed (compute, data labeling, maintenance), favoring lightweight or efficient architectures (e.g., distilled models, quantized versions) over larger ones unless justified by critical performance gains.\n\n- **Leverage existing, proven models before building new ones**: Reuse pre-trained, open-source, or internally vetted models that align with the task \u2014 fine-tuning is cheaper and faster than training from scratch \u2014 and only invest in custom development when no suitable model exists and the expected ROI clearly justifies the cost.", "prompt_tokens": 24, "completion_tokens": 161, "latency_ms": 19927.98662185669, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of resource consumed (compute, data labeling, maintenance), favoring lightweight or efficient architectures (e.g., distilled models, quantized versions) over larger ones unless justified by critical performance gains.\n\n- **Leverage existing, proven models before building new ones**: Reuse pre-trained, open-source, or internally vetted models that align with the task \u2014 fine-tuning is cheaper and faster than training from scratch \u2014 and only invest in custom development when no suitable model exists and the expected ROI clearly justifies the cost.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:31:32Z"}}
{"id": "20260120-192728-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 3112.2188568115234, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:31:36Z"}}
{"id": "20260120-192728-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workload.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 4525.6030559539795, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workload.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:31:41Z"}}
{"id": "20260120-192728-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1143.000602722168, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:31:42Z"}}
{"id": "20260120-192728-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON data from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for compatibility with most modern systems.\n- **Modular**: Encapsulated in a function for", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 30417.56272315979, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON data from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for compatibility with most modern systems.\n- **Modular**: Encapsulated in a function for", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:32:13Z"}}
{"id": "20260120-192728-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2227.205276489258, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:32:15Z"}}
{"id": "20260120-192728-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you\u2019ll need to:\n\n1. First, **list all models** currently loaded in LM Studio\u2019s local server (typically via its `/v1/models` endpoint).\n2. Then, for each model ID returned, **call your evaluation script** with the model name as an argument.\n\nHere's a complete, robust bash one-liner that does this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model_id; do echo \"Evaluating model: $model_id\"; python scripts/eval_lmstudio_models.py --model \"$model_id\"; done\n```\n\n### Explanation:\n\n- `curl -s http://127.0.0.1:1234/v1/models`  \n  \u2192 Fetches the list of models from LM Studio\u2019s OpenAI-compatible API endpoint (silent mode `-s`).\n\n- `jq -r '.data[].id'`  \n  \u2192 Parses the JSON response and extracts just", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 31055.13882637024, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you\u2019ll need to:\n\n1. First, **list all models** currently loaded in LM Studio\u2019s local server (typically via its `/v1/models` endpoint).\n2. Then, for each model ID returned, **call your evaluation script** with the model name as an argument.\n\nHere's a complete, robust bash one-liner that does this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model_id; do echo \"Evaluating model: $model_id\"; python scripts/eval_lmstudio_models.py --model \"$model_id\"; done\n```\n\n### Explanation:\n\n- `curl -s http://127.0.0.1:1234/v1/models`  \n  \u2192 Fetches the list of models from LM Studio\u2019s OpenAI-compatible API endpoint (silent mode `-s`).\n\n- `jq -r '.data[].id'`  \n  \u2192 Parses the JSON response and extracts just", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:32:46Z"}}
{"id": "20260120-192728-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 2342.611789703369, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:32:49Z"}}
{"id": "20260120-192728-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the greatest business or user value per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures (e.g., distilled or quantized models) over larger ones unless performance gains justify the cost.\n\n- **Leverage existing, proven models before building new ones**: Reuse open-source or pre-trained models that align with your task, minimizing training time and infrastructure needs\u2014only fine-tune or develop custom models when clear evidence shows off-the-shelf options are insufficient.", "prompt_tokens": 24, "completion_tokens": 139, "latency_ms": 16927.17432975769, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the greatest business or user value per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures (e.g., distilled or quantized models) over larger ones unless performance gains justify the cost.\n\n- **Leverage existing, proven models before building new ones**: Reuse open-source or pre-trained models that align with your task, minimizing training time and infrastructure needs\u2014only fine-tune or develop custom models when clear evidence shows off-the-shelf options are insufficient.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:33:06Z"}}
{"id": "20260120-192728-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 2929.4371604919434, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:33:09Z"}}
{"id": "20260120-192728-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workflow demands.", "prompt_tokens": 22, "completion_tokens": 35, "latency_ms": 4505.305051803589, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workflow demands.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:33:14Z"}}
{"id": "20260120-192728-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1117.35200881958, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:33:16Z"}}
{"id": "20260120-192728-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n```\n\n### Key features:\n- **Error handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for compatibility with most modern JSON files.\n- **Return value**: Returns the parsed data on success, `None` on failure (easy to check).\n-", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 30595.470428466797, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n```\n\n### Key features:\n- **Error handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for compatibility with most modern JSON files.\n- **Return value**: Returns the parsed data on success, `None` on failure (easy to check).\n-", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:33:46Z"}}
{"id": "20260120-192728-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2256.274461746216, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:33:49Z"}}
{"id": "20260120-192728-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you need to:\n\n1. First, **list all models** currently loaded in LM Studio\u2019s local server (typically via its `/v1/models` endpoint).\n2. Then, for each model ID returned, invoke your Python script with the model name as an argument.\n\nHere's a complete, robust bash command that does this using `curl`, `jq` (for JSON parsing), and a loop:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model_id; do\n    echo \"Evaluating model: $model_id\"\n    python scripts/eval_lmstudio_models.py --model \"$model_id\" --api-base http://127.0.0.1:1234\ndone\n```\n\n### Assumptions:\n- LM Studio is running and accessible at `http://127.0.0.1:1234`.\n- The `/v1/models` endpoint returns a", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 31330.557823181152, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you need to:\n\n1. First, **list all models** currently loaded in LM Studio\u2019s local server (typically via its `/v1/models` endpoint).\n2. Then, for each model ID returned, invoke your Python script with the model name as an argument.\n\nHere's a complete, robust bash command that does this using `curl`, `jq` (for JSON parsing), and a loop:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model_id; do\n    echo \"Evaluating model: $model_id\"\n    python scripts/eval_lmstudio_models.py --model \"$model_id\" --api-base http://127.0.0.1:1234\ndone\n```\n\n### Assumptions:\n- LM Studio is running and accessible at `http://127.0.0.1:1234`.\n- The `/v1/models` endpoint returns a", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:34:20Z"}}
{"id": "20260120-192728-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 2333.3287239074707, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:34:23Z"}}
{"id": "20260120-192728-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the greatest business or user value per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures (e.g., distilled or quantized models) over larger ones unless performance gains justify the cost.\n\n- **Leverage existing, proven models before building new ones**: Reuse open-source or pre-trained models that align with your task domain to avoid redundant training costs; fine-tune only when necessary and validate on real-world data to ensure ROI.", "prompt_tokens": 24, "completion_tokens": 134, "latency_ms": 16321.47765159607, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the greatest business or user value per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures (e.g., distilled or quantized models) over larger ones unless performance gains justify the cost.\n\n- **Leverage existing, proven models before building new ones**: Reuse open-source or pre-trained models that align with your task domain to avoid redundant training costs; fine-tune only when necessary and validate on real-world data to ensure ROI.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:34:40Z"}}
{"id": "20260120-192728-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 2852.5259494781494, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:34:43Z"}}
{"id": "20260120-192728-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of work.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 4517.639875411987, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of work.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:34:48Z"}}
{"id": "20260120-192728-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1154.2651653289795, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:34:49Z"}}
{"id": "20260120-192728-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Error: Configuration file '{config_path}' not found.\")\n        return None\n    except json.JSONDecodeError:\n        print(f\"Error: Invalid JSON in '{config_path}'.\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading '{config_path}': {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n```\n\n### Features:\n- **Error handling**: Catches file not found, invalid JSON, and other exceptions.\n- **UTF-8 encoding**: Ensures compatibility with international characters.\n- **Return value**: Returns the parsed JSON data or `None` on error.\n- **Clear feedback**: Prints helpful messages", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 29143.600702285767, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Error: Configuration file '{config_path}' not found.\")\n        return None\n    except json.JSONDecodeError:\n        print(f\"Error: Invalid JSON in '{config_path}'.\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading '{config_path}': {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n```\n\n### Features:\n- **Error handling**: Catches file not found, invalid JSON, and other exceptions.\n- **UTF-8 encoding**: Ensures compatibility with international characters.\n- **Return value**: Returns the parsed JSON data or `None` on error.\n- **Clear feedback**: Prints helpful messages", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:35:18Z"}}
{"id": "20260120-192728-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2178.3909797668457, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:35:21Z"}}
{"id": "20260120-192728-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you need to:\n\n1. First, **list all models** currently loaded in LM Studio\u2019s local API (at `http://127.0.0.1:1234/v1/models`).\n2. Then, for each model ID returned, invoke your Python script with the model name as an argument.\n\nLM Studio exposes a standard OpenAI-compatible API at `http://127.0.0.1:1234/v1/models`, which returns a JSON list of models like:\n\n```json\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"model-1\",\n      \"object\": \"model\",\n      \"created\": 1700000000,\n      \"owned_by\": \"local\"\n    },\n    {\n      \"id\": \"model-2\",\n      \"object\": \"model\",\n      \"created\": 1700000001,\n      \"owned_by\": \"local\"\n    }\n  ]\n}\n```\n\nWe", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 29375.65803527832, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you need to:\n\n1. First, **list all models** currently loaded in LM Studio\u2019s local API (at `http://127.0.0.1:1234/v1/models`).\n2. Then, for each model ID returned, invoke your Python script with the model name as an argument.\n\nLM Studio exposes a standard OpenAI-compatible API at `http://127.0.0.1:1234/v1/models`, which returns a JSON list of models like:\n\n```json\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"model-1\",\n      \"object\": \"model\",\n      \"created\": 1700000000,\n      \"owned_by\": \"local\"\n    },\n    {\n      \"id\": \"model-2\",\n      \"object\": \"model\",\n      \"created\": 1700000001,\n      \"owned_by\": \"local\"\n    }\n  ]\n}\n```\n\nWe", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:35:50Z"}}
{"id": "20260120-192728-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 2365.6880855560303, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:35:53Z"}}
{"id": "20260120-192728-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of resource consumed (compute, data labeling, maintenance), favoring lightweight or efficient architectures like distilled models or quantized versions.\n\n- **Start small and iterate with measurable milestones**: Begin with the simplest model that meets minimum viable performance thresholds, then scale up only if clear, quantifiable gains justify additional investment\u2014avoid over-engineering upfront.", "prompt_tokens": 24, "completion_tokens": 124, "latency_ms": 14807.540893554688, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of resource consumed (compute, data labeling, maintenance), favoring lightweight or efficient architectures like distilled models or quantized versions.\n\n- **Start small and iterate with measurable milestones**: Begin with the simplest model that meets minimum viable performance thresholds, then scale up only if clear, quantifiable gains justify additional investment\u2014avoid over-engineering upfront.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-192728", "created_at": "2026-01-20T19:36:08Z"}}
{"id": "20260120-210234-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 57441.01023674011, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:03:32Z"}}
{"id": "20260120-210234-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or requests to the most appropriate person or team based on predefined rules, ensuring efficient workflow management and timely resolution.", "prompt_tokens": 22, "completion_tokens": 30, "latency_ms": 5193.525791168213, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or requests to the most appropriate person or team based on predefined rules, ensuring efficient workflow management and timely resolution.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:03:37Z"}}
{"id": "20260120-210234-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1514.815092086792, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:03:39Z"}}
{"id": "20260120-210234-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding Specified**: Uses `utf-8` encoding for compatibility across platforms.\n- **Returns `None` on Failure**: Allows the calling code to handle absence gracefully.\n- **Clear Feedback**:", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 33635.71834564209, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding Specified**: Uses `utf-8` encoding for compatibility across platforms.\n- **Returns `None` on Failure**: Allows the calling code to handle absence gracefully.\n- **Clear Feedback**:", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:04:13Z"}}
{"id": "20260120-210234-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2499.734401702881, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:04:16Z"}}
{"id": "20260120-210234-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you\u2019ll need to:\n\n1. First, **list all models** currently loaded in LM Studio\u2019s local server (which typically exposes an API endpoint like `/v1/models`).\n2. Then, for each model ID returned, invoke your Python script with the model name as an argument.\n\nAssuming:\n- The LM Studio server at `http://127.0.0.1:1234` follows the OpenAI-compatible API (which it does by default),\n- The endpoint `/v1/models` returns a JSON list of models with `\"id\"` fields,\n- Your script `scripts/eval_lmstudio_models.py` accepts a model name as an argument like:  \n  ```bash\n  python scripts/eval_lmstudio_models.py --model <MODEL_ID>\n  ```\n\nHere\u2019s the **complete bash command** to do this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model; do\n", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 33514.291524887085, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you\u2019ll need to:\n\n1. First, **list all models** currently loaded in LM Studio\u2019s local server (which typically exposes an API endpoint like `/v1/models`).\n2. Then, for each model ID returned, invoke your Python script with the model name as an argument.\n\nAssuming:\n- The LM Studio server at `http://127.0.0.1:1234` follows the OpenAI-compatible API (which it does by default),\n- The endpoint `/v1/models` returns a JSON list of models with `\"id\"` fields,\n- Your script `scripts/eval_lmstudio_models.py` accepts a model name as an argument like:  \n  ```bash\n  python scripts/eval_lmstudio_models.py --model <MODEL_ID>\n  ```\n\nHere\u2019s the **complete bash command** to do this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model; do\n", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:04:50Z"}}
{"id": "20260120-210234-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 2270.32470703125, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:04:52Z"}}
{"id": "20260120-210234-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational cost, training time, or engineering effort\u2014favoring smaller, efficient architectures (like distilled or quantized models) over larger ones when performance is comparable.\n\n- **Leverage existing, proven models before building new ones**: Opt for fine-tuning open-source or pre-trained models that align closely with your task rather than training from scratch; this reduces data, compute, and time requirements while minimizing risk.", "prompt_tokens": 24, "completion_tokens": 140, "latency_ms": 18221.890449523926, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational cost, training time, or engineering effort\u2014favoring smaller, efficient architectures (like distilled or quantized models) over larger ones when performance is comparable.\n\n- **Leverage existing, proven models before building new ones**: Opt for fine-tuning open-source or pre-trained models that align closely with your task rather than training from scratch; this reduces data, compute, and time requirements while minimizing risk.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:05:11Z"}}
{"id": "20260120-210234-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 3466.317653656006, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:05:14Z"}}
{"id": "20260120-210234-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of work.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 4655.194520950317, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of work.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:05:19Z"}}
{"id": "20260120-210234-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1238.0754947662354, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:05:21Z"}}
{"id": "20260120-210234-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` to handle Unicode characters properly.\n- **Return Value**: Returns the parsed data on success, `None` on failure for easy checking.\n- **Modular", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 31936.83362007141, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` to handle Unicode characters properly.\n- **Return Value**: Returns the parsed data on success, `None` on failure for easy checking.\n- **Modular", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:05:53Z"}}
{"id": "20260120-210234-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2343.8003063201904, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:05:55Z"}}
{"id": "20260120-210234-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you\u2019ll need to:\n\n1. First, **list all models** currently loaded in LM Studio\u2019s local server (which typically exposes an API endpoint like `/v1/models`).\n2. Then, for each model ID returned, invoke your Python script with the model name as an argument.\n\nAssuming:\n- The LM Studio server at `http://127.0.0.1:1234` follows the OpenAI-compatible API (as it does by default),\n- The endpoint `/v1/models` returns a JSON list of models with `\"id\"` fields,\n- Your script `scripts/eval_lmstudio_models.py` accepts a model name as an argument, e.g., `python scripts/eval_lmstudio_models.py --model <model-id>`,\n\nHere\u2019s the **bash command** to do this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model; do\n    echo \"Evaluating", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 33569.592237472534, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you\u2019ll need to:\n\n1. First, **list all models** currently loaded in LM Studio\u2019s local server (which typically exposes an API endpoint like `/v1/models`).\n2. Then, for each model ID returned, invoke your Python script with the model name as an argument.\n\nAssuming:\n- The LM Studio server at `http://127.0.0.1:1234` follows the OpenAI-compatible API (as it does by default),\n- The endpoint `/v1/models` returns a JSON list of models with `\"id\"` fields,\n- Your script `scripts/eval_lmstudio_models.py` accepts a model name as an argument, e.g., `python scripts/eval_lmstudio_models.py --model <model-id>`,\n\nHere\u2019s the **bash command** to do this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model; do\n    echo \"Evaluating", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:06:29Z"}}
{"id": "20260120-210234-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 2568.490743637085, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:06:32Z"}}
{"id": "20260120-210234-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the greatest business or user value relative to their computational, financial, and maintenance costs\u2014favoring smaller, efficient architectures (e.g., distilled or quantized versions) over larger ones unless performance gains justify the overhead.\n\n- **Leverage existing, proven models before building new ones**: Opt for well-established open-source or pre-trained models that align closely with your use case, minimizing development time and resource expenditure\u2014only fine-tune or train from scratch if there\u2019s a clear, measurable advantage that justifies the investment.", "prompt_tokens": 24, "completion_tokens": 144, "latency_ms": 19556.51021003723, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the greatest business or user value relative to their computational, financial, and maintenance costs\u2014favoring smaller, efficient architectures (e.g., distilled or quantized versions) over larger ones unless performance gains justify the overhead.\n\n- **Leverage existing, proven models before building new ones**: Opt for well-established open-source or pre-trained models that align closely with your use case, minimizing development time and resource expenditure\u2014only fine-tune or train from scratch if there\u2019s a clear, measurable advantage that justifies the investment.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:06:52Z"}}
{"id": "20260120-210234-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 3274.4035720825195, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:06:55Z"}}
{"id": "20260120-210234-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workload.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 5374.418258666992, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workload.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:07:01Z"}}
{"id": "20260120-210234-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1171.22483253479, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:07:03Z"}}
{"id": "20260120-210234-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for compatibility with most modern systems.\n- **Return Value**: Returns the parsed data if successful, `None` otherwise \u2014 making it easy to check success.\n", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 33982.92088508606, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for compatibility with most modern systems.\n- **Return Value**: Returns the parsed data if successful, `None` otherwise \u2014 making it easy to check success.\n", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:07:37Z"}}
{"id": "20260120-210234-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2784.3940258026123, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:07:40Z"}}
{"id": "20260120-210234-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you need to:\n\n1. First, **list all running models** from the LM Studio API endpoint (typically `/v1/models`).\n2. Then, for each model ID returned, invoke your evaluation script with that model as an argument.\n\nAssuming:\n- The LM Studio server is running at `http://127.0.0.1:1234`\n- The models are listed via the OpenAI-compatible API endpoint: `http://127.0.0.1:1234/v1/models`\n- The response is a JSON object with a key `\"data\"` containing an array of model objects, each with an `\"id\"` field.\n- Your script `scripts/eval_lmstudio_models.py` accepts the model ID as a command-line argument (e.g., `python scripts/eval_lmstudio_models.py --model <model-id>`)\n\nHere\u2019s a **bash one-liner** that does this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 56719.271421432495, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you need to:\n\n1. First, **list all running models** from the LM Studio API endpoint (typically `/v1/models`).\n2. Then, for each model ID returned, invoke your evaluation script with that model as an argument.\n\nAssuming:\n- The LM Studio server is running at `http://127.0.0.1:1234`\n- The models are listed via the OpenAI-compatible API endpoint: `http://127.0.0.1:1234/v1/models`\n- The response is a JSON object with a key `\"data\"` containing an array of model objects, each with an `\"id\"` field.\n- Your script `scripts/eval_lmstudio_models.py` accepts the model ID as a command-line argument (e.g., `python scripts/eval_lmstudio_models.py --model <model-id>`)\n\nHere\u2019s a **bash one-liner** that does this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:08:37Z"}}
{"id": "20260120-210234-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 3107.022762298584, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:08:40Z"}}
{"id": "20260120-210234-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here are two concise, practical bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize the smallest model that meets accuracy and latency requirements** \u2014 Choose the minimal viable model size to reduce compute costs, memory usage, and inference time, while still delivering acceptable performance for the use case.\n\n- **Leverage existing fine-tuned or open-source models over training from scratch** \u2014 Reuse pre-trained, community-supported models (e.g., Hugging Face) that align with your task to save time, data, and GPU/TPU resources.", "prompt_tokens": 24, "completion_tokens": 117, "latency_ms": 18186.092615127563, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here are two concise, practical bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize the smallest model that meets accuracy and latency requirements** \u2014 Choose the minimal viable model size to reduce compute costs, memory usage, and inference time, while still delivering acceptable performance for the use case.\n\n- **Leverage existing fine-tuned or open-source models over training from scratch** \u2014 Reuse pre-trained, community-supported models (e.g., Hugging Face) that align with your task to save time, data, and GPU/TPU resources.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:08:59Z"}}
{"id": "20260120-210234-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 3438.5476112365723, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:09:02Z"}}
{"id": "20260120-210234-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of work.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 5160.469532012939, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of work.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:09:08Z"}}
{"id": "20260120-210234-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1408.83469581604, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:09:09Z"}}
{"id": "20260120-210234-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for compatibility with most modern systems.\n- **Return Value**: Returns the parsed data on success, `", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 39511.30557060242, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for compatibility with most modern systems.\n- **Return Value**: Returns the parsed data on success, `", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:09:49Z"}}
{"id": "20260120-210234-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2884.532690048218, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-210234", "created_at": "2026-01-20T21:09:52Z"}}
{"id": "20260120-234025-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 65552.69050598145, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234025", "created_at": "2026-01-20T23:41:30Z"}}
{"id": "20260120-234025-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate fulfillment of responsibilities.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 5210.976362228394, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate fulfillment of responsibilities.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234025", "created_at": "2026-01-20T23:41:36Z"}}
{"id": "20260120-234025-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1304.6915531158447, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234025", "created_at": "2026-01-20T23:41:37Z"}}
{"id": "20260120-234147-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 3786.8337631225586, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234147", "created_at": "2026-01-20T23:41:51Z"}}
{"id": "20260120-234147-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of work.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 4718.433380126953, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of work.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234147", "created_at": "2026-01-20T23:41:56Z"}}
{"id": "20260120-234147-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1558.1951141357422, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234147", "created_at": "2026-01-20T23:41:58Z"}}
{"id": "20260120-234230-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 3024.294853210449, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234230", "created_at": "2026-01-20T23:42:33Z"}}
{"id": "20260120-234230-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workload.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 4682.103157043457, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workload.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234230", "created_at": "2026-01-20T23:42:38Z"}}
{"id": "20260120-234230-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1139.347791671753, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234230", "created_at": "2026-01-20T23:42:40Z"}}
{"id": "20260120-234230-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON data from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key features:\n- Uses `with open()` for safe file handling (auto-closes the file).\n- Specifies `encoding='utf-8'` for cross-platform compatibility.\n- Includes comprehensive error handling for common issues:\n  - File not", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 33903.350591659546, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON data from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key features:\n- Uses `with open()` for safe file handling (auto-closes the file).\n- Specifies `encoding='utf-8'` for cross-platform compatibility.\n- Includes comprehensive error handling for common issues:\n  - File not", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234230", "created_at": "2026-01-20T23:43:14Z"}}
{"id": "20260120-234230-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2117.286443710327, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234230", "created_at": "2026-01-20T23:43:16Z"}}
{"id": "20260120-234230-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you\u2019ll need to:\n\n1. First, **list all models** currently loaded in LM Studio\u2019s local server (typically via its `/v1/models` endpoint).\n2. Then, for each model ID returned, **call your Python script** with the model name as an argument.\n\nHere's a complete, robust bash command that does this using `curl`, `jq`, and a loop:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model_id; do\n    echo \"Evaluating model: $model_id\"\n    python scripts/eval_lmstudio_models.py --model \"$model_id\" --api-base http://127.0.0.1:1234\ndone\n```\n\n### Explanation:\n\n- `curl -s http://127.0.0.1:1234/v1/models`:  \n  Fetches the list of models from LM Studio\u2019s OpenAI-compatible", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 35378.29566001892, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you\u2019ll need to:\n\n1. First, **list all models** currently loaded in LM Studio\u2019s local server (typically via its `/v1/models` endpoint).\n2. Then, for each model ID returned, **call your Python script** with the model name as an argument.\n\nHere's a complete, robust bash command that does this using `curl`, `jq`, and a loop:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model_id; do\n    echo \"Evaluating model: $model_id\"\n    python scripts/eval_lmstudio_models.py --model \"$model_id\" --api-base http://127.0.0.1:1234\ndone\n```\n\n### Explanation:\n\n- `curl -s http://127.0.0.1:1234/v1/models`:  \n  Fetches the list of models from LM Studio\u2019s OpenAI-compatible", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234230", "created_at": "2026-01-20T23:43:52Z"}}
{"id": "20260120-234230-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 2371.4208602905273, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234230", "created_at": "2026-01-20T23:43:54Z"}}
{"id": "20260120-234230-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures or fine-tuned open-source alternatives over large, expensive proprietary ones.\n\n- **Leverage existing, validated models before building new ones**: Reuse pre-trained, domain-appropriate models from trusted sources (e.g., Hugging Face, model zoos) or adapt previously deployed models rather than training from scratch\u2014reducing time, data needs, and infrastructure burden.", "prompt_tokens": 24, "completion_tokens": 148, "latency_ms": 18982.969999313354, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures or fine-tuned open-source alternatives over large, expensive proprietary ones.\n\n- **Leverage existing, validated models before building new ones**: Reuse pre-trained, domain-appropriate models from trusted sources (e.g., Hugging Face, model zoos) or adapt previously deployed models rather than training from scratch\u2014reducing time, data needs, and infrastructure burden.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234230", "created_at": "2026-01-20T23:44:14Z"}}
{"id": "20260120-234230-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 3267.5998210906982, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234230", "created_at": "2026-01-20T23:44:17Z"}}
{"id": "20260120-234230-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or requests to the most appropriate person or team based on predefined rules, ensuring efficient workflow management and timely resolution.", "prompt_tokens": 22, "completion_tokens": 30, "latency_ms": 5364.3763065338135, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or requests to the most appropriate person or team based on predefined rules, ensuring efficient workflow management and timely resolution.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234230", "created_at": "2026-01-20T23:44:23Z"}}
{"id": "20260120-234230-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1135.303020477295, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234230", "created_at": "2026-01-20T23:44:24Z"}}
{"id": "20260120-234230-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding Specified**: Uses `utf-8` encoding for compatibility across systems.\n- **Return Value**: Returns the parsed JSON data (as a dict/list) or `None` on error.\n", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 33470.47281265259, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding Specified**: Uses `utf-8` encoding for compatibility across systems.\n- **Return Value**: Returns the parsed JSON data (as a dict/list) or `None` on error.\n", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234230", "created_at": "2026-01-20T23:44:58Z"}}
{"id": "20260120-234230-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2351.6736030578613, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234230", "created_at": "2026-01-20T23:45:01Z"}}
{"id": "20260120-234230-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you\u2019ll need to:\n\n1. First, **list all models** currently loaded in LM Studio\u2019s local server (typically via its `/v1/models` endpoint).\n2. Then, for each model ID returned, **invoke your Python script** with the model name as an argument.\n\nHere's a complete, robust bash one-liner that does this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model_id; do echo \"Evaluating model: $model_id\"; python scripts/eval_lmstudio_models.py --model \"$model_id\"; done\n```\n\n### Explanation:\n\n- `curl -s http://127.0.0.1:1234/v1/models`  \n  \u2192 Fetches the list of models from LM Studio\u2019s OpenAI-compatible API endpoint (standard for LM Studio v0.2+). The `-s` flag silences progress output.\n\n- `jq -r '.data", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 32949.37562942505, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you\u2019ll need to:\n\n1. First, **list all models** currently loaded in LM Studio\u2019s local server (typically via its `/v1/models` endpoint).\n2. Then, for each model ID returned, **invoke your Python script** with the model name as an argument.\n\nHere's a complete, robust bash one-liner that does this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model_id; do echo \"Evaluating model: $model_id\"; python scripts/eval_lmstudio_models.py --model \"$model_id\"; done\n```\n\n### Explanation:\n\n- `curl -s http://127.0.0.1:1234/v1/models`  \n  \u2192 Fetches the list of models from LM Studio\u2019s OpenAI-compatible API endpoint (standard for LM Studio v0.2+). The `-s` flag silences progress output.\n\n- `jq -r '.data", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234230", "created_at": "2026-01-20T23:45:34Z"}}
{"id": "20260120-234230-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 2791.846990585327, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234230", "created_at": "2026-01-20T23:45:37Z"}}
{"id": "20260120-234230-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the greatest business or user value relative to their computational, financial, and maintenance costs\u2014favoring smaller, efficient architectures (e.g., distilled or quantized models) over larger ones unless performance gains justify the overhead.\n\n- **Leverage existing, proven models before building new ones**: Reuse open-source or pre-trained models that align closely with your use case to avoid redundant training costs; fine-tune only when necessary and validate on real-world data to ensure reliability without over-investing in R&D.", "prompt_tokens": 24, "completion_tokens": 142, "latency_ms": 19399.232387542725, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the greatest business or user value relative to their computational, financial, and maintenance costs\u2014favoring smaller, efficient architectures (e.g., distilled or quantized models) over larger ones unless performance gains justify the overhead.\n\n- **Leverage existing, proven models before building new ones**: Reuse open-source or pre-trained models that align closely with your use case to avoid redundant training costs; fine-tune only when necessary and validate on real-world data to ensure reliability without over-investing in R&D.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234230", "created_at": "2026-01-20T23:45:56Z"}}
{"id": "20260120-234230-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 3158.249616622925, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234230", "created_at": "2026-01-20T23:46:00Z"}}
{"id": "20260120-234230-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workload.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 4519.789934158325, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workload.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234230", "created_at": "2026-01-20T23:46:05Z"}}
{"id": "20260120-234230-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1189.8343563079834, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-234230", "created_at": "2026-01-20T23:46:06Z"}}
{"id": "20260120-235455-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 3297.5523471832275, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-235455", "created_at": "2026-01-20T23:54:58Z"}}
{"id": "20260120-235455-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or requests to the most appropriate person or team based on predefined rules, ensuring efficient workflow management and timely resolution.", "prompt_tokens": 22, "completion_tokens": 30, "latency_ms": 4057.9323768615723, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or requests to the most appropriate person or team based on predefined rules, ensuring efficient workflow management and timely resolution.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-235455", "created_at": "2026-01-20T23:55:02Z"}}
{"id": "20260120-235455-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1346.0373878479004, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-235455", "created_at": "2026-01-20T23:55:04Z"}}
{"id": "20260120-235455-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses UTF-8 explicitly for compatibility.\n- **Return Value**: Returns the parsed data on success, `None` on failure (", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 33077.92663574219, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses UTF-8 explicitly for compatibility.\n- **Return Value**: Returns the parsed data on success, `None` on failure (", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-235455", "created_at": "2026-01-20T23:55:37Z"}}
{"id": "20260120-235455-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 3204.6189308166504, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-235455", "created_at": "2026-01-20T23:55:41Z"}}
{"id": "20260121-000259-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 3097.956657409668, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000259", "created_at": "2026-01-21T00:03:02Z"}}
{"id": "20260121-000259-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or requests to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate resolution.", "prompt_tokens": 22, "completion_tokens": 31, "latency_ms": 4033.975839614868, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or requests to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate resolution.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000259", "created_at": "2026-01-21T00:03:07Z"}}
{"id": "20260121-000259-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1091.6850566864014, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000259", "created_at": "2026-01-21T00:03:08Z"}}
{"id": "20260121-000326-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 3095.399856567383, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000326", "created_at": "2026-01-21T00:03:29Z"}}
{"id": "20260121-000326-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of work.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 4270.349025726318, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of work.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000326", "created_at": "2026-01-21T00:03:34Z"}}
{"id": "20260121-000326-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1157.4509143829346, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000326", "created_at": "2026-01-21T00:03:35Z"}}
{"id": "20260121-000326-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for compatibility with most modern systems.\n- **Return Value**: Returns the parsed data on success, `", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 30598.16598892212, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for compatibility with most modern systems.\n- **Return Value**: Returns the parsed data on success, `", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000326", "created_at": "2026-01-21T00:04:06Z"}}
{"id": "20260121-000326-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2307.8505992889404, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000326", "created_at": "2026-01-21T00:04:09Z"}}
{"id": "20260121-000326-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you need to:\n\n1. **List all model IDs** from the LM Studio local API endpoint.\n2. **Iterate over each model ID** and invoke your Python script with that model as an argument.\n\nLM Studio\u2019s local server at `http://127.0.0.1:1234` typically exposes a `/v1/models` endpoint (compatible with OpenAI API) that returns a JSON list of available models.\n\n---\n\n### \u2705 Bash Command (One-liner):\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model_id; do echo \"Evaluating model: $model_id\"; python scripts/eval_lmstudio_models.py --model \"$model_id\"; done\n```\n\n---\n\n### \ud83d\udd0d Explanation:\n\n- `curl -s http://127.0.0.1:1234/v1/models`  \n  \u2192 Fetches the list of models silently (`-", "prompt_tokens": 42, "completion_tokens": 254, "latency_ms": 30938.970804214478, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you need to:\n\n1. **List all model IDs** from the LM Studio local API endpoint.\n2. **Iterate over each model ID** and invoke your Python script with that model as an argument.\n\nLM Studio\u2019s local server at `http://127.0.0.1:1234` typically exposes a `/v1/models` endpoint (compatible with OpenAI API) that returns a JSON list of available models.\n\n---\n\n### \u2705 Bash Command (One-liner):\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model_id; do echo \"Evaluating model: $model_id\"; python scripts/eval_lmstudio_models.py --model \"$model_id\"; done\n```\n\n---\n\n### \ud83d\udd0d Explanation:\n\n- `curl -s http://127.0.0.1:1234/v1/models`  \n  \u2192 Fetches the list of models silently (`-", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000326", "created_at": "2026-01-21T00:04:40Z"}}
{"id": "20260121-000326-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 2354.809522628784, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000326", "created_at": "2026-01-21T00:04:43Z"}}
{"id": "20260121-000326-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational cost, training time, or human effort\u2014favoring smaller, efficient architectures (like DistilBERT, TinyML, or quantized variants) over larger ones unless significantly superior.\n\n- **Leverage existing, proven models before building new ones**: Reuse pre-trained, open-source, or internally validated models that align with the task\u2014even if imperfect\u2014to avoid redundant training costs; fine-tune only when necessary and validate against a minimal viable benchmark.", "prompt_tokens": 24, "completion_tokens": 149, "latency_ms": 17620.628595352173, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational cost, training time, or human effort\u2014favoring smaller, efficient architectures (like DistilBERT, TinyML, or quantized variants) over larger ones unless significantly superior.\n\n- **Leverage existing, proven models before building new ones**: Reuse pre-trained, open-source, or internally validated models that align with the task\u2014even if imperfect\u2014to avoid redundant training costs; fine-tune only when necessary and validate against a minimal viable benchmark.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000326", "created_at": "2026-01-21T00:05:00Z"}}
{"id": "20260121-000326-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 2786.276340484619, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000326", "created_at": "2026-01-21T00:05:03Z"}}
{"id": "20260121-000326-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate fulfillment of responsibilities.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 4347.15461730957, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate fulfillment of responsibilities.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000326", "created_at": "2026-01-21T00:05:08Z"}}
{"id": "20260121-000326-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1171.3237762451172, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000326", "created_at": "2026-01-21T00:05:09Z"}}
{"id": "20260121-000550-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 2853.6269664764404, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:05:53Z"}}
{"id": "20260121-000550-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workload.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 4585.23964881897, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workload.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:05:58Z"}}
{"id": "20260121-000550-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1086.0302448272705, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:05:59Z"}}
{"id": "20260121-000550-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Error: Configuration file '{config_path}' not found.\")\n        return None\n    except json.JSONDecodeError:\n        print(f\"Error: Invalid JSON in '{config_path}'.\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading '{config_path}': {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for compatibility with most modern JSON files.\n- **Return Value**: Returns the parsed data on success, `None` on failure \u2014 making it easy to", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 32154.999256134033, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Error: Configuration file '{config_path}' not found.\")\n        return None\n    except json.JSONDecodeError:\n        print(f\"Error: Invalid JSON in '{config_path}'.\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading '{config_path}': {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for compatibility with most modern JSON files.\n- **Return Value**: Returns the parsed data on success, `None` on failure \u2014 making it easy to", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:06:32Z"}}
{"id": "20260121-000550-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2238.462209701538, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:06:34Z"}}
{"id": "20260121-000550-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you\u2019ll need to:\n\n1. **List all models** currently loaded in LM Studio\u2019s local API (typically via a GET request to `/v1/models`).\n2. **Iterate over each model ID** and invoke your evaluation script with the model name as an argument.\n\nHere's a complete, robust bash command that does this using `curl` and `jq`:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model_id; do\n    echo \"Evaluating model: $model_id\"\n    python scripts/eval_lmstudio_models.py --model \"$model_id\" --api-base http://127.0.0.1:1234\ndone\n```\n\n---\n\n### \u2705 Prerequisites\n\nMake sure you have:\n\n- `curl` installed (usually pre-installed on macOS/Linux)\n- `jq` installed for JSON parsing \u2014 install it if needed:\n  ```bash\n  #", "prompt_tokens": 42, "completion_tokens": 255, "latency_ms": 32787.64462471008, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you\u2019ll need to:\n\n1. **List all models** currently loaded in LM Studio\u2019s local API (typically via a GET request to `/v1/models`).\n2. **Iterate over each model ID** and invoke your evaluation script with the model name as an argument.\n\nHere's a complete, robust bash command that does this using `curl` and `jq`:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model_id; do\n    echo \"Evaluating model: $model_id\"\n    python scripts/eval_lmstudio_models.py --model \"$model_id\" --api-base http://127.0.0.1:1234\ndone\n```\n\n---\n\n### \u2705 Prerequisites\n\nMake sure you have:\n\n- `curl` installed (usually pre-installed on macOS/Linux)\n- `jq` installed for JSON parsing \u2014 install it if needed:\n  ```bash\n  #", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:07:07Z"}}
{"id": "20260121-000550-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 2490.239381790161, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:07:10Z"}}
{"id": "20260121-000550-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational cost, training time, or human effort\u2014favoring smaller, efficient architectures (like DistilBERT, TinyML, or quantized variants) over larger ones unless significantly superior.\n\n- **Leverage existing, proven models before building new ones**: Reuse pre-trained, open-source, or internally validated models that align with the task\u2014even if imperfect\u2014to avoid redundant training costs; fine-tune only when necessary and measure gains against baseline performance.", "prompt_tokens": 24, "completion_tokens": 148, "latency_ms": 18745.018005371094, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational cost, training time, or human effort\u2014favoring smaller, efficient architectures (like DistilBERT, TinyML, or quantized variants) over larger ones unless significantly superior.\n\n- **Leverage existing, proven models before building new ones**: Reuse pre-trained, open-source, or internally validated models that align with the task\u2014even if imperfect\u2014to avoid redundant training costs; fine-tune only when necessary and measure gains against baseline performance.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:07:29Z"}}
{"id": "20260121-000550-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 4392.072677612305, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:07:34Z"}}
{"id": "20260121-000550-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workflows.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 5508.916616439819, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workflows.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:07:40Z"}}
{"id": "20260121-000550-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1297.5952625274658, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:07:41Z"}}
{"id": "20260121-000550-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for compatibility with most modern systems.\n- **Return Value**: Returns the parsed data if successful, `", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 33918.734073638916, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for compatibility with most modern systems.\n- **Return Value**: Returns the parsed data if successful, `", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:08:15Z"}}
{"id": "20260121-000550-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 3266.1876678466797, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:08:19Z"}}
{"id": "20260121-000550-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** hosted on `http://127.0.0.1:1234`, you need to:\n\n1. First, **list all available models** from the LM Studio local API endpoint (`http://127.0.0.1:1234/v1/models` \u2014 typical OpenAI-compatible endpoint).\n2. Then, for each model ID returned, invoke `scripts/eval_lmstudio_models.py` with the model name as an argument.\n\nAssuming:\n- The LM Studio server is running and accessible at `http://127.0.0.1:1234`\n- It exposes a standard OpenAI-compatible `/v1/models` endpoint\n- Your script `scripts/eval_lmstudio_models.py` accepts a model name as an argument (e.g., `python scripts/eval_lmstudio_models.py --model <model-id>`)\n\nHere\u2019s the **bash one-liner** to do this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model; do", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 33789.350271224976, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** hosted on `http://127.0.0.1:1234`, you need to:\n\n1. First, **list all available models** from the LM Studio local API endpoint (`http://127.0.0.1:1234/v1/models` \u2014 typical OpenAI-compatible endpoint).\n2. Then, for each model ID returned, invoke `scripts/eval_lmstudio_models.py` with the model name as an argument.\n\nAssuming:\n- The LM Studio server is running and accessible at `http://127.0.0.1:1234`\n- It exposes a standard OpenAI-compatible `/v1/models` endpoint\n- Your script `scripts/eval_lmstudio_models.py` accepts a model name as an argument (e.g., `python scripts/eval_lmstudio_models.py --model <model-id>`)\n\nHere\u2019s the **bash one-liner** to do this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model; do", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:08:53Z"}}
{"id": "20260121-000550-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 2703.740358352661, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:08:56Z"}}
{"id": "20260121-000550-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures or fine-tuned open-source alternatives over large proprietary ones.\n\n- **Leverage existing, validated models before building new ones**: Reuse pre-trained, well-documented models from trusted sources (e.g., Hugging Face, TensorFlow Hub) that align closely with the task, avoiding redundant training efforts and reducing time-to-deployment.", "prompt_tokens": 24, "completion_tokens": 140, "latency_ms": 19599.549293518066, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures or fine-tuned open-source alternatives over large proprietary ones.\n\n- **Leverage existing, validated models before building new ones**: Reuse pre-trained, well-documented models from trusted sources (e.g., Hugging Face, TensorFlow Hub) that align closely with the task, avoiding redundant training efforts and reducing time-to-deployment.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:09:16Z"}}
{"id": "20260121-000550-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 3031.7699909210205, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:09:19Z"}}
{"id": "20260121-000550-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workflow demands.", "prompt_tokens": 22, "completion_tokens": 35, "latency_ms": 4835.251569747925, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workflow demands.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:09:24Z"}}
{"id": "20260121-000550-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1172.126293182373, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:09:25Z"}}
{"id": "20260121-000550-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for compatibility with most modern systems.\n- **Return Value**: Returns the parsed data if successful, `", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 33784.13105010986, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for compatibility with most modern systems.\n- **Return Value**: Returns the parsed data if successful, `", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:10:00Z"}}
{"id": "20260121-000550-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2482.414484024048, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:10:02Z"}}
{"id": "20260121-000550-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you need to:\n\n1. First, **list all running models** via the LM Studio API endpoint (typically `/v1/models`).\n2. Then, for each model ID returned, invoke your Python script with that model name.\n\nAssuming:\n- The LM Studio server is running at `http://127.0.0.1:1234`\n- The models are listed via the OpenAI-compatible endpoint: `GET http://127.0.0.1:1234/v1/models`\n- The response is JSON with a list of model objects, each having an `\"id\"` field.\n- Your script `scripts/eval_lmstudio_models.py` accepts a `--model` argument for the model ID.\n\nHere\u2019s a **complete bash command** that does this in one line using `curl`, `jq`, and a loop:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 36392.25673675537, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you need to:\n\n1. First, **list all running models** via the LM Studio API endpoint (typically `/v1/models`).\n2. Then, for each model ID returned, invoke your Python script with that model name.\n\nAssuming:\n- The LM Studio server is running at `http://127.0.0.1:1234`\n- The models are listed via the OpenAI-compatible endpoint: `GET http://127.0.0.1:1234/v1/models`\n- The response is JSON with a list of model objects, each having an `\"id\"` field.\n- Your script `scripts/eval_lmstudio_models.py` accepts a `--model` argument for the model ID.\n\nHere\u2019s a **complete bash command** that does this in one line using `curl`, `jq`, and a loop:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:10:39Z"}}
{"id": "20260121-000550-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 3011.157512664795, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:10:42Z"}}
{"id": "20260121-000550-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here are two concise, practical bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize the smallest model that meets performance thresholds** \u2014 Choose the minimal viable model architecture that achieves acceptable accuracy, latency, and reliability for your use case to reduce compute, memory, and cost overhead.\n\n- **Leverage domain-specific or fine-tuned lightweight models** \u2014 Opt for models pre-trained or fine-tuned on data similar to yours (e.g., TinyBERT, MobileBERT, or quantized versions) rather than generic large models, to maximize efficiency without sacrificing task relevance.", "prompt_tokens": 24, "completion_tokens": 121, "latency_ms": 16137.260913848877, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here are two concise, practical bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize the smallest model that meets performance thresholds** \u2014 Choose the minimal viable model architecture that achieves acceptable accuracy, latency, and reliability for your use case to reduce compute, memory, and cost overhead.\n\n- **Leverage domain-specific or fine-tuned lightweight models** \u2014 Opt for models pre-trained or fine-tuned on data similar to yours (e.g., TinyBERT, MobileBERT, or quantized versions) rather than generic large models, to maximize efficiency without sacrificing task relevance.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-000550", "created_at": "2026-01-21T00:10:59Z"}}
{"id": "20260121-001338-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 4178.456783294678, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001338", "created_at": "2026-01-21T00:13:42Z"}}
{"id": "20260121-001618-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 50061.18869781494, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:17:08Z"}}
{"id": "20260121-001618-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of work.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 5005.531311035156, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of work.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:17:13Z"}}
{"id": "20260121-001618-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1429.072380065918, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:17:15Z"}}
{"id": "20260121-001618-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding specified**: Uses `utf-8` for compatibility with most modern systems.\n- **Returns `None` on failure**: Allows the calling", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 32215.61598777771, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding specified**: Uses `utf-8` for compatibility with most modern systems.\n- **Returns `None` on failure**: Allows the calling", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:17:47Z"}}
{"id": "20260121-001618-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2145.7788944244385, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:17:50Z"}}
{"id": "20260121-001618-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you need to:\n\n1. First, **list all models** currently loaded in LM Studio\u2019s local server (which typically exposes them via an API endpoint like `/v1/models`).\n2. Then, for each model ID returned, **invoke your evaluation script** with the model name as an argument.\n\nAssuming:\n- The LM Studio server at `http://127.0.0.1:1234` follows the OpenAI-compatible API (which it does by default),\n- The endpoint to list models is `http://127.0.0.1:1234/v1/models`,\n- Your script `scripts/eval_lmstudio_models.py` accepts a model name as an argument like:  \n  ```bash\n  python scripts/eval_lmstudio_models.py --model <model-id>\n  ```\n\nHere\u2019s the **complete bash command**:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' |", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 31049.44634437561, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you need to:\n\n1. First, **list all models** currently loaded in LM Studio\u2019s local server (which typically exposes them via an API endpoint like `/v1/models`).\n2. Then, for each model ID returned, **invoke your evaluation script** with the model name as an argument.\n\nAssuming:\n- The LM Studio server at `http://127.0.0.1:1234` follows the OpenAI-compatible API (which it does by default),\n- The endpoint to list models is `http://127.0.0.1:1234/v1/models`,\n- Your script `scripts/eval_lmstudio_models.py` accepts a model name as an argument like:  \n  ```bash\n  python scripts/eval_lmstudio_models.py --model <model-id>\n  ```\n\nHere\u2019s the **complete bash command**:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' |", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:18:21Z"}}
{"id": "20260121-001618-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 2701.8158435821533, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:18:24Z"}}
{"id": "20260121-001618-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the greatest business or user value relative to their computational, financial, and maintenance costs\u2014favoring smaller, efficient architectures (e.g., distilled or quantized versions) over oversized alternatives.\n\n- **Opt for reusable, well-documented, and community-supported models**: Select models with strong ecosystem support, pre-trained weights, and clear documentation to minimize development time, reduce debugging overhead, and avoid reinventing the wheel under resource constraints.", "prompt_tokens": 24, "completion_tokens": 125, "latency_ms": 18717.96941757202, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the greatest business or user value relative to their computational, financial, and maintenance costs\u2014favoring smaller, efficient architectures (e.g., distilled or quantized versions) over oversized alternatives.\n\n- **Opt for reusable, well-documented, and community-supported models**: Select models with strong ecosystem support, pre-trained weights, and clear documentation to minimize development time, reduce debugging overhead, and avoid reinventing the wheel under resource constraints.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:18:43Z"}}
{"id": "20260121-001618-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 2577.3799419403076, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:18:46Z"}}
{"id": "20260121-001618-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workflows.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 5096.996068954468, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workflows.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:18:51Z"}}
{"id": "20260121-001618-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1267.0056819915771, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:18:53Z"}}
{"id": "20260121-001618-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for broad compatibility.\n- **Modular**: Encapsulated in a function for reusability.\n", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 27236.190795898438, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for broad compatibility.\n- **Modular**: Encapsulated in a function for reusability.\n", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:19:20Z"}}
{"id": "20260121-001618-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2988.746404647827, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:19:23Z"}}
{"id": "20260121-001618-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run `scripts/eval_lmstudio_models.py` against **all models** available at the LM Studio local server (`http://127.0.0.1:1234`), you need to:\n\n1. **List all running models** via the LM Studio API.\n2. **Iterate over each model ID** and call your Python script with that model as an argument.\n\nLM Studio\u2019s local API (on `http://127.0.0.1:1234`) exposes a `/v1/models` endpoint that returns a JSON list of available models.\n\nHere's a complete, robust **bash command** to do this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model_id; do\n    echo \"Evaluating model: $model_id\"\n    python scripts/eval_lmstudio_models.py --model \"$model_id\" --base-url http://127.0.0.1:1234\ndone\n```\n\n---\n\n### \u2705 Requirements:\n\n- `curl` \u2014 Usually pre-installed on Linux/macOS.\n- `", "prompt_tokens": 42, "completion_tokens": 255, "latency_ms": 27121.36220932007, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run `scripts/eval_lmstudio_models.py` against **all models** available at the LM Studio local server (`http://127.0.0.1:1234`), you need to:\n\n1. **List all running models** via the LM Studio API.\n2. **Iterate over each model ID** and call your Python script with that model as an argument.\n\nLM Studio\u2019s local API (on `http://127.0.0.1:1234`) exposes a `/v1/models` endpoint that returns a JSON list of available models.\n\nHere's a complete, robust **bash command** to do this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model_id; do\n    echo \"Evaluating model: $model_id\"\n    python scripts/eval_lmstudio_models.py --model \"$model_id\" --base-url http://127.0.0.1:1234\ndone\n```\n\n---\n\n### \u2705 Requirements:\n\n- `curl` \u2014 Usually pre-installed on Linux/macOS.\n- `", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:19:51Z"}}
{"id": "20260121-001618-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 3208.550453186035, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:19:54Z"}}
{"id": "20260121-001618-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the greatest business or user value relative to their computational, financial, and maintenance costs\u2014favoring smaller, efficient architectures (e.g., distilled or quantized versions) over larger ones unless performance gains justify the expense.\n\n- **Leverage existing, proven models before building new ones**: Avoid reinventing the wheel; select well-supported open-source or pre-trained models with active communities and clear documentation to minimize development time, reduce risk, and conserve engineering resources.", "prompt_tokens": 24, "completion_tokens": 131, "latency_ms": 14545.708894729614, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the greatest business or user value relative to their computational, financial, and maintenance costs\u2014favoring smaller, efficient architectures (e.g., distilled or quantized versions) over larger ones unless performance gains justify the expense.\n\n- **Leverage existing, proven models before building new ones**: Avoid reinventing the wheel; select well-supported open-source or pre-trained models with active communities and clear documentation to minimize development time, reduce risk, and conserve engineering resources.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:20:09Z"}}
{"id": "20260121-001618-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 2689.0881061553955, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:20:12Z"}}
{"id": "20260121-001618-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workflows.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 4109.648942947388, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workflows.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:20:16Z"}}
{"id": "20260121-001618-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1111.398696899414, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:20:18Z"}}
{"id": "20260121-001618-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for compatibility with most modern systems.\n- **Return Value**: Returns the parsed data on success, `", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 40852.454662323, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for compatibility with most modern systems.\n- **Return Value**: Returns the parsed data on success, `", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:20:59Z"}}
{"id": "20260121-001618-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2186.847448348999, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:21:01Z"}}
{"id": "20260121-001618-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at the local LM Studio server (`http://127.0.0.1:1234`), you\u2019ll need to:\n\n1. First, **list all running models** via the LM Studio API.\n2. Then, **loop over each model** and invoke your evaluation script with the model name.\n\nLM Studio exposes an API at `http://127.0.0.1:1234/v1/models` to list available models (as of recent versions). The response is a JSON array like:\n\n```json\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"mistral-7b-instruct-v0.2\",\n      \"object\": \"model\"\n    },\n    {\n      \"id\": \"llama-3-8b\",\n      \"object\": \"model\"\n    }\n  ]\n}\n```\n\nWe can use `curl` to fetch this list, parse the model IDs with `jq`, and then run your Python script for each one.\n\n---\n\n### \u2705 Bash Command (One-liner):\n\n```bash\ncurl -s http://127.", "prompt_tokens": 42, "completion_tokens": 255, "latency_ms": 35914.79587554932, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at the local LM Studio server (`http://127.0.0.1:1234`), you\u2019ll need to:\n\n1. First, **list all running models** via the LM Studio API.\n2. Then, **loop over each model** and invoke your evaluation script with the model name.\n\nLM Studio exposes an API at `http://127.0.0.1:1234/v1/models` to list available models (as of recent versions). The response is a JSON array like:\n\n```json\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"mistral-7b-instruct-v0.2\",\n      \"object\": \"model\"\n    },\n    {\n      \"id\": \"llama-3-8b\",\n      \"object\": \"model\"\n    }\n  ]\n}\n```\n\nWe can use `curl` to fetch this list, parse the model IDs with `jq`, and then run your Python script for each one.\n\n---\n\n### \u2705 Bash Command (One-liner):\n\n```bash\ncurl -s http://127.", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:21:38Z"}}
{"id": "20260121-001618-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 5182.925462722778, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:21:43Z"}}
{"id": "20260121-001618-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures (like distilled or quantized models) over larger ones when performance is comparable.\n\n- **Leverage existing, well-supported models before building new ones**: Avoid reinventing the wheel; select proven, open-source, or pre-trained models that align with your task and require minimal fine-tuning or infrastructure overhead\u2014reducing development time and maintenance burden.", "prompt_tokens": 24, "completion_tokens": 144, "latency_ms": 20917.481184005737, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures (like distilled or quantized models) over larger ones when performance is comparable.\n\n- **Leverage existing, well-supported models before building new ones**: Avoid reinventing the wheel; select proven, open-source, or pre-trained models that align with your task and require minimal fine-tuning or infrastructure overhead\u2014reducing development time and maintenance burden.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:22:04Z"}}
{"id": "20260121-001618-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 3945.8203315734863, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:22:08Z"}}
{"id": "20260121-001618-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or requests to the most appropriate person or team based on predefined rules, ensuring efficient workflow management and timely resolution.", "prompt_tokens": 22, "completion_tokens": 30, "latency_ms": 4618.7732219696045, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or requests to the most appropriate person or team based on predefined rules, ensuring efficient workflow management and timely resolution.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:22:13Z"}}
{"id": "20260121-001618-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1242.7732944488525, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:22:15Z"}}
{"id": "20260121-001618-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Error: Configuration file '{config_path}' not found.\")\n        return None\n    except json.JSONDecodeError:\n        print(f\"Error: Invalid JSON in '{config_path}'.\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading '{config_path}': {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n```\n\n### Features:\n- **Error handling**: Catches file not found, invalid JSON, and other exceptions.\n- **UTF-8 encoding**: Ensures compatibility with international characters.\n- **Return value**: Returns the parsed JSON data or `None` on error for safe usage.\n- **Clear feedback**:", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 31511.96575164795, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Error: Configuration file '{config_path}' not found.\")\n        return None\n    except json.JSONDecodeError:\n        print(f\"Error: Invalid JSON in '{config_path}'.\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading '{config_path}': {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n```\n\n### Features:\n- **Error handling**: Catches file not found, invalid JSON, and other exceptions.\n- **UTF-8 encoding**: Ensures compatibility with international characters.\n- **Return value**: Returns the parsed JSON data or `None` on error for safe usage.\n- **Clear feedback**:", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:22:47Z"}}
{"id": "20260121-001618-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2268.2926654815674, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:22:49Z"}}
{"id": "20260121-001618-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you need to:\n\n1. First, **list all models** currently loaded in LM Studio\u2019s local server (which typically exposes them via an API endpoint like `/v1/models`).\n2. Then, for each model ID returned, invoke your Python script with the model name as an argument.\n\nAssuming:\n- The LM Studio server at `http://127.0.0.1:1234` follows OpenAI-compatible API conventions.\n- The endpoint to list models is `http://127.0.0.1:1234/v1/models`.\n- Your script `scripts/eval_lmstudio_models.py` accepts a model name as an argument (e.g., `python scripts/eval_lmstudio_models.py --model <model-id>`).\n- You have `curl`, `jq`, and Python installed.\n\nHere\u2019s the **bash command** to do this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 31189.908504486084, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you need to:\n\n1. First, **list all models** currently loaded in LM Studio\u2019s local server (which typically exposes them via an API endpoint like `/v1/models`).\n2. Then, for each model ID returned, invoke your Python script with the model name as an argument.\n\nAssuming:\n- The LM Studio server at `http://127.0.0.1:1234` follows OpenAI-compatible API conventions.\n- The endpoint to list models is `http://127.0.0.1:1234/v1/models`.\n- Your script `scripts/eval_lmstudio_models.py` accepts a model name as an argument (e.g., `python scripts/eval_lmstudio_models.py --model <model-id>`).\n- You have `curl`, `jq`, and Python installed.\n\nHere\u2019s the **bash command** to do this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:23:21Z"}}
{"id": "20260121-001618-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 2408.2515239715576, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:23:23Z"}}
{"id": "20260121-001618-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures over oversized ones unless clearly justified.\n\n- **Leverage existing, proven models before building new ones**: Reuse fine-tuned open-source or pre-trained models that align with your task, minimizing training time and infrastructure needs\u2014only develop from scratch if no suitable model exists and the gain is substantial.", "prompt_tokens": 24, "completion_tokens": 133, "latency_ms": 21219.783306121826, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures over oversized ones unless clearly justified.\n\n- **Leverage existing, proven models before building new ones**: Reuse fine-tuned open-source or pre-trained models that align with your task, minimizing training time and infrastructure needs\u2014only develop from scratch if no suitable model exists and the gain is substantial.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:23:45Z"}}
{"id": "20260121-001618-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 3488.1675243377686, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:23:48Z"}}
{"id": "20260121-001618-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or requests to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate resolution.", "prompt_tokens": 22, "completion_tokens": 31, "latency_ms": 4239.390134811401, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or requests to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate resolution.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:23:53Z"}}
{"id": "20260121-001618-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1165.079116821289, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:23:54Z"}}
{"id": "20260121-001618-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for broad compatibility.\n- **Modular**: Encapsulated in a function for reusability.\n", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 54269.004344940186, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for broad compatibility.\n- **Modular**: Encapsulated in a function for reusability.\n", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:24:49Z"}}
{"id": "20260121-001618-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 4322.287559509277, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:24:53Z"}}
{"id": "20260121-001618-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you\u2019ll need to:\n\n1. First, **list all models** currently loaded in LM Studio\u2019s local server (which typically exposes an API endpoint like `/v1/models`).\n2. Then, for each model ID returned, invoke your Python script with the model name as an argument.\n\nAssuming:\n- The LM Studio server at `http://127.0.0.1:1234` follows the OpenAI-compatible API (as it does by default),\n- The endpoint `/v1/models` returns a JSON list of models with `\"id\"` fields,\n- Your script `scripts/eval_lmstudio_models.py` accepts a model name as an argument (e.g., `python scripts/eval_lmstudio_models.py --model <model-id>`),\n- You have `curl` and `jq` installed (standard on most Linux/macOS systems),\n\nHere\u2019s the **bash one-liner** to do this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 48200.24371147156, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you\u2019ll need to:\n\n1. First, **list all models** currently loaded in LM Studio\u2019s local server (which typically exposes an API endpoint like `/v1/models`).\n2. Then, for each model ID returned, invoke your Python script with the model name as an argument.\n\nAssuming:\n- The LM Studio server at `http://127.0.0.1:1234` follows the OpenAI-compatible API (as it does by default),\n- The endpoint `/v1/models` returns a JSON list of models with `\"id\"` fields,\n- Your script `scripts/eval_lmstudio_models.py` accepts a model name as an argument (e.g., `python scripts/eval_lmstudio_models.py --model <model-id>`),\n- You have `curl` and `jq` installed (standard on most Linux/macOS systems),\n\nHere\u2019s the **bash one-liner** to do this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:25:42Z"}}
{"id": "20260121-001618-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 2878.002166748047, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:25:45Z"}}
{"id": "20260121-001618-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the greatest business or user value per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures (e.g., distilled or quantized models) over larger ones unless performance gains justify the cost.\n\n- **Leverage existing, proven models before building new ones**: Reuse open-source or pre-trained models that align with your task domain to avoid redundant training costs; fine-tune only when necessary and validate on real-world data to ensure ROI.", "prompt_tokens": 24, "completion_tokens": 134, "latency_ms": 16511.55400276184, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the greatest business or user value per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures (e.g., distilled or quantized models) over larger ones unless performance gains justify the cost.\n\n- **Leverage existing, proven models before building new ones**: Reuse open-source or pre-trained models that align with your task domain to avoid redundant training costs; fine-tune only when necessary and validate on real-world data to ensure ROI.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:26:02Z"}}
{"id": "20260121-001618-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 3421.0383892059326, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:26:05Z"}}
{"id": "20260121-001618-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of work.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 4974.458456039429, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of work.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:26:11Z"}}
{"id": "20260121-001618-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1433.485746383667, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:26:12Z"}}
{"id": "20260121-001618-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for proper text handling.\n- **Return Value**: Returns the parsed data on success, `None`", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 43877.64668464661, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for proper text handling.\n- **Return Value**: Returns the parsed data on success, `None`", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:26:57Z"}}
{"id": "20260121-001618-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2499.152660369873, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:26:59Z"}}
{"id": "20260121-001618-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you\u2019ll need to:\n\n1. First, **list all models** currently loaded in LM Studio\u2019s local server (typically via its `/v1/models` endpoint).\n2. Then, for each model ID returned, invoke your Python script with the model name as an argument.\n\nHere's a complete, robust bash command that does this using `curl`, `jq` (for JSON parsing), and a loop:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model_id; do\n    echo \"Evaluating model: $model_id\"\n    python scripts/eval_lmstudio_models.py --model \"$model_id\" --base-url http://127.0.0.1:1234\ndone\n```\n\n---\n\n### \u2705 Prerequisites\n\n- Ensure `curl` and `jq` are installed:\n  ```bash\n  # On Ubuntu/Debian\n  sudo apt install curl jq\n\n  #", "prompt_tokens": 42, "completion_tokens": 255, "latency_ms": 34609.0521812439, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you\u2019ll need to:\n\n1. First, **list all models** currently loaded in LM Studio\u2019s local server (typically via its `/v1/models` endpoint).\n2. Then, for each model ID returned, invoke your Python script with the model name as an argument.\n\nHere's a complete, robust bash command that does this using `curl`, `jq` (for JSON parsing), and a loop:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model_id; do\n    echo \"Evaluating model: $model_id\"\n    python scripts/eval_lmstudio_models.py --model \"$model_id\" --base-url http://127.0.0.1:1234\ndone\n```\n\n---\n\n### \u2705 Prerequisites\n\n- Ensure `curl` and `jq` are installed:\n  ```bash\n  # On Ubuntu/Debian\n  sudo apt install curl jq\n\n  #", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:27:34Z"}}
{"id": "20260121-001618-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 3524.7297286987305, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:27:38Z"}}
{"id": "20260121-001618-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational cost, training time, or engineering effort\u2014favoring smaller, efficient architectures (like DistilBERT, TinyML, or quantized variants) over larger ones unless absolutely necessary.\n\n- **Leverage existing, well-supported models before building from scratch**: Reuse pre-trained, open-source, or community-vetted models that align with your task to minimize development time, reduce infrastructure burden, and avoid reinventing the wheel\u2014only fine-tune or customize when gains justify the cost.", "prompt_tokens": 24, "completion_tokens": 157, "latency_ms": 20622.159957885742, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational cost, training time, or engineering effort\u2014favoring smaller, efficient architectures (like DistilBERT, TinyML, or quantized variants) over larger ones unless absolutely necessary.\n\n- **Leverage existing, well-supported models before building from scratch**: Reuse pre-trained, open-source, or community-vetted models that align with your task to minimize development time, reduce infrastructure burden, and avoid reinventing the wheel\u2014only fine-tune or customize when gains justify the cost.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:27:59Z"}}
{"id": "20260121-001618-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 2915.861129760742, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:28:02Z"}}
{"id": "20260121-001618-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workload.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 4918.290853500366, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workload.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:28:07Z"}}
{"id": "20260121-001618-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1222.7294445037842, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:28:09Z"}}
{"id": "20260121-001618-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Error: Configuration file '{config_path}' not found.\")\n        return None\n    except json.JSONDecodeError:\n        print(f\"Error: Invalid JSON in '{config_path}'.\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading '{config_path}': {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n```\n\n### Features:\n- **Error handling**: Catches file not found, invalid JSON, and other exceptions.\n- **UTF-8 encoding**: Ensures compatibility with international characters.\n- **Return value**: Returns the parsed JSON data or `None` on error for safe usage.\n- **Clear feedback**:", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 37376.649141311646, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Error: Configuration file '{config_path}' not found.\")\n        return None\n    except json.JSONDecodeError:\n        print(f\"Error: Invalid JSON in '{config_path}'.\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading '{config_path}': {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n```\n\n### Features:\n- **Error handling**: Catches file not found, invalid JSON, and other exceptions.\n- **UTF-8 encoding**: Ensures compatibility with international characters.\n- **Return value**: Returns the parsed JSON data or `None` on error for safe usage.\n- **Clear feedback**:", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:28:46Z"}}
{"id": "20260121-001618-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2351.0799407958984, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:28:49Z"}}
{"id": "20260121-001618-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you\u2019ll need to:\n\n1. **List all model IDs** from the LM Studio local API endpoint.\n2. **Iterate over each model ID** and call your evaluation script with that model.\n\nLM Studio\u2019s local server (at `http://127.0.0.1:1234`) typically exposes an API endpoint like:\n\n```\nGET http://127.0.0.1:1234/v1/models\n```\n\nThis returns a JSON list of models, e.g.:\n```json\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"model-1\",\n      \"object\": \"model\",\n      \"created\": 1700000000,\n      \"owned_by\": \"local\"\n    },\n    {\n      \"id\": \"model-2\",\n      \"object\": \"model\",\n      \"created\": 1700000001,\n      \"owned_by\": \"local\"\n    }\n  ]\n}\n``", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 33020.76005935669, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you\u2019ll need to:\n\n1. **List all model IDs** from the LM Studio local API endpoint.\n2. **Iterate over each model ID** and call your evaluation script with that model.\n\nLM Studio\u2019s local server (at `http://127.0.0.1:1234`) typically exposes an API endpoint like:\n\n```\nGET http://127.0.0.1:1234/v1/models\n```\n\nThis returns a JSON list of models, e.g.:\n```json\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"model-1\",\n      \"object\": \"model\",\n      \"created\": 1700000000,\n      \"owned_by\": \"local\"\n    },\n    {\n      \"id\": \"model-2\",\n      \"object\": \"model\",\n      \"created\": 1700000001,\n      \"owned_by\": \"local\"\n    }\n  ]\n}\n``", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:29:22Z"}}
{"id": "20260121-001618-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 2700.718641281128, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:29:25Z"}}
{"id": "20260121-001618-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the greatest business or user value per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures (e.g., distilled or quantized models) over larger ones unless performance gains justify the cost.\n\n- **Leverage existing, proven models before building new ones**: Reuse open-source or pre-trained models that align with your task, minimizing training time and infrastructure needs\u2014only fine-tune or develop custom models when clear evidence shows they outperform available alternatives on your specific use case.", "prompt_tokens": 24, "completion_tokens": 142, "latency_ms": 18702.731132507324, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the greatest business or user value per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures (e.g., distilled or quantized models) over larger ones unless performance gains justify the cost.\n\n- **Leverage existing, proven models before building new ones**: Reuse open-source or pre-trained models that align with your task, minimizing training time and infrastructure needs\u2014only fine-tune or develop custom models when clear evidence shows they outperform available alternatives on your specific use case.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:29:44Z"}}
{"id": "20260121-001618-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 2920.16339302063, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:29:47Z"}}
{"id": "20260121-001618-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of work.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 4134.906053543091, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of work.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:29:52Z"}}
{"id": "20260121-001618-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1201.2584209442139, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:29:53Z"}}
{"id": "20260121-001618-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Notes:\n- Uses `utf-8` encoding for broad compatibility.\n- Includes comprehensive error handling for common issues (file not found, invalid JSON, etc.).\n- Returns `None` on failure so you can check if loading succeeded.\n-", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 29356.546878814697, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Notes:\n- Uses `utf-8` encoding for broad compatibility.\n- Includes comprehensive error handling for common issues (file not found, invalid JSON, etc.).\n- Returns `None` on failure so you can check if loading succeeded.\n-", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:30:23Z"}}
{"id": "20260121-001618-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2179.823398590088, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:30:25Z"}}
{"id": "20260121-001618-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you need to:\n\n1. First, **list all running models** via the LM Studio API endpoint.\n2. Then, **loop over each model ID** and invoke your evaluation script with that model.\n\nLM Studio\u2019s local API (at `http://127.0.0.1:1234`) typically exposes a `/v1/models` endpoint to list available models.\n\nHere's a complete, robust bash command to do this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model_id; do\n    echo \"Evaluating model: $model_id\"\n    python scripts/eval_lmstudio_models.py --model \"$model_id\" --api-base http://127.0.0.1:1234\ndone\n```\n\n### Explanation:\n\n- `curl -s http://127.0.0.1:1234/v1/models`  \n ", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 29473.162174224854, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you need to:\n\n1. First, **list all running models** via the LM Studio API endpoint.\n2. Then, **loop over each model ID** and invoke your evaluation script with that model.\n\nLM Studio\u2019s local API (at `http://127.0.0.1:1234`) typically exposes a `/v1/models` endpoint to list available models.\n\nHere's a complete, robust bash command to do this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model_id; do\n    echo \"Evaluating model: $model_id\"\n    python scripts/eval_lmstudio_models.py --model \"$model_id\" --api-base http://127.0.0.1:1234\ndone\n```\n\n### Explanation:\n\n- `curl -s http://127.0.0.1:1234/v1/models`  \n ", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:30:55Z"}}
{"id": "20260121-001618-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 3408.0450534820557, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:30:58Z"}}
{"id": "20260121-001618-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures or fine-tuned open-source alternatives over large, expensive proprietary ones.\n\n- **Leverage existing, validated models before building new ones**: Reuse pre-trained models or solutions already proven in similar domains to avoid redundant training costs and accelerate deployment\u2014only develop custom models when clear, measurable gains justify the investment.", "prompt_tokens": 24, "completion_tokens": 135, "latency_ms": 15876.56283378601, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures or fine-tuned open-source alternatives over large, expensive proprietary ones.\n\n- **Leverage existing, validated models before building new ones**: Reuse pre-trained models or solutions already proven in similar domains to avoid redundant training costs and accelerate deployment\u2014only develop custom models when clear, measurable gains justify the investment.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:31:15Z"}}
{"id": "20260121-001618-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 2784.1203212738037, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:31:18Z"}}
{"id": "20260121-001618-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate fulfillment of responsibilities.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 4156.631946563721, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate fulfillment of responsibilities.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:31:22Z"}}
{"id": "20260121-001618-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1121.7691898345947, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:31:23Z"}}
{"id": "20260121-001618-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses UTF-8 encoding for compatibility with most modern JSON files.\n- **Return Value**: Returns the parsed data on success, `", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 28947.284698486328, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses UTF-8 encoding for compatibility with most modern JSON files.\n- **Return Value**: Returns the parsed data on success, `", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:31:53Z"}}
{"id": "20260121-001618-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2138.2405757904053, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:31:55Z"}}
{"id": "20260121-001618-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you\u2019ll need to:\n\n1. **List all model names** currently loaded in LM Studio\u2019s local server (typically via its API).\n2. **Iterate over each model**, and invoke your Python script with the model name as an argument.\n\nLM Studio exposes a local API at `http://127.0.0.1:1234/v1/models` to list loaded models (as of recent versions). The response is JSON, containing an array of model objects with an `id` field \u2014 that\u2019s the model name you want.\n\n---\n\n### \u2705 Bash Command (One-liner):\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model; do echo \"Evaluating $model\"; python scripts/eval_lmstudio_models.py --model \"$model\"; done\n```\n\n---\n\n### \ud83d\udd0d Breakdown:\n\n| Part | Purpose |\n|------|---------|\n| `curl -s http://12", "prompt_tokens": 42, "completion_tokens": 254, "latency_ms": 29734.92741584778, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you\u2019ll need to:\n\n1. **List all model names** currently loaded in LM Studio\u2019s local server (typically via its API).\n2. **Iterate over each model**, and invoke your Python script with the model name as an argument.\n\nLM Studio exposes a local API at `http://127.0.0.1:1234/v1/models` to list loaded models (as of recent versions). The response is JSON, containing an array of model objects with an `id` field \u2014 that\u2019s the model name you want.\n\n---\n\n### \u2705 Bash Command (One-liner):\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model; do echo \"Evaluating $model\"; python scripts/eval_lmstudio_models.py --model \"$model\"; done\n```\n\n---\n\n### \ud83d\udd0d Breakdown:\n\n| Part | Purpose |\n|------|---------|\n| `curl -s http://12", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:32:25Z"}}
{"id": "20260121-001618-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 2255.0318241119385, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:32:28Z"}}
{"id": "20260121-001618-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the greatest business or user value relative to their computational, financial, and maintenance costs\u2014favoring smaller, efficient architectures (e.g., distilled or quantized models) over larger ones unless performance gains justify the overhead.\n\n- **Leverage existing, proven models before building new ones**: Reuse open-source or pre-trained models that align closely with your use case to avoid redundant training costs and accelerate deployment\u2014only fine-tune or train from scratch if there\u2019s a clear, measurable advantage that justifies the resource investment.", "prompt_tokens": 24, "completion_tokens": 144, "latency_ms": 17302.953243255615, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the greatest business or user value relative to their computational, financial, and maintenance costs\u2014favoring smaller, efficient architectures (e.g., distilled or quantized models) over larger ones unless performance gains justify the overhead.\n\n- **Leverage existing, proven models before building new ones**: Reuse open-source or pre-trained models that align closely with your use case to avoid redundant training costs and accelerate deployment\u2014only fine-tune or train from scratch if there\u2019s a clear, measurable advantage that justifies the resource investment.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:32:45Z"}}
{"id": "20260121-001618-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 2802.0434379577637, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:32:48Z"}}
{"id": "20260121-001618-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workload.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 5490.65375328064, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of workload.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:32:54Z"}}
{"id": "20260121-001618-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1156.7070484161377, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:32:55Z"}}
{"id": "20260121-001618-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for broad compatibility.\n- **Modular**: Encapsulated in a function for reusability.\n", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 37573.301553726196, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for broad compatibility.\n- **Modular**: Encapsulated in a function for reusability.\n", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:33:33Z"}}
{"id": "20260121-001618-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2422.6784706115723, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:33:36Z"}}
{"id": "20260121-001618-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you'll need to:\n\n1. First, **list all running models** via LM Studio\u2019s local API (typically `/v1/models`).\n2. Then, for each model ID, invoke your evaluation script with the model name as an argument.\n\nAssuming:\n- The LM Studio server is running at `http://127.0.0.1:1234`\n- It exposes a standard OpenAI-compatible API endpoint `/v1/models` that returns a JSON list of models\n- Your script `scripts/eval_lmstudio_models.py` accepts a model name as an argument (e.g., `python scripts/eval_lmstudio_models.py --model <model-id>`)\n\nHere\u2019s the **bash command** to do this in one line:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model; do echo \"Evaluating $model\"; python scripts/eval_lmstudio_models.py --model \"$model", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 32009.67288017273, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you'll need to:\n\n1. First, **list all running models** via LM Studio\u2019s local API (typically `/v1/models`).\n2. Then, for each model ID, invoke your evaluation script with the model name as an argument.\n\nAssuming:\n- The LM Studio server is running at `http://127.0.0.1:1234`\n- It exposes a standard OpenAI-compatible API endpoint `/v1/models` that returns a JSON list of models\n- Your script `scripts/eval_lmstudio_models.py` accepts a model name as an argument (e.g., `python scripts/eval_lmstudio_models.py --model <model-id>`)\n\nHere\u2019s the **bash command** to do this in one line:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model; do echo \"Evaluating $model\"; python scripts/eval_lmstudio_models.py --model \"$model", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:34:08Z"}}
{"id": "20260121-001618-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 2422.9912757873535, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:34:11Z"}}
{"id": "20260121-001618-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational cost, training time, or engineering effort\u2014favoring smaller, efficient architectures (like distilled or quantized models) over larger ones when performance is comparable.\n\n- **Leverage existing, proven models before building new ones**: Reuse open-source or pre-trained models that align with your use case to avoid redundant development; fine-tune only when necessary, and always validate against a baseline to ensure the added cost is justified.", "prompt_tokens": 24, "completion_tokens": 144, "latency_ms": 18043.917179107666, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational cost, training time, or engineering effort\u2014favoring smaller, efficient architectures (like distilled or quantized models) over larger ones when performance is comparable.\n\n- **Leverage existing, proven models before building new ones**: Reuse open-source or pre-trained models that align with your use case to avoid redundant development; fine-tune only when necessary, and always validate against a baseline to ensure the added cost is justified.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:34:29Z"}}
{"id": "20260121-001618-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 2646.9075679779053, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:34:32Z"}}
{"id": "20260121-001618-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and consistent handling of workflows.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 4257.02977180481, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and consistent handling of workflows.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:34:36Z"}}
{"id": "20260121-001618-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1156.8045616149902, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:34:38Z"}}
{"id": "20260121-001618-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n```\n\n### Key features:\n- Uses `with open()` for safe file handling (auto-closes the file).\n- Specifies `encoding='utf-8'` for cross-platform compatibility.\n- Includes comprehensive error handling for common issues:\n  - File not found\n  - Invalid JSON syntax\n  - Other I", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 29229.21919822693, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n```\n\n### Key features:\n- Uses `with open()` for safe file handling (auto-closes the file).\n- Specifies `encoding='utf-8'` for cross-platform compatibility.\n- Includes comprehensive error handling for common issues:\n  - File not found\n  - Invalid JSON syntax\n  - Other I", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:35:07Z"}}
{"id": "20260121-001618-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 1993.3960437774658, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:35:10Z"}}
{"id": "20260121-001618-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you need to:\n\n1. First, **list all running models** from the LM Studio local API endpoint.\n2. Then, **loop over each model ID** and invoke your evaluation script with that model.\n\nLM Studio\u2019s local server at `http://127.0.0.1:1234` typically exposes an API endpoint like:\n\n```\nGET http://127.0.0.1:1234/v1/models\n```\n\nThis returns a JSON list of models, e.g.:\n```json\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"model-1\",\n      \"object\": \"model\",\n      \"created\": 1700000000,\n      \"owned_by\": \"local\"\n    },\n    {\n      \"id\": \"model-2\",\n      \"object\": \"model\",\n      \"created\": 1700000001,\n      \"owned_by\": \"local\"\n    }\n  ]\n}\n", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 29974.627017974854, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** available at `http://127.0.0.1:1234`, you need to:\n\n1. First, **list all running models** from the LM Studio local API endpoint.\n2. Then, **loop over each model ID** and invoke your evaluation script with that model.\n\nLM Studio\u2019s local server at `http://127.0.0.1:1234` typically exposes an API endpoint like:\n\n```\nGET http://127.0.0.1:1234/v1/models\n```\n\nThis returns a JSON list of models, e.g.:\n```json\n{\n  \"object\": \"list\",\n  \"data\": [\n    {\n      \"id\": \"model-1\",\n      \"object\": \"model\",\n      \"created\": 1700000000,\n      \"owned_by\": \"local\"\n    },\n    {\n      \"id\": \"model-2\",\n      \"object\": \"model\",\n      \"created\": 1700000001,\n      \"owned_by\": \"local\"\n    }\n  ]\n}\n", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:35:40Z"}}
{"id": "20260121-001618-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 2220.2134132385254, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:35:42Z"}}
{"id": "20260121-001618-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the greatest business or user value per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures (e.g., distilled or quantized models) over larger ones unless performance gains justify the cost.\n\n- **Leverage existing, proven models before building new ones**: Reuse open-source or pre-trained models that align with your use case to avoid redundant training costs and accelerate deployment\u2014only fine-tune or train from scratch if there\u2019s a clear, measurable advantage that justifies the investment.", "prompt_tokens": 24, "completion_tokens": 143, "latency_ms": 16732.31029510498, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the greatest business or user value per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures (e.g., distilled or quantized models) over larger ones unless performance gains justify the cost.\n\n- **Leverage existing, proven models before building new ones**: Reuse open-source or pre-trained models that align with your use case to avoid redundant training costs and accelerate deployment\u2014only fine-tune or train from scratch if there\u2019s a clear, measurable advantage that justifies the investment.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:35:59Z"}}
{"id": "20260121-001618-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 2635.13445854187, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:36:02Z"}}
{"id": "20260121-001618-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of work.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 4217.305421829224, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of work.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:36:07Z"}}
{"id": "20260121-001618-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1201.8122673034668, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:36:08Z"}}
{"id": "20260121-001618-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for compatibility with most modern systems.\n- **Return Value**: Returns the parsed data on success, `", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 30445.84631919861, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding**: Uses `utf-8` for compatibility with most modern systems.\n- **Return Value**: Returns the parsed data on success, `", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:36:39Z"}}
{"id": "20260121-001618-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2387.1068954467773, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:36:41Z"}}
{"id": "20260121-001618-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run `scripts/eval_lmstudio_models.py` against **all models** available at the LM Studio local server (`http://127.0.0.1:1234`), you need to:\n\n1. **List all running models** via the LM Studio API endpoint.\n2. **Iterate over each model ID** and call your Python script with that model as an argument.\n\nLM Studio\u2019s local server (on `http://127.0.0.1:1234`) exposes a `/v1/models` endpoint that returns a JSON list of available models.\n\nHere's a complete, robust bash command to do this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model_id; do\n  echo \"Evaluating model: $model_id\"\n  python scripts/eval_lmstudio_models.py --model \"$model_id\" --base-url http://127.0.0.1:1234\ndone\n```\n\n### Explanation:\n\n- `curl -s http://127.0.0.1:123", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 31096.282720565796, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run `scripts/eval_lmstudio_models.py` against **all models** available at the LM Studio local server (`http://127.0.0.1:1234`), you need to:\n\n1. **List all running models** via the LM Studio API endpoint.\n2. **Iterate over each model ID** and call your Python script with that model as an argument.\n\nLM Studio\u2019s local server (on `http://127.0.0.1:1234`) exposes a `/v1/models` endpoint that returns a JSON list of available models.\n\nHere's a complete, robust bash command to do this:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model_id; do\n  echo \"Evaluating model: $model_id\"\n  python scripts/eval_lmstudio_models.py --model \"$model_id\" --base-url http://127.0.0.1:1234\ndone\n```\n\n### Explanation:\n\n- `curl -s http://127.0.0.1:123", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:37:13Z"}}
{"id": "20260121-001618-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 2376.384496688843, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:37:15Z"}}
{"id": "20260121-001618-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures (like distilled or quantized models) over larger ones when performance is comparable.\n\n- **Leverage existing, well-supported models before training from scratch**: Opt for pre-trained, open-source, or community-vetted models that require minimal fine-tuning or infrastructure investment, reducing development time, energy use, and the need for large labeled datasets.", "prompt_tokens": 24, "completion_tokens": 143, "latency_ms": 16510.30731201172, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures (like distilled or quantized models) over larger ones when performance is comparable.\n\n- **Leverage existing, well-supported models before training from scratch**: Opt for pre-trained, open-source, or community-vetted models that require minimal fine-tuning or infrastructure investment, reducing development time, energy use, and the need for large labeled datasets.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:37:32Z"}}
{"id": "20260121-001618-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 2795.466661453247, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:37:35Z"}}
{"id": "20260121-001618-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of work.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 4053.539991378784, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "A task routing system automatically directs tasks or work items to the most appropriate person or team based on predefined rules, ensuring efficient, timely, and accurate handling of work.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:37:39Z"}}
{"id": "20260121-001618-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "UrgentCode", "prompt_tokens": 31, "completion_tokens": 5, "latency_ms": 1106.865406036377, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "UrgentCode", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:37:41Z"}}
{"id": "20260121-001618-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding Specified**: Uses `utf-8` encoding for compatibility.\n- **Returns `None` on Failure**: Allows the calling code to", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 28601.979732513428, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Here's a clean and safe Python snippet to load JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\nimport os\n\ndef load_model_routing_config():\n    config_path = 'guild/config/model_routing.json'\n    \n    try:\n        with open(config_path, 'r', encoding='utf-8') as file:\n            config_data = json.load(file)\n        return config_data\n    except FileNotFoundError:\n        print(f\"Configuration file not found: {config_path}\")\n        return None\n    except json.JSONDecodeError as e:\n        print(f\"Invalid JSON in {config_path}: {e}\")\n        return None\n    except Exception as e:\n        print(f\"Unexpected error loading {config_path}: {e}\")\n        return None\n\n# Usage example\nif __name__ == \"__main__\":\n    config = load_model_routing_config()\n    if config is not None:\n        print(\"Configuration loaded successfully:\")\n        print(config)\n    else:\n        print(\"Failed to load configuration.\")\n```\n\n### Key Features:\n- **Error Handling**: Catches common issues like missing files or invalid JSON.\n- **Encoding Specified**: Uses `utf-8` encoding for compatibility.\n- **Returns `None` on Failure**: Allows the calling code to", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:38:10Z"}}
{"id": "20260121-001618-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 2147.423028945923, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:38:12Z"}}
{"id": "20260121-001618-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** hosted on `http://127.0.0.1:1234`, you\u2019ll need to:\n\n1. **List all available models** from the LM Studio local API endpoint.\n2. **Iterate over each model name** and call your evaluation script with that model as an argument.\n\nLM Studio\u2019s local server at `http://127.0.0.1:1234` typically exposes a `/v1/models` endpoint (following OpenAI-compatible API format) that returns a JSON list of available models.\n\n---\n\n### \u2705 Bash Command (One-liner):\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model; do echo \"Evaluating model: $model\"; python scripts/eval_lmstudio_models.py --model \"$model\"; done\n```\n\n---\n\n### \ud83d\udd0d Explanation:\n\n- `curl -s http://127.0.0.1:1234/v1/models`  \n  \u2192 Fetches the list of models silently (`-s", "prompt_tokens": 42, "completion_tokens": 254, "latency_ms": 29089.579105377197, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "To run the script `scripts/eval_lmstudio_models.py` against **all models** hosted on `http://127.0.0.1:1234`, you\u2019ll need to:\n\n1. **List all available models** from the LM Studio local API endpoint.\n2. **Iterate over each model name** and call your evaluation script with that model as an argument.\n\nLM Studio\u2019s local server at `http://127.0.0.1:1234` typically exposes a `/v1/models` endpoint (following OpenAI-compatible API format) that returns a JSON list of available models.\n\n---\n\n### \u2705 Bash Command (One-liner):\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read -r model; do echo \"Evaluating model: $model\"; python scripts/eval_lmstudio_models.py --model \"$model\"; done\n```\n\n---\n\n### \ud83d\udd0d Explanation:\n\n- `curl -s http://127.0.0.1:1234/v1/models`  \n  \u2192 Fetches the list of models silently (`-s", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:38:41Z"}}
{"id": "20260121-001618-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 2174.022674560547, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:38:44Z"}}
{"id": "20260121-001618-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures over large, expensive ones unless clearly justified.\n\n- **Leverage existing, well-supported models and infrastructure**: Avoid building from scratch; reuse proven, open-source, or internally vetted models that integrate smoothly with current toolchains to minimize development time, maintenance overhead, and risk.", "prompt_tokens": 24, "completion_tokens": 129, "latency_ms": 15045.178890228271, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-next-80b", "response": "Certainly! Here are two concise, actionable bullet rules for how Guild should pick a model when resources are tight:\n\n- **Prioritize models with the highest impact-to-cost ratio**: Choose models that deliver the most value (e.g., accuracy, user satisfaction, business outcome) per unit of computational, financial, or human resource spent\u2014favoring smaller, efficient architectures over large, expensive ones unless clearly justified.\n\n- **Leverage existing, well-supported models and infrastructure**: Avoid building from scratch; reuse proven, open-source, or internally vetted models that integrate smoothly with current toolchains to minimize development time, maintenance overhead, and risk.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001618", "created_at": "2026-01-21T00:38:59Z"}}
