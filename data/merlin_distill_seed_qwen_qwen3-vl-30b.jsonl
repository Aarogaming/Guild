{"id": "20260120-203024-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 24510.90168952942, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:30:49Z"}}
{"id": "20260120-203024-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "A task routing system automatically assigns tasks to the most appropriate individuals or teams based on predefined criteria such as skills, workload, or availability to ensure efficient and timely completion.", "prompt_tokens": 22, "completion_tokens": 34, "latency_ms": 1535.2809429168701, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "A task routing system automatically assigns tasks to the most appropriate individuals or teams based on predefined criteria such as skills, workload, or availability to ensure efficient and timely completion.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:30:51Z"}}
{"id": "20260120-203024-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "urgent", "prompt_tokens": 31, "completion_tokens": 2, "latency_ms": 426.5456199645996, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "urgent", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:30:51Z"}}
{"id": "20260120-203024-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "Here's a Python snippet that loads JSON from the file `guild/config/model_routing.json`:\n\n```python\nimport json\n\n# Load JSON from the specified file\ntry:\n    with open('guild/config/model_routing.json', 'r', encoding='utf-8') as file:\n        data = json.load(file)\n    print(\"JSON loaded successfully:\", data)\nexcept FileNotFoundError:\n    print(\"File not found: guild/config/model_routing.json\")\nexcept json.JSONDecodeError as e:\n    print(f\"Error decoding JSON: {e}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n```\n\n### Notes:\n- The file path is relative to the current working directory.\n- The `encoding='utf-8'` parameter ensures proper handling of Unicode characters.\n- Error handling is included to catch common issues like file not found or invalid JSON.\n- `data` will contain the parsed JSON object (usually a dictionary or list).", "prompt_tokens": 23, "completion_tokens": 194, "latency_ms": 9564.752578735352, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "Here's a Python snippet that loads JSON from the file `guild/config/model_routing.json`:\n\n```python\nimport json\n\n# Load JSON from the specified file\ntry:\n    with open('guild/config/model_routing.json', 'r', encoding='utf-8') as file:\n        data = json.load(file)\n    print(\"JSON loaded successfully:\", data)\nexcept FileNotFoundError:\n    print(\"File not found: guild/config/model_routing.json\")\nexcept json.JSONDecodeError as e:\n    print(f\"Error decoding JSON: {e}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n```\n\n### Notes:\n- The file path is relative to the current working directory.\n- The `encoding='utf-8'` parameter ensures proper handling of Unicode characters.\n- Error handling is included to catch common issues like file not found or invalid JSON.\n- `data` will contain the parsed JSON object (usually a dictionary or list).", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:31:01Z"}}
{"id": "20260120-203024-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 894.9198722839355, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:31:02Z"}}
{"id": "20260120-203024-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "To run the script `scripts/eval_lmstudio_models.py` against all models available at `http://127.0.0.1:1234`, you'll first need to:\n\n1. **Get a list of available models** from the LM Studio API (usually via a `/v1/models` endpoint).\n2. **Loop through each model** and run the evaluation script with the appropriate model name.\n\nAssuming the LM Studio API exposes a `/v1/models` endpoint that returns a JSON list of model names (e.g., `{\"data\": [{\"id\": \"model1\"}, {\"id\": \"model2\"}, ...]}`), here's a **bash command** that does this:\n\n```bash\n#!/bin/bash\n\n# Get the list of models from LM Studio API\nmodels=$(curl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id')\n\n# Loop through each model and run the evaluation script\nfor model in $models; do\n    echo \"Evaluating model: $model\"\n    python scripts/eval_lmstudio_models.py --model \"$model\"\ndone\n```\n\n### Requirements:\n- `curl` \u2014 for making", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 13231.646537780762, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "To run the script `scripts/eval_lmstudio_models.py` against all models available at `http://127.0.0.1:1234`, you'll first need to:\n\n1. **Get a list of available models** from the LM Studio API (usually via a `/v1/models` endpoint).\n2. **Loop through each model** and run the evaluation script with the appropriate model name.\n\nAssuming the LM Studio API exposes a `/v1/models` endpoint that returns a JSON list of model names (e.g., `{\"data\": [{\"id\": \"model1\"}, {\"id\": \"model2\"}, ...]}`), here's a **bash command** that does this:\n\n```bash\n#!/bin/bash\n\n# Get the list of models from LM Studio API\nmodels=$(curl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id')\n\n# Loop through each model and run the evaluation script\nfor model in $models; do\n    echo \"Evaluating model: $model\"\n    python scripts/eval_lmstudio_models.py --model \"$model\"\ndone\n```\n\n### Requirements:\n- `curl` \u2014 for making", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:31:16Z"}}
{"id": "20260120-203024-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 998.8143444061279, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:31:17Z"}}
{"id": "20260120-203024-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "- **Prioritize Models with High Impact-to-Cost Ratio**: Select models that deliver the greatest value or performance improvement relative to their resource requirements, ensuring efficient use of limited computational and financial resources.  \n- **Choose Models with Low Maintenance and Scalability Needs**: Opt for models that require minimal ongoing tuning, monitoring, and infrastructure support, reducing long-term operational overhead when resources are constrained.", "prompt_tokens": 24, "completion_tokens": 78, "latency_ms": 3344.6497917175293, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "- **Prioritize Models with High Impact-to-Cost Ratio**: Select models that deliver the greatest value or performance improvement relative to their resource requirements, ensuring efficient use of limited computational and financial resources.  \n- **Choose Models with Low Maintenance and Scalability Needs**: Opt for models that require minimal ongoing tuning, monitoring, and infrastructure support, reducing long-term operational overhead when resources are constrained.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:31:21Z"}}
{"id": "20260120-203024-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 1105.6134700775146, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:31:22Z"}}
{"id": "20260120-203024-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "A task routing system automatically assigns tasks to the most appropriate individuals or teams based on predefined criteria such as skills, workload, or availability to ensure efficient and timely task completion.", "prompt_tokens": 22, "completion_tokens": 35, "latency_ms": 1542.8643226623535, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "A task routing system automatically assigns tasks to the most appropriate individuals or teams based on predefined criteria such as skills, workload, or availability to ensure efficient and timely task completion.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:31:24Z"}}
{"id": "20260120-203024-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "urgent", "prompt_tokens": 31, "completion_tokens": 2, "latency_ms": 346.7538356781006, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "urgent", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:31:25Z"}}
{"id": "20260120-203024-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "Here's a Python snippet that loads JSON from the file `guild/config/model_routing.json`:\n\n```python\nimport json\n\ntry:\n    with open('guild/config/model_routing.json', 'r') as file:\n        data = json.load(file)\n    print(\"JSON loaded successfully:\")\n    print(data)\nexcept FileNotFoundError:\n    print(\"Error: 'guild/config/model_routing.json' not found.\")\nexcept json.JSONDecodeError as e:\n    print(f\"Error: Invalid JSON format. {e}\")\nexcept Exception as e:\n    print(f\"An unexpected error occurred: {e}\")\n```\n\n### Notes:\n- This snippet uses `json.load()` to parse the JSON file.\n- It includes error handling for common issues like file not found, invalid JSON, and other exceptions.\n- The `with open(...)` context manager ensures the file is properly closed after reading.\n- Adjust the file path if your script is run from a different directory.", "prompt_tokens": 23, "completion_tokens": 190, "latency_ms": 14075.969934463501, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "Here's a Python snippet that loads JSON from the file `guild/config/model_routing.json`:\n\n```python\nimport json\n\ntry:\n    with open('guild/config/model_routing.json', 'r') as file:\n        data = json.load(file)\n    print(\"JSON loaded successfully:\")\n    print(data)\nexcept FileNotFoundError:\n    print(\"Error: 'guild/config/model_routing.json' not found.\")\nexcept json.JSONDecodeError as e:\n    print(f\"Error: Invalid JSON format. {e}\")\nexcept Exception as e:\n    print(f\"An unexpected error occurred: {e}\")\n```\n\n### Notes:\n- This snippet uses `json.load()` to parse the JSON file.\n- It includes error handling for common issues like file not found, invalid JSON, and other exceptions.\n- The `with open(...)` context manager ensures the file is properly closed after reading.\n- Adjust the file path if your script is run from a different directory.", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:31:39Z"}}
{"id": "20260120-203024-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 1242.7387237548828, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:31:40Z"}}
{"id": "20260120-203024-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "To run the `scripts/eval_lmstudio_models.py` script against all models available at `http://127.0.0.1:1234`, you can use a bash command that:\n\n1. Queries the API to get the list of available models (assuming the API returns a JSON list of model names),\n2. Loops through each model and runs the evaluation script.\n\nAssuming the API endpoint for listing models is `http://127.0.0.1:1234/v1/models` and returns a JSON like:\n\n```json\n{\n  \"data\": [\n    {\"id\": \"model1\"},\n    {\"id\": \"model2\"},\n    ...\n  ]\n}\n```\n\nYou can use `curl` and `jq` to parse the response and loop over the models.\n\nHere's a complete bash command:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read model; do\n    echo \"Evaluating model: $model\"\n    python scripts/eval_lmstudio_models.py --model \"$model\"\ndone\n```\n\n### Explanation:\n- `curl -s http", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 11874.696016311646, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "To run the `scripts/eval_lmstudio_models.py` script against all models available at `http://127.0.0.1:1234`, you can use a bash command that:\n\n1. Queries the API to get the list of available models (assuming the API returns a JSON list of model names),\n2. Loops through each model and runs the evaluation script.\n\nAssuming the API endpoint for listing models is `http://127.0.0.1:1234/v1/models` and returns a JSON like:\n\n```json\n{\n  \"data\": [\n    {\"id\": \"model1\"},\n    {\"id\": \"model2\"},\n    ...\n  ]\n}\n```\n\nYou can use `curl` and `jq` to parse the response and loop over the models.\n\nHere's a complete bash command:\n\n```bash\ncurl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id' | while read model; do\n    echo \"Evaluating model: $model\"\n    python scripts/eval_lmstudio_models.py --model \"$model\"\ndone\n```\n\n### Explanation:\n- `curl -s http", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:31:52Z"}}
{"id": "20260120-203024-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 1094.4287776947021, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:31:54Z"}}
{"id": "20260120-203024-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "- **Prioritize Models with High Impact-to-Cost Ratio**: Select models that deliver the greatest value or performance improvement relative to their resource requirements, ensuring efficient use of limited computational and financial resources.  \n- **Leverage Pre-trained Models and Transfer Learning**: Choose models that can be fine-tuned on existing data rather than training from scratch, reducing time, energy, and data needs while still achieving strong results.", "prompt_tokens": 24, "completion_tokens": 84, "latency_ms": 3839.8094177246094, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "- **Prioritize Models with High Impact-to-Cost Ratio**: Select models that deliver the greatest value or performance improvement relative to their resource requirements, ensuring efficient use of limited computational and financial resources.  \n- **Leverage Pre-trained Models and Transfer Learning**: Choose models that can be fine-tuned on existing data rather than training from scratch, reducing time, energy, and data needs while still achieving strong results.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:31:58Z"}}
{"id": "20260120-203024-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 1117.0892715454102, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:31:59Z"}}
{"id": "20260120-203024-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "A task routing system automatically assigns tasks to the most appropriate individuals or teams based on predefined criteria such as skills, workload, or availability to ensure efficient and timely task completion.", "prompt_tokens": 22, "completion_tokens": 35, "latency_ms": 1748.744249343872, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "A task routing system automatically assigns tasks to the most appropriate individuals or teams based on predefined criteria such as skills, workload, or availability to ensure efficient and timely task completion.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:32:01Z"}}
{"id": "20260120-203024-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "urgent", "prompt_tokens": 31, "completion_tokens": 2, "latency_ms": 357.6979637145996, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "urgent", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:32:02Z"}}
{"id": "20260120-203024-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "Here's a Python snippet that loads JSON from the file `guild/config/model_routing.json`:\n\n```python\nimport json\n\n# Load JSON from the specified file\ntry:\n    with open('guild/config/model_routing.json', 'r', encoding='utf-8') as file:\n        data = json.load(file)\n    print(\"JSON loaded successfully:\")\n    print(data)\nexcept FileNotFoundError:\n    print(\"File not found: guild/config/model_routing.json\")\nexcept json.JSONDecodeError as e:\n    print(f\"Error decoding JSON: {e}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n```\n\n### Notes:\n- The file path is relative to the current working directory.\n- The `encoding='utf-8'` ensures proper handling of Unicode characters.\n- Error handling is included to manage common issues like file not found or invalid JSON.\n- `data` will contain the parsed JSON object (usually a dictionary or list).", "prompt_tokens": 23, "completion_tokens": 195, "latency_ms": 10001.126766204834, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "Here's a Python snippet that loads JSON from the file `guild/config/model_routing.json`:\n\n```python\nimport json\n\n# Load JSON from the specified file\ntry:\n    with open('guild/config/model_routing.json', 'r', encoding='utf-8') as file:\n        data = json.load(file)\n    print(\"JSON loaded successfully:\")\n    print(data)\nexcept FileNotFoundError:\n    print(\"File not found: guild/config/model_routing.json\")\nexcept json.JSONDecodeError as e:\n    print(f\"Error decoding JSON: {e}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n```\n\n### Notes:\n- The file path is relative to the current working directory.\n- The `encoding='utf-8'` ensures proper handling of Unicode characters.\n- Error handling is included to manage common issues like file not found or invalid JSON.\n- `data` will contain the parsed JSON object (usually a dictionary or list).", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:32:12Z"}}
{"id": "20260120-203024-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 768.9907550811768, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:32:13Z"}}
{"id": "20260120-203024-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "To run the script `scripts/eval_lmstudio_models.py` against all models available at `http://127.0.0.1:1234`, you'll first need to:\n\n1. **Get a list of available models** from the LM Studio API (usually via a `/v1/models` endpoint).\n2. **Loop through each model** and run the evaluation script with the appropriate model name.\n\nAssuming the LM Studio API exposes a `/v1/models` endpoint that returns a JSON list of models (e.g., `{\"data\": [{\"id\": \"model-1\"}, {\"id\": \"model-2\"}, ...]}`), here's a **bash command** that does this:\n\n```bash\n#!/bin/bash\n\n# Get the list of models from the LM Studio API\nmodels=$(curl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id')\n\n# Loop through each model and run the evaluation script\nfor model in $models; do\n    echo \"Evaluating model: $model\"\n    python scripts/eval_lmstudio_models.py --model \"$model\"\ndone\n```\n\n### Requirements:\n- `curl` must", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 12561.17033958435, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "To run the script `scripts/eval_lmstudio_models.py` against all models available at `http://127.0.0.1:1234`, you'll first need to:\n\n1. **Get a list of available models** from the LM Studio API (usually via a `/v1/models` endpoint).\n2. **Loop through each model** and run the evaluation script with the appropriate model name.\n\nAssuming the LM Studio API exposes a `/v1/models` endpoint that returns a JSON list of models (e.g., `{\"data\": [{\"id\": \"model-1\"}, {\"id\": \"model-2\"}, ...]}`), here's a **bash command** that does this:\n\n```bash\n#!/bin/bash\n\n# Get the list of models from the LM Studio API\nmodels=$(curl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id')\n\n# Loop through each model and run the evaluation script\nfor model in $models; do\n    echo \"Evaluating model: $model\"\n    python scripts/eval_lmstudio_models.py --model \"$model\"\ndone\n```\n\n### Requirements:\n- `curl` must", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:32:26Z"}}
{"id": "20260120-203024-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 1022.7494239807129, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:32:27Z"}}
{"id": "20260120-203024-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "- **Prioritize models with high impact relative to cost**: Select models that deliver the greatest value or performance improvement per unit of resource consumed, ensuring efficient use of limited budgets and computational power.  \n- **Choose models with strong scalability and adaptability**: Opt for models that can be easily fine-tuned or scaled for future needs, reducing long-term costs and enabling reuse across multiple projects.", "prompt_tokens": 24, "completion_tokens": 78, "latency_ms": 4053.5757541656494, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "- **Prioritize models with high impact relative to cost**: Select models that deliver the greatest value or performance improvement per unit of resource consumed, ensuring efficient use of limited budgets and computational power.  \n- **Choose models with strong scalability and adaptability**: Opt for models that can be easily fine-tuned or scaled for future needs, reducing long-term costs and enabling reuse across multiple projects.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:32:32Z"}}
{"id": "20260120-203024-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 1002.4909973144531, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:32:33Z"}}
{"id": "20260120-203024-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "A task routing system automatically assigns tasks to the most appropriate individuals or teams based on predefined criteria such as skill, availability, or workload to improve efficiency and ensure timely completion.", "prompt_tokens": 22, "completion_tokens": 35, "latency_ms": 1474.9586582183838, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "A task routing system automatically assigns tasks to the most appropriate individuals or teams based on predefined criteria such as skill, availability, or workload to improve efficiency and ensure timely completion.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:32:35Z"}}
{"id": "20260120-203024-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "urgent", "prompt_tokens": 31, "completion_tokens": 2, "latency_ms": 487.75243759155273, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "urgent", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:32:35Z"}}
{"id": "20260120-203024-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "Here's a Python snippet that loads JSON from the file `guild/config/model_routing.json`:\n\n```python\nimport json\n\n# Load JSON from the specified file\ntry:\n    with open('guild/config/model_routing.json', 'r', encoding='utf-8') as file:\n        data = json.load(file)\n    print(\"JSON loaded successfully:\", data)\nexcept FileNotFoundError:\n    print(\"File not found: guild/config/model_routing.json\")\nexcept json.JSONDecodeError as e:\n    print(f\"Error decoding JSON: {e}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n```\n\n### Notes:\n- The `with open(...)` statement ensures the file is properly closed after reading.\n- `encoding='utf-8'` ensures proper handling of Unicode characters.\n- Error handling is included for common issues like file not found or invalid JSON.\n- `data` will contain the parsed JSON object (usually a dictionary or list).", "prompt_tokens": 23, "completion_tokens": 196, "latency_ms": 11279.324293136597, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "Here's a Python snippet that loads JSON from the file `guild/config/model_routing.json`:\n\n```python\nimport json\n\n# Load JSON from the specified file\ntry:\n    with open('guild/config/model_routing.json', 'r', encoding='utf-8') as file:\n        data = json.load(file)\n    print(\"JSON loaded successfully:\", data)\nexcept FileNotFoundError:\n    print(\"File not found: guild/config/model_routing.json\")\nexcept json.JSONDecodeError as e:\n    print(f\"Error decoding JSON: {e}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n```\n\n### Notes:\n- The `with open(...)` statement ensures the file is properly closed after reading.\n- `encoding='utf-8'` ensures proper handling of Unicode characters.\n- Error handling is included for common issues like file not found or invalid JSON.\n- `data` will contain the parsed JSON object (usually a dictionary or list).", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:32:47Z"}}
{"id": "20260120-203024-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 1411.088466644287, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:32:49Z"}}
{"id": "20260120-203024-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "To run the script `scripts/eval_lmstudio_models.py` against all models available at `http://127.0.0.1:1234`, you'll first need to:\n\n1. **Get a list of available models** from the LM Studio API (usually via a `/v1/models` endpoint).\n2. **Loop through each model** and run the evaluation script with the appropriate model name.\n\nAssuming the LM Studio API supports a `/v1/models` endpoint that returns a JSON list of models (e.g., `{\"data\": [{\"id\": \"model-1\"}, {\"id\": \"model-2\"}, ...]}`), here's a **bash command** that does this:\n\n```bash\n#!/bin/bash\n\n# Get the list of models from the LM Studio API\nmodels=$(curl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id')\n\n# Loop through each model and run the evaluation script\nfor model in $models; do\n    echo \"Evaluating model: $model\"\n    python scripts/eval_lmstudio_models.py --model \"$model\"\ndone\n```\n\n### Requirements:\n- `curl` \u2014", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 11450.511693954468, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "To run the script `scripts/eval_lmstudio_models.py` against all models available at `http://127.0.0.1:1234`, you'll first need to:\n\n1. **Get a list of available models** from the LM Studio API (usually via a `/v1/models` endpoint).\n2. **Loop through each model** and run the evaluation script with the appropriate model name.\n\nAssuming the LM Studio API supports a `/v1/models` endpoint that returns a JSON list of models (e.g., `{\"data\": [{\"id\": \"model-1\"}, {\"id\": \"model-2\"}, ...]}`), here's a **bash command** that does this:\n\n```bash\n#!/bin/bash\n\n# Get the list of models from the LM Studio API\nmodels=$(curl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id')\n\n# Loop through each model and run the evaluation script\nfor model in $models; do\n    echo \"Evaluating model: $model\"\n    python scripts/eval_lmstudio_models.py --model \"$model\"\ndone\n```\n\n### Requirements:\n- `curl` \u2014", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:33:00Z"}}
{"id": "20260120-203024-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 1416.799545288086, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:33:02Z"}}
{"id": "20260120-203024-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "- **Prioritize Models with High Impact-to-Cost Ratio**: Select models that deliver the greatest value or performance improvement relative to their resource requirements, ensuring efficient use of limited computational and financial resources.  \n- **Choose Models with Strong Transferability and Adaptability**: Opt for models that can be fine-tuned or applied across multiple use cases with minimal additional training, reducing the need for new model development and saving time and resources.", "prompt_tokens": 24, "completion_tokens": 86, "latency_ms": 6676.967620849609, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "- **Prioritize Models with High Impact-to-Cost Ratio**: Select models that deliver the greatest value or performance improvement relative to their resource requirements, ensuring efficient use of limited computational and financial resources.  \n- **Choose Models with Strong Transferability and Adaptability**: Opt for models that can be fine-tuned or applied across multiple use cases with minimal additional training, reducing the need for new model development and saving time and resources.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:33:09Z"}}
{"id": "20260120-203024-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 1408.2181453704834, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:33:10Z"}}
{"id": "20260120-203024-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "A task routing system automatically assigns tasks to the most appropriate individuals or teams based on predefined criteria such as skills, workload, or availability to ensure efficient and timely task completion.", "prompt_tokens": 22, "completion_tokens": 35, "latency_ms": 1548.6962795257568, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "A task routing system automatically assigns tasks to the most appropriate individuals or teams based on predefined criteria such as skills, workload, or availability to ensure efficient and timely task completion.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:33:12Z"}}
{"id": "20260120-203024-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "urgent", "prompt_tokens": 31, "completion_tokens": 2, "latency_ms": 331.1648368835449, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "urgent", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:33:13Z"}}
{"id": "20260120-203024-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "Here's a Python snippet that loads JSON from the file `guild/config/model_routing.json`:\n\n```python\nimport json\n\n# Load JSON from the specified file\ntry:\n    with open('guild/config/model_routing.json', 'r', encoding='utf-8') as file:\n        data = json.load(file)\n    print(\"JSON loaded successfully:\", data)\nexcept FileNotFoundError:\n    print(\"File not found: guild/config/model_routing.json\")\nexcept json.JSONDecodeError as e:\n    print(f\"Error decoding JSON: {e}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n```\n\n### Notes:\n- The `with open(...)` statement ensures the file is properly closed after reading.\n- `encoding='utf-8'` ensures proper handling of Unicode characters.\n- Error handling is included for common issues like file not found or invalid JSON.\n- The loaded JSON data is stored in the variable `data` and can be used as a dictionary or list depending on the structure.", "prompt_tokens": 23, "completion_tokens": 206, "latency_ms": 9096.231460571289, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "Here's a Python snippet that loads JSON from the file `guild/config/model_routing.json`:\n\n```python\nimport json\n\n# Load JSON from the specified file\ntry:\n    with open('guild/config/model_routing.json', 'r', encoding='utf-8') as file:\n        data = json.load(file)\n    print(\"JSON loaded successfully:\", data)\nexcept FileNotFoundError:\n    print(\"File not found: guild/config/model_routing.json\")\nexcept json.JSONDecodeError as e:\n    print(f\"Error decoding JSON: {e}\")\nexcept Exception as e:\n    print(f\"An error occurred: {e}\")\n```\n\n### Notes:\n- The `with open(...)` statement ensures the file is properly closed after reading.\n- `encoding='utf-8'` ensures proper handling of Unicode characters.\n- Error handling is included for common issues like file not found or invalid JSON.\n- The loaded JSON data is stored in the variable `data` and can be used as a dictionary or list depending on the structure.", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:33:22Z"}}
{"id": "20260120-203024-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 696.2475776672363, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:33:23Z"}}
{"id": "20260120-203024-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "To run the script `scripts/eval_lmstudio_models.py` against all models available at `http://127.0.0.1:1234`, you'll first need to:\n\n1. **Get a list of available models** from the LM Studio API (usually via a `/v1/models` endpoint).\n2. **Loop through each model** and run the evaluation script with the appropriate model name.\n\nHere's a **bash command** that does this:\n\n```bash\n# Get the list of models from the LM Studio API\nmodels=$(curl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id')\n\n# Loop through each model and run the evaluation script\nfor model in $models; do\n    echo \"Evaluating model: $model\"\n    python scripts/eval_lmstudio_models.py --model \"$model\" --base-url http://127.0.0.1:1234\ndone\n```\n\n### Requirements:\n- `curl` must be installed.\n- `jq` must be installed (to parse JSON). Install it via:\n  ```bash\n  # On Ubuntu/Debian\n  sudo", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 17430.076360702515, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "To run the script `scripts/eval_lmstudio_models.py` against all models available at `http://127.0.0.1:1234`, you'll first need to:\n\n1. **Get a list of available models** from the LM Studio API (usually via a `/v1/models` endpoint).\n2. **Loop through each model** and run the evaluation script with the appropriate model name.\n\nHere's a **bash command** that does this:\n\n```bash\n# Get the list of models from the LM Studio API\nmodels=$(curl -s http://127.0.0.1:1234/v1/models | jq -r '.data[].id')\n\n# Loop through each model and run the evaluation script\nfor model in $models; do\n    echo \"Evaluating model: $model\"\n    python scripts/eval_lmstudio_models.py --model \"$model\" --base-url http://127.0.0.1:1234\ndone\n```\n\n### Requirements:\n- `curl` must be installed.\n- `jq` must be installed (to parse JSON). Install it via:\n  ```bash\n  # On Ubuntu/Debian\n  sudo", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:33:41Z"}}
{"id": "20260120-203024-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 1224.8098850250244, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:33:42Z"}}
{"id": "20260120-203024-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "- **Prioritize models with high impact relative to cost**: Select models that deliver the greatest value or performance improvement per unit of resource consumed, ensuring efficient use of limited budget and computational power.  \n- **Choose models with strong scalability and adaptability**: Opt for models that can be easily fine-tuned or scaled for future needs, reducing the need for costly redevelopments or replacements.", "prompt_tokens": 24, "completion_tokens": 78, "latency_ms": 3198.171377182007, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "- **Prioritize models with high impact relative to cost**: Select models that deliver the greatest value or performance improvement per unit of resource consumed, ensuring efficient use of limited budget and computational power.  \n- **Choose models with strong scalability and adaptability**: Opt for models that can be easily fine-tuned or scaled for future needs, reducing the need for costly redevelopments or replacements.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-203024", "created_at": "2026-01-20T20:33:46Z"}}
{"id": "20260121-001539-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 21935.73021888733, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-30b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260121-001539", "created_at": "2026-01-21T00:16:01Z"}}
