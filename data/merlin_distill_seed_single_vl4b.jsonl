{"id": "20260120-190714-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 4527.992010116577, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:18Z"}}
{"id": "20260120-190714-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "A task routing system automates the assignment of tasks to the most suitable team members or resources based on skills, availability, and priorities to enhance efficiency and productivity.", "prompt_tokens": 22, "completion_tokens": 33, "latency_ms": 196.58970832824707, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "A task routing system automates the assignment of tasks to the most suitable team members or resources based on skills, availability, and priorities to enhance efficiency and productivity.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:19Z"}}
{"id": "20260120-190714-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "Code", "prompt_tokens": 31, "completion_tokens": 2, "latency_ms": 34.27839279174805, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "Code", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:19Z"}}
{"id": "20260120-190714-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "```python\nimport json\n\n# Load JSON from 'guild/config/model_routing.json'\nwith open('guild/config/model_routing.json', 'r', encoding='utf-8') as f:\n    data = json.load(f)\n\n# Optional: print the loaded data for verification\nprint(data)\n```\n\nThis snippet:\n- Imports the `json` module\n- Opens the file `'guild/config/model_routing.json'` in read mode with UTF-8 encoding\n- Loads the JSON content into a Python dictionary (`json.load`)\n- Optionally prints the data for verification\n\nNote: Make sure the file exists at the specified path and is a valid JSON file. If you want to handle potential errors, you could wrap this in a try-except block.", "prompt_tokens": 23, "completion_tokens": 151, "latency_ms": 820.0709819793701, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "```python\nimport json\n\n# Load JSON from 'guild/config/model_routing.json'\nwith open('guild/config/model_routing.json', 'r', encoding='utf-8') as f:\n    data = json.load(f)\n\n# Optional: print the loaded data for verification\nprint(data)\n```\n\nThis snippet:\n- Imports the `json` module\n- Opens the file `'guild/config/model_routing.json'` in read mode with UTF-8 encoding\n- Loads the JSON content into a Python dictionary (`json.load`)\n- Optionally prints the data for verification\n\nNote: Make sure the file exists at the specified path and is a valid JSON file. If you want to handle potential errors, you could wrap this in a try-except block.", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:20Z"}}
{"id": "20260120-190714-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 102.39720344543457, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:20Z"}}
{"id": "20260120-190714-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "To run `scripts/eval_lmstudio_models.py` against all models available on `http://127.0.0.1:1234`, you can use a bash command that:\n\n1. Lists all available models via the LM Studio API.\n2. Iterates over them and runs the evaluation script for each model.\n\nAssuming the LM Studio API exposes a `/models` endpoint that returns a list of model names (or you can use `/models?format=json`), here\u2019s a practical solution:\n\n---\n\n### \u2705 Bash Command:\n\n```bash\ncurl -s \"http://127.0.0.1:1234/models\" | jq -r '.[] | .name' | while read -r model; do\n  echo \"Evaluating model: $model\"\n  python scripts/eval_lmstudio_models.py --model \"$model\"\ndone\n```\n\n---\n\n### \ud83d\udccc Notes:\n\n- This assumes the API returns a JSON array of model objects, each with a `name` field.\n- If the API returns a different structure (e.g., `models` array or `name` as a key), adjust the `jq` command accordingly.\n- If the API doesn\u2019t return a JSON", "prompt_tokens": 42, "completion_tokens": 253, "latency_ms": 1380.2545070648193, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "To run `scripts/eval_lmstudio_models.py` against all models available on `http://127.0.0.1:1234`, you can use a bash command that:\n\n1. Lists all available models via the LM Studio API.\n2. Iterates over them and runs the evaluation script for each model.\n\nAssuming the LM Studio API exposes a `/models` endpoint that returns a list of model names (or you can use `/models?format=json`), here\u2019s a practical solution:\n\n---\n\n### \u2705 Bash Command:\n\n```bash\ncurl -s \"http://127.0.0.1:1234/models\" | jq -r '.[] | .name' | while read -r model; do\n  echo \"Evaluating model: $model\"\n  python scripts/eval_lmstudio_models.py --model \"$model\"\ndone\n```\n\n---\n\n### \ud83d\udccc Notes:\n\n- This assumes the API returns a JSON array of model objects, each with a `name` field.\n- If the API returns a different structure (e.g., `models` array or `name` as a key), adjust the `jq` command accordingly.\n- If the API doesn\u2019t return a JSON", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:22Z"}}
{"id": "20260120-190714-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 79.08868789672852, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:22Z"}}
{"id": "20260120-190714-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "- **Prioritize Models with Highest Utility per Resource Cost**: Select the model that delivers the greatest operational or strategic benefit (e.g., highest efficiency, lowest error rate, or best user impact) relative to its resource footprint \u2014 whether computational, time, or personnel \u2014 to maximize ROI under constraints.\n\n- **Leverage Lightweight or Modular Models First**: Choose models that are smaller, faster, or more adaptable (e.g., quantized, distilled, or modular architectures) to reduce resource overhead while maintaining acceptable performance, especially when deploying in constrained environments like edge devices or low-bandwidth systems.", "prompt_tokens": 24, "completion_tokens": 119, "latency_ms": 638.1113529205322, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "- **Prioritize Models with Highest Utility per Resource Cost**: Select the model that delivers the greatest operational or strategic benefit (e.g., highest efficiency, lowest error rate, or best user impact) relative to its resource footprint \u2014 whether computational, time, or personnel \u2014 to maximize ROI under constraints.\n\n- **Leverage Lightweight or Modular Models First**: Choose models that are smaller, faster, or more adaptable (e.g., quantized, distilled, or modular architectures) to reduce resource overhead while maintaining acceptable performance, especially when deploying in constrained environments like edge devices or low-bandwidth systems.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:23Z"}}
{"id": "20260120-190714-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 129.48250770568848, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:24Z"}}
{"id": "20260120-190714-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "A task routing system automates the assignment of tasks to the most suitable team members or resources based on skills, availability, priorities, and other predefined criteria to optimize efficiency and outcomes.", "prompt_tokens": 22, "completion_tokens": 37, "latency_ms": 214.79249000549316, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "A task routing system automates the assignment of tasks to the most suitable team members or resources based on skills, availability, priorities, and other predefined criteria to optimize efficiency and outcomes.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:24Z"}}
{"id": "20260120-190714-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "Code", "prompt_tokens": 31, "completion_tokens": 2, "latency_ms": 35.02917289733887, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "Code", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:24Z"}}
{"id": "20260120-190714-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "Here's a Python snippet that loads JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\n\n# Load JSON from the file\nwith open('guild/config/model_routing.json', 'r', encoding='utf-8') as f:\n    data = json.load(f)\n\n# Optional: Print the loaded data to verify\nprint(data)\n```\n\n### Notes:\n- The file path `'guild/config/model_routing.json'` is assumed to exist and be readable.\n- `encoding='utf-8'` is used to handle Unicode characters properly.\n- `json.load()` reads from a file-like object (like a file opened with `open()`).\n- If you want to handle potential errors, you might want to wrap this in a try-except block.\n\n### Enhanced version with error handling:\n\n```python\nimport json\n\ntry:\n    with open('guild/config/model_routing.json', 'r', encoding='utf-8') as f:\n        data = json.load(f)\n    print(\"Successfully loaded JSON data:\")\n    print(data)\nexcept FileNotFoundError:\n    print(\"Error: 'guild/config/model_routing.json' not found.\")\nexcept json.JSONDecodeError:\n    print(\"Error: Invalid JSON format in the file.\")\nexcept Exception as e:\n   ", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 1380.6040287017822, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "Here's a Python snippet that loads JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\n\n# Load JSON from the file\nwith open('guild/config/model_routing.json', 'r', encoding='utf-8') as f:\n    data = json.load(f)\n\n# Optional: Print the loaded data to verify\nprint(data)\n```\n\n### Notes:\n- The file path `'guild/config/model_routing.json'` is assumed to exist and be readable.\n- `encoding='utf-8'` is used to handle Unicode characters properly.\n- `json.load()` reads from a file-like object (like a file opened with `open()`).\n- If you want to handle potential errors, you might want to wrap this in a try-except block.\n\n### Enhanced version with error handling:\n\n```python\nimport json\n\ntry:\n    with open('guild/config/model_routing.json', 'r', encoding='utf-8') as f:\n        data = json.load(f)\n    print(\"Successfully loaded JSON data:\")\n    print(data)\nexcept FileNotFoundError:\n    print(\"Error: 'guild/config/model_routing.json' not found.\")\nexcept json.JSONDecodeError:\n    print(\"Error: Invalid JSON format in the file.\")\nexcept Exception as e:\n   ", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:26Z"}}
{"id": "20260120-190714-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 95.97253799438477, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:26Z"}}
{"id": "20260120-190714-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "To run `scripts/eval_lmstudio_models.py` against all models available on `http://127.0.0.1:1234`, you can use a bash command that:\n\n1. Lists all available models from the LM Studio server (typically via `/api/models` or similar endpoint).\n2. Iterates over them and runs the evaluation script for each model.\n\nHowever, since `eval_lmstudio_models.py` likely expects a model name as an argument, and the server exposes models via an API, you can use `curl` to fetch the list of models and then loop through them.\n\nHere\u2019s a practical bash command:\n\n```bash\ncurl -s http://127.0.0.1:1234/api/models | jq -r '.[] | .name' | while read -r model; do\n    echo \"Evaluating model: $model\"\n    python scripts/eval_lmstudio_models.py --model \"$model\"\ndone\n```\n\n> \u26a0\ufe0f **Note**: This assumes:\n> - The LM Studio server exposes models via a JSON API at `http://127.0.0.1:1234/api/models`.\n> - The `eval_lmstudio", "prompt_tokens": 42, "completion_tokens": 254, "latency_ms": 1368.070125579834, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "To run `scripts/eval_lmstudio_models.py` against all models available on `http://127.0.0.1:1234`, you can use a bash command that:\n\n1. Lists all available models from the LM Studio server (typically via `/api/models` or similar endpoint).\n2. Iterates over them and runs the evaluation script for each model.\n\nHowever, since `eval_lmstudio_models.py` likely expects a model name as an argument, and the server exposes models via an API, you can use `curl` to fetch the list of models and then loop through them.\n\nHere\u2019s a practical bash command:\n\n```bash\ncurl -s http://127.0.0.1:1234/api/models | jq -r '.[] | .name' | while read -r model; do\n    echo \"Evaluating model: $model\"\n    python scripts/eval_lmstudio_models.py --model \"$model\"\ndone\n```\n\n> \u26a0\ufe0f **Note**: This assumes:\n> - The LM Studio server exposes models via a JSON API at `http://127.0.0.1:1234/api/models`.\n> - The `eval_lmstudio", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:28Z"}}
{"id": "20260120-190714-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 81.45880699157715, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:28Z"}}
{"id": "20260120-190714-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "- **Prioritize Models with Highest Resource Efficiency**: Select the model that delivers the most value (e.g., highest accuracy, lowest latency, or best user satisfaction) per unit of computational or memory resource consumed \u2014 ensuring maximum output quality within constraints.\n\n- **Leverage Lightweight or Modular Architectures**: Choose models that are explicitly designed for low-resource environments (e.g., quantized, distilled, or smaller-batch variants) or can be dynamically loaded/unloaded to conserve memory and processing power during peak loads.", "prompt_tokens": 24, "completion_tokens": 103, "latency_ms": 551.8989562988281, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "- **Prioritize Models with Highest Resource Efficiency**: Select the model that delivers the most value (e.g., highest accuracy, lowest latency, or best user satisfaction) per unit of computational or memory resource consumed \u2014 ensuring maximum output quality within constraints.\n\n- **Leverage Lightweight or Modular Architectures**: Choose models that are explicitly designed for low-resource environments (e.g., quantized, distilled, or smaller-batch variants) or can be dynamically loaded/unloaded to conserve memory and processing power during peak loads.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:29Z"}}
{"id": "20260120-190714-guild_route_json", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "prompt_tokens": 31, "completion_tokens": 20, "latency_ms": 125.12588500976562, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "{\"category\":\"code\",\"models\":[\"qwen/qwen3-coder-30b\"]}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:30Z"}}
{"id": "20260120-190714-guild_task_summary", "task_type": "chat", "system_prompt": null, "user_prompt": "Summarize the purpose of a task routing system in one sentence.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "A task routing system automates the assignment of tasks to the most suitable team members or resources based on skills, availability, workload, and other predefined criteria to optimize efficiency and performance.", "prompt_tokens": 22, "completion_tokens": 37, "latency_ms": 228.42049598693848, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "A task routing system automates the assignment of tasks to the most suitable team members or resources based on skills, availability, workload, and other predefined criteria to optimize efficiency and performance.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:30Z"}}
{"id": "20260120-190714-guild_reasoning_priority", "task_type": "reasoning", "system_prompt": null, "user_prompt": "If a task is marked urgent and requires code generation, which routing category should it use? Reply with one word.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "Code", "prompt_tokens": 31, "completion_tokens": 2, "latency_ms": 30.7462215423584, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "Code", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:30Z"}}
{"id": "20260120-190714-guild_code_config", "task_type": "code", "system_prompt": null, "user_prompt": "Write a Python snippet that loads JSON from 'guild/config/model_routing.json'.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "Here's a Python snippet that loads JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\n\n# Load JSON from the file\nwith open('guild/config/model_routing.json', 'r', encoding='utf-8') as f:\n    data = json.load(f)\n\n# Example: print the loaded data\nprint(data)\n```\n\n**Alternative version with error handling:**\n\n```python\nimport json\n\ntry:\n    with open('guild/config/model_routing.json', 'r', encoding='utf-8') as f:\n        data = json.load(f)\n    print(\"JSON loaded successfully:\", data)\nexcept FileNotFoundError:\n    print(\"Error: 'guild/config/model_routing.json' not found\")\nexcept json.JSONDecodeError:\n    print(\"Error: Invalid JSON format in the file\")\nexcept Exception as e:\n    print(f\"Error: {e}\")\n```\n\n**Note:** Make sure the file exists at the specified path and is properly formatted as valid JSON. The `encoding='utf-8'` parameter is used to handle UTF-8 encoded files, which is standard for JSON files.\n\nYou can also use `json.load()` directly on the file object without a `with` block, but the `with` block is recommended for proper", "prompt_tokens": 23, "completion_tokens": 256, "latency_ms": 1377.9582977294922, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "Here's a Python snippet that loads JSON from `'guild/config/model_routing.json'`:\n\n```python\nimport json\n\n# Load JSON from the file\nwith open('guild/config/model_routing.json', 'r', encoding='utf-8') as f:\n    data = json.load(f)\n\n# Example: print the loaded data\nprint(data)\n```\n\n**Alternative version with error handling:**\n\n```python\nimport json\n\ntry:\n    with open('guild/config/model_routing.json', 'r', encoding='utf-8') as f:\n        data = json.load(f)\n    print(\"JSON loaded successfully:\", data)\nexcept FileNotFoundError:\n    print(\"Error: 'guild/config/model_routing.json' not found\")\nexcept json.JSONDecodeError:\n    print(\"Error: Invalid JSON format in the file\")\nexcept Exception as e:\n    print(f\"Error: {e}\")\n```\n\n**Note:** Make sure the file exists at the specified path and is properly formatted as valid JSON. The `encoding='utf-8'` parameter is used to handle UTF-8 encoded files, which is standard for JSON files.\n\nYou can also use `json.load()` directly on the file object without a `with` block, but the `with` block is recommended for proper", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:32Z"}}
{"id": "20260120-190714-guild_format_task", "task_type": "format", "system_prompt": null, "user_prompt": "Return ONLY JSON: {\"task_id\":\"T-100\",\"status\":\"queued\"}", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "prompt_tokens": 26, "completion_tokens": 15, "latency_ms": 97.76020050048828, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "{\"task_id\":\"T-100\",\"status\":\"queued\"}", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:32Z"}}
{"id": "20260120-190714-guild_code_cli", "task_type": "code", "system_prompt": null, "user_prompt": "Write a bash command to run scripts/eval_lmstudio_models.py against all models on http://127.0.0.1:1234.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "You can use the following bash command to run `scripts/eval_lmstudio_models.py` against all models available on `http://127.0.0.1:1234`:\n\n```bash\ncurl -s \"http://127.0.0.1:1234/models\" | jq -r '.[] | select(.name != null) | .name' | while read -r model; do\n    echo \"Running evaluation for model: $model\"\n    python scripts/eval_lmstudio_models.py --model \"$model\"\ndone\n```\n\n### Explanation:\n\n- `curl -s \"http://127.0.0.1:1234/models\"` \u2014 fetches the list of models from the LM Studio server.\n- `jq -r '.[] | select(.name != null) | .name'` \u2014 parses the JSON response and extracts only the `name` fields of models (skipping any null or invalid entries).\n- `while read -r model` \u2014 loops through each model name.\n- `python scripts/eval_lmstudio_models.py --model \"$model\"` \u2014 runs the evaluation script for each model.\n\n---\n\n### Alternative: If you want to run with a", "prompt_tokens": 42, "completion_tokens": 256, "latency_ms": 1390.2993202209473, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "You can use the following bash command to run `scripts/eval_lmstudio_models.py` against all models available on `http://127.0.0.1:1234`:\n\n```bash\ncurl -s \"http://127.0.0.1:1234/models\" | jq -r '.[] | select(.name != null) | .name' | while read -r model; do\n    echo \"Running evaluation for model: $model\"\n    python scripts/eval_lmstudio_models.py --model \"$model\"\ndone\n```\n\n### Explanation:\n\n- `curl -s \"http://127.0.0.1:1234/models\"` \u2014 fetches the list of models from the LM Studio server.\n- `jq -r '.[] | select(.name != null) | .name'` \u2014 parses the JSON response and extracts only the `name` fields of models (skipping any null or invalid entries).\n- `while read -r model` \u2014 loops through each model name.\n- `python scripts/eval_lmstudio_models.py --model \"$model\"` \u2014 runs the evaluation script for each model.\n\n---\n\n### Alternative: If you want to run with a", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:34Z"}}
{"id": "20260120-190714-guild_reasoning_fallback", "task_type": "reasoning", "system_prompt": null, "user_prompt": "Name one valid fallback model from this list: gemma-3n-e4b, lfm2.5-1.2b. Reply with the model id only.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "lfm2.5-1.2b", "prompt_tokens": 44, "completion_tokens": 11, "latency_ms": 80.44314384460449, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "lfm2.5-1.2b", "rationale": "single-teacher"}, "labels": {"difficulty": "medium", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:34Z"}}
{"id": "20260120-190714-guild_chat_policy", "task_type": "chat", "system_prompt": null, "user_prompt": "Give two bullet rules for how Guild should pick a model when resources are tight.", "context": null, "attachments": [], "tools": [], "teacher_responses": [{"model": "qwen/qwen3-vl-4b", "response": "- **Prioritize Models with Highest Utility-to-Cost Ratio**: Select the model that delivers the most value (e.g., highest performance, best user outcomes, or greatest efficiency gains) relative to its resource footprint \u2014 whether computational, time, or personnel cost \u2014 to maximize impact under constraints.\n\n- **Leverage Lightweight or Modular Models First**: Choose models that are smaller, faster, or more adaptable (e.g., distilled versions, modular architectures, or inference-only models) to reduce resource overhead while maintaining acceptable performance, especially for non-critical or exploratory tasks.", "prompt_tokens": 24, "completion_tokens": 115, "latency_ms": 622.539758682251, "checks": {"passed": 0, "total": 0}, "judge_scores": []}], "selection": {"winner_model": "qwen/qwen3-vl-4b", "response": "- **Prioritize Models with Highest Utility-to-Cost Ratio**: Select the model that delivers the most value (e.g., highest performance, best user outcomes, or greatest efficiency gains) relative to its resource footprint \u2014 whether computational, time, or personnel cost \u2014 to maximize impact under constraints.\n\n- **Leverage Lightweight or Modular Models First**: Choose models that are smaller, faster, or more adaptable (e.g., distilled versions, modular architectures, or inference-only models) to reduce resource overhead while maintaining acceptable performance, especially for non-critical or exploratory tasks.", "rationale": "single-teacher"}, "labels": {"difficulty": "easy", "style": "neutral", "safety": "safe"}, "metadata": {"domain": "guild", "source": "seed_script", "prompt_set": "scripts/eval/prompts_guild.json", "run_id": "20260120-190714", "created_at": "2026-01-20T19:07:35Z"}}
